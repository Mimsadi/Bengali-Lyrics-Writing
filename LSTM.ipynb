{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"LSTM.ipynb","provenance":[{"file_id":"18P1aaNBYg4UQcsENLbc2tI1xOFWH2nPa","timestamp":1643541938481},{"file_id":"https://github.com/saif14/MyProject/blob/master/artcellSongCreate.ipynb","timestamp":1592280166701}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"wYJd1ELv1jzB"},"source":["# Mounting the drive"]},{"cell_type":"code","metadata":{"id":"_fQmHDDKNLC1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1645394016186,"user_tz":-360,"elapsed":17056,"user":{"displayName":"Mimsadi Islam","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07228862094531790502"}},"outputId":"9d7161c2-00bc-4a0b-d502-c33845a9fb9a"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","metadata":{"id":"kRkcw_7uGxnM"},"source":["# Reading the data for Rabindra sangeet"]},{"cell_type":"code","metadata":{"id":"HU-TtHLnVD3t"},"source":["with open('/content/drive/MyDrive/ML Project/Bengali Lyrics/R_T_lyrics.txt') as f:\n","    data=f.read()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pDzp5j1K11Y_"},"source":["# Fetching the weight file from Drive"]},{"cell_type":"code","metadata":{"id":"OMrbz9zfk-9-","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1645394030118,"user_tz":-360,"elapsed":384,"user":{"displayName":"Mimsadi Islam","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07228862094531790502"}},"outputId":"c0a2a577-0295-4cf0-fb1f-7b28fea45b59"},"source":["import shutil\n","\n","shutil.copyfile('/content/drive/MyDrive/ML Project/LSTM_weights/best_86.hdf5' , 'best.hdf5')"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'best.hdf5'"]},"metadata":{},"execution_count":3}]},{"cell_type":"markdown","metadata":{"id":"tvA0f_OU18UI"},"source":["# Importing necessary Libraries"]},{"cell_type":"code","metadata":{"id":"57mJSXENntXN"},"source":["from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional,Conv1D, GlobalMaxPooling1D , MaxPooling1D ,BatchNormalization\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.models import Sequential\n","#from keras.layers import BatchNormalization\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras import regularizers\n","import tensorflow.keras.utils as ku \n","import numpy as np \n","import tensorflow as tf\n","#from imblearn.keras import balanced_batch_generator\n","#from imblearn.keras import BalancedBatchGenerator\n","from imblearn.under_sampling import NearMiss\n","#from balanced_batch_generator import balanced_batch_generator\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","import tensorflow.keras.backend as K\n","#from sklearn.utils import class_weight\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DI04P6X52AK_"},"source":["# Defining the DATA"]},{"cell_type":"code","metadata":{"id":"CjTbOMgJpJLs"},"source":["print(data)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hcqJoNjG2Gp4"},"source":["# Creating the word index using Tokenizer"]},{"cell_type":"code","metadata":{"id":"afAhI_Caqj1l","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1645394155759,"user_tz":-360,"elapsed":386,"user":{"displayName":"Mimsadi Islam","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07228862094531790502"}},"outputId":"a804c4ab-a672-4f77-f1ab-e13733c68003"},"source":["l_end = []\n","l_start = []\n","tokenizer = Tokenizer()\n","corpus = data.split(\"\\n\")\n","tokenizer.fit_on_texts(corpus) \n","total_words = len(tokenizer.word_index) + 1\n","\n","\n","input_sequences = []\n","for line in corpus:\n","\tword=line.split()\n","\tif len(word)!= 0 :\n","  \t\tl_end.append(word[-1])\n","  \t\tl_start.append(word[0])\n","\n","\ttoken_list = tokenizer.texts_to_sequences([line])[0] \n","\n","\tfor i in range(1, len(token_list)):\n","\t\tn_gram_sequence = token_list[:i+1]\n","\n","\t\tinput_sequences.append(n_gram_sequence)\n","max_sequence_len = max([len(x) for x in input_sequences])\n","\n","input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre')) \n","\n","predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n","print(predictors.shape)\n","\n","classes_instance= np.bincount(label)\n","num_classes = len(classes_instance)\n","\n","\n","\n","label = ku.to_categorical(label, num_classes=num_classes)\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(7726, 12)\n"]}]},{"cell_type":"code","metadata":{"id":"NyCWjyFAyXls"},"source":["word_index = tokenizer.word_index\n","word_index\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LVd3hxPt2zFu"},"source":["# Modifying the Tokenizer to reduce number of calsses and pre-process the data to fit in Model"]},{"cell_type":"markdown","metadata":{"id":"eUF5OA1qX2pT"},"source":["#Comute class weights for next line model"]},{"cell_type":"code","metadata":{"id":"RLt1EritX2xS"},"source":["def compute_weight(Y, classes):\n","    Y = np.asarray(Y)\n","    num_samples = len(Y)\n","    n_classes = len(classes)\n","    Y = Y.astype(int)\n","    Y = np.expand_dims(Y, axis=1)\n","    num_bin = np.bincount(Y[:, 0])\n","    class_weights={}\n","    for i in range(n_classes):\n","        if num_bin[i]!=0:\n","            class_weights[i]=(num_samples / (n_classes * num_bin[i]))\n","        else:\n","            class_weights[i]=1 \n","    return class_weights"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KG_zIF-P7Rsm"},"source":["# Preparing data for the next line model"]},{"cell_type":"code","metadata":{"id":"n16j9anr7Vz-"},"source":["text=[]\n","\n","for each_line in data.split('\\n'):\n","    each_line = each_line+'\\n'\n","    text.append(each_line)\n","\n","while True:\n","    try:\n","        text.remove('\\n')\n","    except:\n","        break\n","\n","\n","char_tokenizer = Tokenizer(char_level=True,oov_token=\"UNK\")\n","char_tokenizer.fit_on_texts(text)\n","\n","next_line_token = char_tokenizer.word_index['\\n']\n","total_character = len(char_tokenizer.word_index.keys())\n","\n","sequences = char_tokenizer.texts_to_sequences(text)\n","\n","X=[]\n","Y=[]\n","for each_sequence in sequences:\n","    for i in range(1,len(each_sequence)):\n","        if each_sequence[i]!=next_line_token and each_sequence[i+1]!=next_line_token:\n","            X.append(each_sequence[:i+1])\n","            Y.append(0)\n","        else:\n","            X.append(each_sequence[:i+1])\n","            Y.append(1)\n","            break\n","max_seq_length = max([len(i) for i in X])\n","\n","X = np.array(pad_sequences(X, maxlen=max_seq_length, padding='post'))\n","\n","Y = np.asarray(Y)\n","class_weight = compute_weight(Y, [0,1])\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SBUbYwEYP3Y8"},"source":["# Next Word Model"]},{"cell_type":"code","metadata":{"id":"TfOrUFYVGccX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1645394181743,"user_tz":-360,"elapsed":5138,"user":{"displayName":"Mimsadi Islam","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07228862094531790502"}},"outputId":"791ade4a-0e1d-4014-a82d-eb7792b0bbf9"},"source":["\n","tf.random.set_seed(10)\n","\n","model_3 = Sequential()\n","model_3.add(Embedding(total_words, 120, input_length=max_sequence_len-1))\n","model_3.add(Bidirectional(LSTM(170, return_sequences = True)))\n","\n","model_3.add(Conv1D(filters=64, kernel_size=3,padding='valid'))\n","model_3.add(BatchNormalization())\n","model_3.add(MaxPooling1D(pool_size=2))\n","model_3.add(Dropout(0.2))\n","model_3.add(LSTM(150,return_sequences=True))\n","model_3.add(LSTM(150))\n","\n","model_3.add(Dense(total_words/2, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n","model_3.add(Dense(num_classes, activation='softmax'))\n","adam = Adam(learning_rate=0.001)\n","\n","model_3.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n","print(model_3.summary())"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding (Embedding)       (None, 12, 120)           404880    \n","                                                                 \n"," bidirectional (Bidirectiona  (None, 12, 340)          395760    \n"," l)                                                              \n","                                                                 \n"," conv1d (Conv1D)             (None, 10, 64)            65344     \n","                                                                 \n"," batch_normalization (BatchN  (None, 10, 64)           256       \n"," ormalization)                                                   \n","                                                                 \n"," max_pooling1d (MaxPooling1D  (None, 5, 64)            0         \n"," )                                                               \n","                                                                 \n"," dropout (Dropout)           (None, 5, 64)             0         \n","                                                                 \n"," lstm_1 (LSTM)               (None, 5, 150)            129000    \n","                                                                 \n"," lstm_2 (LSTM)               (None, 150)               180600    \n","                                                                 \n"," dense (Dense)               (None, 1687)              254737    \n","                                                                 \n"," dense_1 (Dense)             (None, 3374)              5695312   \n","                                                                 \n","=================================================================\n","Total params: 7,125,889\n","Trainable params: 7,125,761\n","Non-trainable params: 128\n","_________________________________________________________________\n","None\n"]}]},{"cell_type":"markdown","metadata":{"id":"MNVGZdv25bub"},"source":["# 2nd model to predict next line in the lyrics"]},{"cell_type":"code","metadata":{"id":"MZ_NgfvG4YCQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1645394191366,"user_tz":-360,"elapsed":529,"user":{"displayName":"Mimsadi Islam","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07228862094531790502"}},"outputId":"c2b46e61-8598-4f35-ab5a-30cd198f1aac"},"source":["model2 = Sequential()\n","model2.add(Embedding(total_character+1, 120, input_length=max_seq_length))\n","model2.add(Conv1D(filters=64, kernel_size=3,padding='valid'))\n","model2.add(GlobalMaxPooling1D())\n","model2.add(Dense(10, activation='relu'))\n","model2.add(Dense(1, activation='sigmoid'))\n","model2.compile(optimizer='adam',\n","              loss='binary_crossentropy',\n","              metrics=['accuracy'])\n","print(model2.summary())"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding_1 (Embedding)     (None, 64, 120)           9480      \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 62, 64)            23104     \n","                                                                 \n"," global_max_pooling1d (Globa  (None, 64)               0         \n"," lMaxPooling1D)                                                  \n","                                                                 \n"," dense_2 (Dense)             (None, 10)                650       \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 11        \n","                                                                 \n","=================================================================\n","Total params: 33,245\n","Trainable params: 33,245\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n"]}]},{"cell_type":"markdown","metadata":{"id":"OxBO8xsejYug"},"source":["# Training Next line model"]},{"cell_type":"code","metadata":{"id":"W8FveZb4Abu7","colab":{"base_uri":"https://localhost:8080/"},"outputId":"d4db6444-4836-4752-b637-4f5ec39139e9","executionInfo":{"status":"ok","timestamp":1645397067445,"user_tz":-360,"elapsed":2871279,"user":{"displayName":"Mimsadi Islam","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07228862094531790502"}}},"source":["\n","K.set_value(model2.optimizer.learning_rate, 0.001)\n","\n","\n","\n","\n","filepath = \"best_next_line_model.hdf5\"\n","model_checkpoint = ModelCheckpoint(filepath, monitor=\"accuracy\", save_best_only=True, verbose=1)\n","history = model2.fit(X, Y, batch_size=128, epochs=1000 , verbose=1, callbacks=[model_checkpoint], class_weight=class_weight)\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.4255 - accuracy: 0.7726\n","Epoch 1: accuracy improved from -inf to 0.77261, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 13s 6ms/step - loss: 0.4255 - accuracy: 0.7726\n","Epoch 2/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.2879 - accuracy: 0.8776\n","Epoch 2: accuracy improved from 0.77261 to 0.87813, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 2s 6ms/step - loss: 0.2876 - accuracy: 0.8781\n","Epoch 3/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.2543 - accuracy: 0.8871\n","Epoch 3: accuracy improved from 0.87813 to 0.88710, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 2s 6ms/step - loss: 0.2543 - accuracy: 0.8871\n","Epoch 4/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.2349 - accuracy: 0.8998\n","Epoch 4: accuracy improved from 0.88710 to 0.89947, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 2s 6ms/step - loss: 0.2361 - accuracy: 0.8995\n","Epoch 5/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.2209 - accuracy: 0.9039\n","Epoch 5: accuracy improved from 0.89947 to 0.90412, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 2s 6ms/step - loss: 0.2213 - accuracy: 0.9041\n","Epoch 6/1000\n","379/387 [============================>.] - ETA: 0s - loss: 0.2085 - accuracy: 0.9064\n","Epoch 6: accuracy improved from 0.90412 to 0.90602, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 2s 6ms/step - loss: 0.2095 - accuracy: 0.9060\n","Epoch 7/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.1966 - accuracy: 0.9109\n","Epoch 7: accuracy improved from 0.90602 to 0.91085, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 2s 6ms/step - loss: 0.1966 - accuracy: 0.9109\n","Epoch 8/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.1879 - accuracy: 0.9131\n","Epoch 8: accuracy improved from 0.91085 to 0.91306, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 2s 6ms/step - loss: 0.1878 - accuracy: 0.9131\n","Epoch 9/1000\n","379/387 [============================>.] - ETA: 0s - loss: 0.1769 - accuracy: 0.9195\n","Epoch 9: accuracy improved from 0.91306 to 0.91932, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 2s 6ms/step - loss: 0.1778 - accuracy: 0.9193\n","Epoch 10/1000\n","379/387 [============================>.] - ETA: 0s - loss: 0.1695 - accuracy: 0.9215\n","Epoch 10: accuracy improved from 0.91932 to 0.92128, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 2s 6ms/step - loss: 0.1703 - accuracy: 0.9213\n","Epoch 11/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.1540 - accuracy: 0.9292\n","Epoch 11: accuracy improved from 0.92128 to 0.92862, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 2s 6ms/step - loss: 0.1545 - accuracy: 0.9286\n","Epoch 12/1000\n","379/387 [============================>.] - ETA: 0s - loss: 0.1488 - accuracy: 0.9290\n","Epoch 12: accuracy improved from 0.92862 to 0.92905, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 2s 6ms/step - loss: 0.1481 - accuracy: 0.9290\n","Epoch 13/1000\n","380/387 [============================>.] - ETA: 0s - loss: 0.1371 - accuracy: 0.9344\n","Epoch 13: accuracy improved from 0.92905 to 0.93440, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 2s 6ms/step - loss: 0.1373 - accuracy: 0.9344\n","Epoch 14/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.1301 - accuracy: 0.9386\n","Epoch 14: accuracy improved from 0.93440 to 0.93832, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 2s 6ms/step - loss: 0.1311 - accuracy: 0.9383\n","Epoch 15/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.1213 - accuracy: 0.9416\n","Epoch 15: accuracy improved from 0.93832 to 0.94160, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 2s 6ms/step - loss: 0.1212 - accuracy: 0.9416\n","Epoch 16/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.1150 - accuracy: 0.9454\n","Epoch 16: accuracy improved from 0.94160 to 0.94532, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 2s 6ms/step - loss: 0.1159 - accuracy: 0.9453\n","Epoch 17/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.1120 - accuracy: 0.9456\n","Epoch 17: accuracy improved from 0.94532 to 0.94568, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 2s 6ms/step - loss: 0.1119 - accuracy: 0.9457\n","Epoch 18/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.1020 - accuracy: 0.9516\n","Epoch 18: accuracy improved from 0.94568 to 0.95151, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 2s 6ms/step - loss: 0.1026 - accuracy: 0.9515\n","Epoch 19/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.1041 - accuracy: 0.9508\n","Epoch 19: accuracy did not improve from 0.95151\n","387/387 [==============================] - 2s 6ms/step - loss: 0.1042 - accuracy: 0.9508\n","Epoch 20/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0971 - accuracy: 0.9533\n","Epoch 20: accuracy improved from 0.95151 to 0.95332, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0970 - accuracy: 0.9533\n","Epoch 21/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0901 - accuracy: 0.9574\n","Epoch 21: accuracy improved from 0.95332 to 0.95735, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0901 - accuracy: 0.9573\n","Epoch 22/1000\n","380/387 [============================>.] - ETA: 0s - loss: 0.0877 - accuracy: 0.9587\n","Epoch 22: accuracy improved from 0.95735 to 0.95852, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0876 - accuracy: 0.9585\n","Epoch 23/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0901 - accuracy: 0.9581\n","Epoch 23: accuracy did not improve from 0.95852\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0905 - accuracy: 0.9575\n","Epoch 24/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0842 - accuracy: 0.9604\n","Epoch 24: accuracy improved from 0.95852 to 0.96042, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0842 - accuracy: 0.9604\n","Epoch 25/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0781 - accuracy: 0.9629\n","Epoch 25: accuracy improved from 0.96042 to 0.96278, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0782 - accuracy: 0.9628\n","Epoch 26/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0739 - accuracy: 0.9652\n","Epoch 26: accuracy improved from 0.96278 to 0.96519, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0741 - accuracy: 0.9652\n","Epoch 27/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0762 - accuracy: 0.9645\n","Epoch 27: accuracy did not improve from 0.96519\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0764 - accuracy: 0.9643\n","Epoch 28/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0712 - accuracy: 0.9667\n","Epoch 28: accuracy improved from 0.96519 to 0.96667, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0712 - accuracy: 0.9667\n","Epoch 29/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0743 - accuracy: 0.9648\n","Epoch 29: accuracy did not improve from 0.96667\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0743 - accuracy: 0.9648\n","Epoch 30/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0705 - accuracy: 0.9665\n","Epoch 30: accuracy did not improve from 0.96667\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0706 - accuracy: 0.9664\n","Epoch 31/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0698 - accuracy: 0.9675\n","Epoch 31: accuracy improved from 0.96667 to 0.96751, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0698 - accuracy: 0.9675\n","Epoch 32/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0626 - accuracy: 0.9703\n","Epoch 32: accuracy improved from 0.96751 to 0.97035, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0626 - accuracy: 0.9703\n","Epoch 33/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0643 - accuracy: 0.9696\n","Epoch 33: accuracy did not improve from 0.97035\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0645 - accuracy: 0.9698\n","Epoch 34/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0770 - accuracy: 0.9640\n","Epoch 34: accuracy did not improve from 0.97035\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0779 - accuracy: 0.9642\n","Epoch 35/1000\n","379/387 [============================>.] - ETA: 0s - loss: 0.0651 - accuracy: 0.9701\n","Epoch 35: accuracy did not improve from 0.97035\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0651 - accuracy: 0.9700\n","Epoch 36/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0705 - accuracy: 0.9680\n","Epoch 36: accuracy did not improve from 0.97035\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0705 - accuracy: 0.9680\n","Epoch 37/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0541 - accuracy: 0.9749\n","Epoch 37: accuracy improved from 0.97035 to 0.97487, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0540 - accuracy: 0.9749\n","Epoch 38/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0522 - accuracy: 0.9757\n","Epoch 38: accuracy improved from 0.97487 to 0.97562, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0525 - accuracy: 0.9756\n","Epoch 39/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0518 - accuracy: 0.9760\n","Epoch 39: accuracy improved from 0.97562 to 0.97601, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0519 - accuracy: 0.9760\n","Epoch 40/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0634 - accuracy: 0.9713\n","Epoch 40: accuracy did not improve from 0.97601\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0636 - accuracy: 0.9714\n","Epoch 41/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0625 - accuracy: 0.9722\n","Epoch 41: accuracy did not improve from 0.97601\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0622 - accuracy: 0.9722\n","Epoch 42/1000\n","380/387 [============================>.] - ETA: 0s - loss: 0.0611 - accuracy: 0.9723\n","Epoch 42: accuracy did not improve from 0.97601\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0609 - accuracy: 0.9724\n","Epoch 43/1000\n","379/387 [============================>.] - ETA: 0s - loss: 0.0536 - accuracy: 0.9757\n","Epoch 43: accuracy did not improve from 0.97601\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0536 - accuracy: 0.9755\n","Epoch 44/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0592 - accuracy: 0.9734\n","Epoch 44: accuracy did not improve from 0.97601\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0593 - accuracy: 0.9735\n","Epoch 45/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0494 - accuracy: 0.9780\n","Epoch 45: accuracy improved from 0.97601 to 0.97813, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0492 - accuracy: 0.9781\n","Epoch 46/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0460 - accuracy: 0.9792\n","Epoch 46: accuracy improved from 0.97813 to 0.97926, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0461 - accuracy: 0.9793\n","Epoch 47/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0646 - accuracy: 0.9714\n","Epoch 47: accuracy did not improve from 0.97926\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0644 - accuracy: 0.9713\n","Epoch 48/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0511 - accuracy: 0.9770\n","Epoch 48: accuracy did not improve from 0.97926\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0517 - accuracy: 0.9770\n","Epoch 49/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0656 - accuracy: 0.9701\n","Epoch 49: accuracy did not improve from 0.97926\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0654 - accuracy: 0.9702\n","Epoch 50/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0582 - accuracy: 0.9746\n","Epoch 50: accuracy did not improve from 0.97926\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0582 - accuracy: 0.9746\n","Epoch 51/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0543 - accuracy: 0.9755\n","Epoch 51: accuracy did not improve from 0.97926\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0548 - accuracy: 0.9751\n","Epoch 52/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0466 - accuracy: 0.9793\n","Epoch 52: accuracy did not improve from 0.97926\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0467 - accuracy: 0.9793\n","Epoch 53/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0502 - accuracy: 0.9777\n","Epoch 53: accuracy did not improve from 0.97926\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0503 - accuracy: 0.9777\n","Epoch 54/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0468 - accuracy: 0.9786\n","Epoch 54: accuracy did not improve from 0.97926\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0468 - accuracy: 0.9786\n","Epoch 55/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0465 - accuracy: 0.9795\n","Epoch 55: accuracy improved from 0.97926 to 0.97938, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0472 - accuracy: 0.9794\n","Epoch 56/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0538 - accuracy: 0.9763\n","Epoch 56: accuracy did not improve from 0.97938\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0538 - accuracy: 0.9763\n","Epoch 57/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0577 - accuracy: 0.9746\n","Epoch 57: accuracy did not improve from 0.97938\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0581 - accuracy: 0.9747\n","Epoch 58/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0471 - accuracy: 0.9785\n","Epoch 58: accuracy did not improve from 0.97938\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0471 - accuracy: 0.9785\n","Epoch 59/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0485 - accuracy: 0.9785\n","Epoch 59: accuracy did not improve from 0.97938\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0484 - accuracy: 0.9785\n","Epoch 60/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0439 - accuracy: 0.9793\n","Epoch 60: accuracy improved from 0.97938 to 0.97944, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0437 - accuracy: 0.9794\n","Epoch 61/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0457 - accuracy: 0.9792\n","Epoch 61: accuracy did not improve from 0.97944\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0458 - accuracy: 0.9791\n","Epoch 62/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0450 - accuracy: 0.9809\n","Epoch 62: accuracy improved from 0.97944 to 0.98063, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0454 - accuracy: 0.9806\n","Epoch 63/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0537 - accuracy: 0.9767\n","Epoch 63: accuracy did not improve from 0.98063\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0537 - accuracy: 0.9767\n","Epoch 64/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0534 - accuracy: 0.9760\n","Epoch 64: accuracy did not improve from 0.98063\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0534 - accuracy: 0.9760\n","Epoch 65/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0405 - accuracy: 0.9818\n","Epoch 65: accuracy improved from 0.98063 to 0.98183, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0407 - accuracy: 0.9818\n","Epoch 66/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0380 - accuracy: 0.9829\n","Epoch 66: accuracy improved from 0.98183 to 0.98284, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0380 - accuracy: 0.9828\n","Epoch 67/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0306 - accuracy: 0.9858\n","Epoch 67: accuracy improved from 0.98284 to 0.98581, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0307 - accuracy: 0.9858\n","Epoch 68/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0425 - accuracy: 0.9804\n","Epoch 68: accuracy did not improve from 0.98581\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0425 - accuracy: 0.9804\n","Epoch 69/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0445 - accuracy: 0.9804\n","Epoch 69: accuracy did not improve from 0.98581\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0454 - accuracy: 0.9804\n","Epoch 70/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0527 - accuracy: 0.9776\n","Epoch 70: accuracy did not improve from 0.98581\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0527 - accuracy: 0.9776\n","Epoch 71/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0441 - accuracy: 0.9805\n","Epoch 71: accuracy did not improve from 0.98581\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0448 - accuracy: 0.9804\n","Epoch 72/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0508 - accuracy: 0.9783\n","Epoch 72: accuracy did not improve from 0.98581\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0508 - accuracy: 0.9782\n","Epoch 73/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0355 - accuracy: 0.9836\n","Epoch 73: accuracy did not improve from 0.98581\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0354 - accuracy: 0.9836\n","Epoch 74/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0460 - accuracy: 0.9809\n","Epoch 74: accuracy did not improve from 0.98581\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0461 - accuracy: 0.9808\n","Epoch 75/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0448 - accuracy: 0.9804\n","Epoch 75: accuracy did not improve from 0.98581\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0449 - accuracy: 0.9804\n","Epoch 76/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0481 - accuracy: 0.9791\n","Epoch 76: accuracy did not improve from 0.98581\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0481 - accuracy: 0.9791\n","Epoch 77/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0407 - accuracy: 0.9819\n","Epoch 77: accuracy did not improve from 0.98581\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0406 - accuracy: 0.9819\n","Epoch 78/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0313 - accuracy: 0.9862\n","Epoch 78: accuracy improved from 0.98581 to 0.98623, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0313 - accuracy: 0.9862\n","Epoch 79/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0414 - accuracy: 0.9823\n","Epoch 79: accuracy did not improve from 0.98623\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0415 - accuracy: 0.9823\n","Epoch 80/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0419 - accuracy: 0.9821\n","Epoch 80: accuracy did not improve from 0.98623\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0417 - accuracy: 0.9822\n","Epoch 81/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0439 - accuracy: 0.9808\n","Epoch 81: accuracy did not improve from 0.98623\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0439 - accuracy: 0.9808\n","Epoch 82/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0425 - accuracy: 0.9810\n","Epoch 82: accuracy did not improve from 0.98623\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0423 - accuracy: 0.9811\n","Epoch 83/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0428 - accuracy: 0.9819\n","Epoch 83: accuracy did not improve from 0.98623\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0426 - accuracy: 0.9819\n","Epoch 84/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0468 - accuracy: 0.9802\n","Epoch 84: accuracy did not improve from 0.98623\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0478 - accuracy: 0.9803\n","Epoch 85/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0399 - accuracy: 0.9819\n","Epoch 85: accuracy did not improve from 0.98623\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0400 - accuracy: 0.9819\n","Epoch 86/1000\n","380/387 [============================>.] - ETA: 0s - loss: 0.0315 - accuracy: 0.9862\n","Epoch 86: accuracy did not improve from 0.98623\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0317 - accuracy: 0.9860\n","Epoch 87/1000\n","379/387 [============================>.] - ETA: 0s - loss: 0.0405 - accuracy: 0.9814\n","Epoch 87: accuracy did not improve from 0.98623\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0403 - accuracy: 0.9816\n","Epoch 88/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0513 - accuracy: 0.9785\n","Epoch 88: accuracy did not improve from 0.98623\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0516 - accuracy: 0.9781\n","Epoch 89/1000\n","379/387 [============================>.] - ETA: 0s - loss: 0.0426 - accuracy: 0.9817\n","Epoch 89: accuracy did not improve from 0.98623\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0427 - accuracy: 0.9817\n","Epoch 90/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0393 - accuracy: 0.9829\n","Epoch 90: accuracy did not improve from 0.98623\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0394 - accuracy: 0.9829\n","Epoch 91/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0317 - accuracy: 0.9857\n","Epoch 91: accuracy did not improve from 0.98623\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0316 - accuracy: 0.9857\n","Epoch 92/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0246 - accuracy: 0.9893\n","Epoch 92: accuracy improved from 0.98623 to 0.98927, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0246 - accuracy: 0.9893\n","Epoch 93/1000\n","380/387 [============================>.] - ETA: 0s - loss: 0.0291 - accuracy: 0.9868\n","Epoch 93: accuracy did not improve from 0.98927\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0295 - accuracy: 0.9869\n","Epoch 94/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0482 - accuracy: 0.9802\n","Epoch 94: accuracy did not improve from 0.98927\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0478 - accuracy: 0.9803\n","Epoch 95/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0398 - accuracy: 0.9828\n","Epoch 95: accuracy did not improve from 0.98927\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0398 - accuracy: 0.9828\n","Epoch 96/1000\n","380/387 [============================>.] - ETA: 0s - loss: 0.0430 - accuracy: 0.9818\n","Epoch 96: accuracy did not improve from 0.98927\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0430 - accuracy: 0.9818\n","Epoch 97/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0336 - accuracy: 0.9856\n","Epoch 97: accuracy did not improve from 0.98927\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0336 - accuracy: 0.9855\n","Epoch 98/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0277 - accuracy: 0.9880\n","Epoch 98: accuracy did not improve from 0.98927\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0275 - accuracy: 0.9881\n","Epoch 99/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0337 - accuracy: 0.9856\n","Epoch 99: accuracy did not improve from 0.98927\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0339 - accuracy: 0.9856\n","Epoch 100/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0402 - accuracy: 0.9831\n","Epoch 100: accuracy did not improve from 0.98927\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0401 - accuracy: 0.9831\n","Epoch 101/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0338 - accuracy: 0.9852\n","Epoch 101: accuracy did not improve from 0.98927\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0338 - accuracy: 0.9852\n","Epoch 102/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0383 - accuracy: 0.9842\n","Epoch 102: accuracy did not improve from 0.98927\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0384 - accuracy: 0.9843\n","Epoch 103/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0284 - accuracy: 0.9875\n","Epoch 103: accuracy did not improve from 0.98927\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0282 - accuracy: 0.9876\n","Epoch 104/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0400 - accuracy: 0.9836\n","Epoch 104: accuracy did not improve from 0.98927\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0401 - accuracy: 0.9836\n","Epoch 105/1000\n","379/387 [============================>.] - ETA: 0s - loss: 0.0469 - accuracy: 0.9812\n","Epoch 105: accuracy did not improve from 0.98927\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0470 - accuracy: 0.9809\n","Epoch 106/1000\n","380/387 [============================>.] - ETA: 0s - loss: 0.0327 - accuracy: 0.9857\n","Epoch 106: accuracy did not improve from 0.98927\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0328 - accuracy: 0.9856\n","Epoch 107/1000\n","380/387 [============================>.] - ETA: 0s - loss: 0.0252 - accuracy: 0.9892\n","Epoch 107: accuracy did not improve from 0.98927\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0255 - accuracy: 0.9892\n","Epoch 108/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0277 - accuracy: 0.9874\n","Epoch 108: accuracy did not improve from 0.98927\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0278 - accuracy: 0.9873\n","Epoch 109/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0509 - accuracy: 0.9797\n","Epoch 109: accuracy did not improve from 0.98927\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0509 - accuracy: 0.9797\n","Epoch 110/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0351 - accuracy: 0.9847\n","Epoch 110: accuracy did not improve from 0.98927\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0351 - accuracy: 0.9847\n","Epoch 111/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0371 - accuracy: 0.9842\n","Epoch 111: accuracy did not improve from 0.98927\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0370 - accuracy: 0.9842\n","Epoch 112/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0375 - accuracy: 0.9843\n","Epoch 112: accuracy did not improve from 0.98927\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0375 - accuracy: 0.9844\n","Epoch 113/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0349 - accuracy: 0.9850\n","Epoch 113: accuracy did not improve from 0.98927\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0355 - accuracy: 0.9851\n","Epoch 114/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0373 - accuracy: 0.9839\n","Epoch 114: accuracy did not improve from 0.98927\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0374 - accuracy: 0.9839\n","Epoch 115/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0323 - accuracy: 0.9860\n","Epoch 115: accuracy did not improve from 0.98927\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0323 - accuracy: 0.9859\n","Epoch 116/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0386 - accuracy: 0.9841\n","Epoch 116: accuracy did not improve from 0.98927\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0386 - accuracy: 0.9841\n","Epoch 117/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0400 - accuracy: 0.9834\n","Epoch 117: accuracy did not improve from 0.98927\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0402 - accuracy: 0.9836\n","Epoch 118/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0447 - accuracy: 0.9820\n","Epoch 118: accuracy did not improve from 0.98927\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0447 - accuracy: 0.9820\n","Epoch 119/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0274 - accuracy: 0.9880\n","Epoch 119: accuracy did not improve from 0.98927\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0273 - accuracy: 0.9880\n","Epoch 120/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0190 - accuracy: 0.9915\n","Epoch 120: accuracy improved from 0.98927 to 0.99145, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0191 - accuracy: 0.9914\n","Epoch 121/1000\n","379/387 [============================>.] - ETA: 0s - loss: 0.0340 - accuracy: 0.9856\n","Epoch 121: accuracy did not improve from 0.99145\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0342 - accuracy: 0.9855\n","Epoch 122/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0382 - accuracy: 0.9841\n","Epoch 122: accuracy did not improve from 0.99145\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0382 - accuracy: 0.9841\n","Epoch 123/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0300 - accuracy: 0.9865\n","Epoch 123: accuracy did not improve from 0.99145\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0300 - accuracy: 0.9866\n","Epoch 124/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0219 - accuracy: 0.9906\n","Epoch 124: accuracy did not improve from 0.99145\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0219 - accuracy: 0.9906\n","Epoch 125/1000\n","379/387 [============================>.] - ETA: 0s - loss: 0.0254 - accuracy: 0.9891\n","Epoch 125: accuracy did not improve from 0.99145\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0254 - accuracy: 0.9891\n","Epoch 126/1000\n","380/387 [============================>.] - ETA: 0s - loss: 0.0244 - accuracy: 0.9896\n","Epoch 126: accuracy did not improve from 0.99145\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0241 - accuracy: 0.9897\n","Epoch 127/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0293 - accuracy: 0.9872\n","Epoch 127: accuracy did not improve from 0.99145\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0300 - accuracy: 0.9870\n","Epoch 128/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0432 - accuracy: 0.9825\n","Epoch 128: accuracy did not improve from 0.99145\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0430 - accuracy: 0.9825\n","Epoch 129/1000\n","379/387 [============================>.] - ETA: 0s - loss: 0.0309 - accuracy: 0.9860\n","Epoch 129: accuracy did not improve from 0.99145\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0306 - accuracy: 0.9861\n","Epoch 130/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0406 - accuracy: 0.9832\n","Epoch 130: accuracy did not improve from 0.99145\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0406 - accuracy: 0.9832\n","Epoch 131/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0306 - accuracy: 0.9866\n","Epoch 131: accuracy did not improve from 0.99145\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0305 - accuracy: 0.9867\n","Epoch 132/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0322 - accuracy: 0.9862\n","Epoch 132: accuracy did not improve from 0.99145\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0323 - accuracy: 0.9863\n","Epoch 133/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0353 - accuracy: 0.9853\n","Epoch 133: accuracy did not improve from 0.99145\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0351 - accuracy: 0.9854\n","Epoch 134/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0308 - accuracy: 0.9868\n","Epoch 134: accuracy did not improve from 0.99145\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0307 - accuracy: 0.9869\n","Epoch 135/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0359 - accuracy: 0.9846\n","Epoch 135: accuracy did not improve from 0.99145\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0360 - accuracy: 0.9847\n","Epoch 136/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0380 - accuracy: 0.9833\n","Epoch 136: accuracy did not improve from 0.99145\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0379 - accuracy: 0.9833\n","Epoch 137/1000\n","379/387 [============================>.] - ETA: 0s - loss: 0.0284 - accuracy: 0.9882\n","Epoch 137: accuracy did not improve from 0.99145\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0281 - accuracy: 0.9883\n","Epoch 138/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0191 - accuracy: 0.9914\n","Epoch 138: accuracy did not improve from 0.99145\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0191 - accuracy: 0.9914\n","Epoch 139/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0171 - accuracy: 0.9925\n","Epoch 139: accuracy improved from 0.99145 to 0.99248, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0172 - accuracy: 0.9925\n","Epoch 140/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0258 - accuracy: 0.9893\n","Epoch 140: accuracy did not improve from 0.99248\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0261 - accuracy: 0.9892\n","Epoch 141/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0273 - accuracy: 0.9882\n","Epoch 141: accuracy did not improve from 0.99248\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0272 - accuracy: 0.9883\n","Epoch 142/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0405 - accuracy: 0.9844\n","Epoch 142: accuracy did not improve from 0.99248\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0405 - accuracy: 0.9843\n","Epoch 143/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0475 - accuracy: 0.9806\n","Epoch 143: accuracy did not improve from 0.99248\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0475 - accuracy: 0.9806\n","Epoch 144/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0297 - accuracy: 0.9869\n","Epoch 144: accuracy did not improve from 0.99248\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0296 - accuracy: 0.9869\n","Epoch 145/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0286 - accuracy: 0.9881\n","Epoch 145: accuracy did not improve from 0.99248\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0285 - accuracy: 0.9882\n","Epoch 146/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0238 - accuracy: 0.9901\n","Epoch 146: accuracy did not improve from 0.99248\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0238 - accuracy: 0.9901\n","Epoch 147/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0168 - accuracy: 0.9926\n","Epoch 147: accuracy improved from 0.99248 to 0.99260, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0168 - accuracy: 0.9926\n","Epoch 148/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0162 - accuracy: 0.9936\n","Epoch 148: accuracy improved from 0.99260 to 0.99349, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0165 - accuracy: 0.9935\n","Epoch 149/1000\n","379/387 [============================>.] - ETA: 0s - loss: 0.0167 - accuracy: 0.9936\n","Epoch 149: accuracy improved from 0.99349 to 0.99357, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0169 - accuracy: 0.9936\n","Epoch 150/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0329 - accuracy: 0.9860\n","Epoch 150: accuracy did not improve from 0.99357\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0328 - accuracy: 0.9861\n","Epoch 151/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0303 - accuracy: 0.9872\n","Epoch 151: accuracy did not improve from 0.99357\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0303 - accuracy: 0.9872\n","Epoch 152/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0215 - accuracy: 0.9910\n","Epoch 152: accuracy did not improve from 0.99357\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0214 - accuracy: 0.9911\n","Epoch 153/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0315 - accuracy: 0.9876\n","Epoch 153: accuracy did not improve from 0.99357\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0316 - accuracy: 0.9875\n","Epoch 154/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0359 - accuracy: 0.9858\n","Epoch 154: accuracy did not improve from 0.99357\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0359 - accuracy: 0.9857\n","Epoch 155/1000\n","380/387 [============================>.] - ETA: 0s - loss: 0.0312 - accuracy: 0.9869\n","Epoch 155: accuracy did not improve from 0.99357\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0314 - accuracy: 0.9867\n","Epoch 156/1000\n","380/387 [============================>.] - ETA: 0s - loss: 0.0310 - accuracy: 0.9873\n","Epoch 156: accuracy did not improve from 0.99357\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0313 - accuracy: 0.9874\n","Epoch 157/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0170 - accuracy: 0.9926\n","Epoch 157: accuracy did not improve from 0.99357\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0170 - accuracy: 0.9926\n","Epoch 158/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0138 - accuracy: 0.9942\n","Epoch 158: accuracy improved from 0.99357 to 0.99412, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0139 - accuracy: 0.9941\n","Epoch 159/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0212 - accuracy: 0.9911\n","Epoch 159: accuracy did not improve from 0.99412\n","387/387 [==============================] - 3s 6ms/step - loss: 0.0212 - accuracy: 0.9911\n","Epoch 160/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0230 - accuracy: 0.9906\n","Epoch 160: accuracy did not improve from 0.99412\n","387/387 [==============================] - 3s 6ms/step - loss: 0.0230 - accuracy: 0.9906\n","Epoch 161/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0314 - accuracy: 0.9871\n","Epoch 161: accuracy did not improve from 0.99412\n","387/387 [==============================] - 3s 6ms/step - loss: 0.0313 - accuracy: 0.9871\n","Epoch 162/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0327 - accuracy: 0.9865\n","Epoch 162: accuracy did not improve from 0.99412\n","387/387 [==============================] - 3s 6ms/step - loss: 0.0327 - accuracy: 0.9865\n","Epoch 163/1000\n","379/387 [============================>.] - ETA: 0s - loss: 0.0241 - accuracy: 0.9896\n","Epoch 163: accuracy did not improve from 0.99412\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0240 - accuracy: 0.9896\n","Epoch 164/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0215 - accuracy: 0.9912\n","Epoch 164: accuracy did not improve from 0.99412\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0215 - accuracy: 0.9912\n","Epoch 165/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0219 - accuracy: 0.9913\n","Epoch 165: accuracy did not improve from 0.99412\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0231 - accuracy: 0.9910\n","Epoch 166/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0408 - accuracy: 0.9835\n","Epoch 166: accuracy did not improve from 0.99412\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0409 - accuracy: 0.9834\n","Epoch 167/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0278 - accuracy: 0.9890\n","Epoch 167: accuracy did not improve from 0.99412\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0278 - accuracy: 0.9890\n","Epoch 168/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0193 - accuracy: 0.9926\n","Epoch 168: accuracy did not improve from 0.99412\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0193 - accuracy: 0.9926\n","Epoch 169/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0277 - accuracy: 0.9893\n","Epoch 169: accuracy did not improve from 0.99412\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0276 - accuracy: 0.9894\n","Epoch 170/1000\n","380/387 [============================>.] - ETA: 0s - loss: 0.0315 - accuracy: 0.9872\n","Epoch 170: accuracy did not improve from 0.99412\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0313 - accuracy: 0.9873\n","Epoch 171/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0238 - accuracy: 0.9900\n","Epoch 171: accuracy did not improve from 0.99412\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0238 - accuracy: 0.9900\n","Epoch 172/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0175 - accuracy: 0.9924\n","Epoch 172: accuracy did not improve from 0.99412\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0174 - accuracy: 0.9924\n","Epoch 173/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0161 - accuracy: 0.9934\n","Epoch 173: accuracy did not improve from 0.99412\n","387/387 [==============================] - 3s 6ms/step - loss: 0.0162 - accuracy: 0.9933\n","Epoch 174/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0147 - accuracy: 0.9940\n","Epoch 174: accuracy did not improve from 0.99412\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0147 - accuracy: 0.9940\n","Epoch 175/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0288 - accuracy: 0.9885\n","Epoch 175: accuracy did not improve from 0.99412\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0288 - accuracy: 0.9885\n","Epoch 176/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0322 - accuracy: 0.9867\n","Epoch 176: accuracy did not improve from 0.99412\n","387/387 [==============================] - 3s 6ms/step - loss: 0.0321 - accuracy: 0.9867\n","Epoch 177/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0319 - accuracy: 0.9878\n","Epoch 177: accuracy did not improve from 0.99412\n","387/387 [==============================] - 3s 6ms/step - loss: 0.0317 - accuracy: 0.9878\n","Epoch 178/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0278 - accuracy: 0.9888\n","Epoch 178: accuracy did not improve from 0.99412\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0275 - accuracy: 0.9889\n","Epoch 179/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0272 - accuracy: 0.9891\n","Epoch 179: accuracy did not improve from 0.99412\n","387/387 [==============================] - 3s 6ms/step - loss: 0.0272 - accuracy: 0.9891\n","Epoch 180/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0255 - accuracy: 0.9900\n","Epoch 180: accuracy did not improve from 0.99412\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0257 - accuracy: 0.9899\n","Epoch 181/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0208 - accuracy: 0.9912\n","Epoch 181: accuracy did not improve from 0.99412\n","387/387 [==============================] - 3s 6ms/step - loss: 0.0208 - accuracy: 0.9912\n","Epoch 182/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0158 - accuracy: 0.9933\n","Epoch 182: accuracy did not improve from 0.99412\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0158 - accuracy: 0.9933\n","Epoch 183/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0112 - accuracy: 0.9953\n","Epoch 183: accuracy improved from 0.99412 to 0.99535, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0111 - accuracy: 0.9954\n","Epoch 184/1000\n","380/387 [============================>.] - ETA: 0s - loss: 0.0116 - accuracy: 0.9954\n","Epoch 184: accuracy did not improve from 0.99535\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0126 - accuracy: 0.9952\n","Epoch 185/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0285 - accuracy: 0.9887\n","Epoch 185: accuracy did not improve from 0.99535\n","387/387 [==============================] - 3s 6ms/step - loss: 0.0284 - accuracy: 0.9887\n","Epoch 186/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0276 - accuracy: 0.9893\n","Epoch 186: accuracy did not improve from 0.99535\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0275 - accuracy: 0.9894\n","Epoch 187/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0272 - accuracy: 0.9895\n","Epoch 187: accuracy did not improve from 0.99535\n","387/387 [==============================] - 3s 6ms/step - loss: 0.0272 - accuracy: 0.9895\n","Epoch 188/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0330 - accuracy: 0.9870\n","Epoch 188: accuracy did not improve from 0.99535\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0330 - accuracy: 0.9870\n","Epoch 189/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0280 - accuracy: 0.9885\n","Epoch 189: accuracy did not improve from 0.99535\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0279 - accuracy: 0.9885\n","Epoch 190/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0181 - accuracy: 0.9925\n","Epoch 190: accuracy did not improve from 0.99535\n","387/387 [==============================] - 3s 6ms/step - loss: 0.0181 - accuracy: 0.9925\n","Epoch 191/1000\n","380/387 [============================>.] - ETA: 0s - loss: 0.0157 - accuracy: 0.9932\n","Epoch 191: accuracy did not improve from 0.99535\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0156 - accuracy: 0.9932\n","Epoch 192/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0291 - accuracy: 0.9887\n","Epoch 192: accuracy did not improve from 0.99535\n","387/387 [==============================] - 3s 6ms/step - loss: 0.0291 - accuracy: 0.9887\n","Epoch 193/1000\n","380/387 [============================>.] - ETA: 0s - loss: 0.0202 - accuracy: 0.9917\n","Epoch 193: accuracy did not improve from 0.99535\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0202 - accuracy: 0.9917\n","Epoch 194/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0114 - accuracy: 0.9953\n","Epoch 194: accuracy did not improve from 0.99535\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0118 - accuracy: 0.9952\n","Epoch 195/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0221 - accuracy: 0.9911\n","Epoch 195: accuracy did not improve from 0.99535\n","387/387 [==============================] - 3s 6ms/step - loss: 0.0228 - accuracy: 0.9910\n","Epoch 196/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0392 - accuracy: 0.9840\n","Epoch 196: accuracy did not improve from 0.99535\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0391 - accuracy: 0.9842\n","Epoch 197/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0223 - accuracy: 0.9913\n","Epoch 197: accuracy did not improve from 0.99535\n","387/387 [==============================] - 3s 6ms/step - loss: 0.0222 - accuracy: 0.9913\n","Epoch 198/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0243 - accuracy: 0.9900\n","Epoch 198: accuracy did not improve from 0.99535\n","387/387 [==============================] - 3s 6ms/step - loss: 0.0242 - accuracy: 0.9900\n","Epoch 199/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0169 - accuracy: 0.9931\n","Epoch 199: accuracy did not improve from 0.99535\n","387/387 [==============================] - 3s 6ms/step - loss: 0.0169 - accuracy: 0.9930\n","Epoch 200/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0109 - accuracy: 0.9955\n","Epoch 200: accuracy improved from 0.99535 to 0.99547, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0109 - accuracy: 0.9955\n","Epoch 201/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0077 - accuracy: 0.9969\n","Epoch 201: accuracy improved from 0.99547 to 0.99687, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0077 - accuracy: 0.9969\n","Epoch 202/1000\n","379/387 [============================>.] - ETA: 0s - loss: 0.0225 - accuracy: 0.9907\n","Epoch 202: accuracy did not improve from 0.99687\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0228 - accuracy: 0.9906\n","Epoch 203/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0367 - accuracy: 0.9859\n","Epoch 203: accuracy did not improve from 0.99687\n","387/387 [==============================] - 3s 6ms/step - loss: 0.0367 - accuracy: 0.9859\n","Epoch 204/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0314 - accuracy: 0.9883\n","Epoch 204: accuracy did not improve from 0.99687\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0314 - accuracy: 0.9883\n","Epoch 205/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0284 - accuracy: 0.9895\n","Epoch 205: accuracy did not improve from 0.99687\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0288 - accuracy: 0.9893\n","Epoch 206/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0327 - accuracy: 0.9866\n","Epoch 206: accuracy did not improve from 0.99687\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0329 - accuracy: 0.9865\n","Epoch 207/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0263 - accuracy: 0.9893\n","Epoch 207: accuracy did not improve from 0.99687\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0263 - accuracy: 0.9893\n","Epoch 208/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0135 - accuracy: 0.9943\n","Epoch 208: accuracy did not improve from 0.99687\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0134 - accuracy: 0.9944\n","Epoch 209/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0258 - accuracy: 0.9903\n","Epoch 209: accuracy did not improve from 0.99687\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0265 - accuracy: 0.9899\n","Epoch 210/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0310 - accuracy: 0.9882\n","Epoch 210: accuracy did not improve from 0.99687\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0310 - accuracy: 0.9882\n","Epoch 211/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0136 - accuracy: 0.9942\n","Epoch 211: accuracy did not improve from 0.99687\n","387/387 [==============================] - 3s 6ms/step - loss: 0.0137 - accuracy: 0.9941\n","Epoch 212/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0133 - accuracy: 0.9945\n","Epoch 212: accuracy did not improve from 0.99687\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0135 - accuracy: 0.9942\n","Epoch 213/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0274 - accuracy: 0.9890\n","Epoch 213: accuracy did not improve from 0.99687\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0274 - accuracy: 0.9890\n","Epoch 214/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0180 - accuracy: 0.9925\n","Epoch 214: accuracy did not improve from 0.99687\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0181 - accuracy: 0.9925\n","Epoch 215/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0113 - accuracy: 0.9951\n","Epoch 215: accuracy did not improve from 0.99687\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0113 - accuracy: 0.9951\n","Epoch 216/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0221 - accuracy: 0.9916\n","Epoch 216: accuracy did not improve from 0.99687\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0221 - accuracy: 0.9916\n","Epoch 217/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0171 - accuracy: 0.9929\n","Epoch 217: accuracy did not improve from 0.99687\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0172 - accuracy: 0.9929\n","Epoch 218/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0307 - accuracy: 0.9887\n","Epoch 218: accuracy did not improve from 0.99687\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0308 - accuracy: 0.9885\n","Epoch 219/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0332 - accuracy: 0.9874\n","Epoch 219: accuracy did not improve from 0.99687\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0332 - accuracy: 0.9874\n","Epoch 220/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0262 - accuracy: 0.9888\n","Epoch 220: accuracy did not improve from 0.99687\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0262 - accuracy: 0.9888\n","Epoch 221/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0132 - accuracy: 0.9944\n","Epoch 221: accuracy did not improve from 0.99687\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0132 - accuracy: 0.9944\n","Epoch 222/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0094 - accuracy: 0.9961\n","Epoch 222: accuracy did not improve from 0.99687\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0094 - accuracy: 0.9961\n","Epoch 223/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0080 - accuracy: 0.9967\n","Epoch 223: accuracy did not improve from 0.99687\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0080 - accuracy: 0.9967\n","Epoch 224/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0054 - accuracy: 0.9979\n","Epoch 224: accuracy improved from 0.99687 to 0.99790, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0054 - accuracy: 0.9979\n","Epoch 225/1000\n","380/387 [============================>.] - ETA: 0s - loss: 0.0060 - accuracy: 0.9974\n","Epoch 225: accuracy did not improve from 0.99790\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0060 - accuracy: 0.9975\n","Epoch 226/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0235 - accuracy: 0.9922\n","Epoch 226: accuracy did not improve from 0.99790\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0237 - accuracy: 0.9921\n","Epoch 227/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0663 - accuracy: 0.9749\n","Epoch 227: accuracy did not improve from 0.99790\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0664 - accuracy: 0.9749\n","Epoch 228/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0247 - accuracy: 0.9897\n","Epoch 228: accuracy did not improve from 0.99790\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0247 - accuracy: 0.9897\n","Epoch 229/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0177 - accuracy: 0.9924\n","Epoch 229: accuracy did not improve from 0.99790\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0176 - accuracy: 0.9925\n","Epoch 230/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0111 - accuracy: 0.9955\n","Epoch 230: accuracy did not improve from 0.99790\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0111 - accuracy: 0.9955\n","Epoch 231/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0085 - accuracy: 0.9965\n","Epoch 231: accuracy did not improve from 0.99790\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0085 - accuracy: 0.9965\n","Epoch 232/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0074 - accuracy: 0.9971\n","Epoch 232: accuracy did not improve from 0.99790\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0074 - accuracy: 0.9971\n","Epoch 233/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0075 - accuracy: 0.9972\n","Epoch 233: accuracy did not improve from 0.99790\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0076 - accuracy: 0.9971\n","Epoch 234/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0654 - accuracy: 0.9776\n","Epoch 234: accuracy did not improve from 0.99790\n","387/387 [==============================] - 3s 6ms/step - loss: 0.0651 - accuracy: 0.9776\n","Epoch 235/1000\n","380/387 [============================>.] - ETA: 0s - loss: 0.0264 - accuracy: 0.9891\n","Epoch 235: accuracy did not improve from 0.99790\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0267 - accuracy: 0.9891\n","Epoch 236/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0256 - accuracy: 0.9893\n","Epoch 236: accuracy did not improve from 0.99790\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0254 - accuracy: 0.9893\n","Epoch 237/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0121 - accuracy: 0.9948\n","Epoch 237: accuracy did not improve from 0.99790\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0121 - accuracy: 0.9947\n","Epoch 238/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0079 - accuracy: 0.9968\n","Epoch 238: accuracy did not improve from 0.99790\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0079 - accuracy: 0.9968\n","Epoch 239/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0056 - accuracy: 0.9978\n","Epoch 239: accuracy did not improve from 0.99790\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0056 - accuracy: 0.9978\n","Epoch 240/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0048 - accuracy: 0.9983\n","Epoch 240: accuracy improved from 0.99790 to 0.99832, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0048 - accuracy: 0.9983\n","Epoch 241/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0045 - accuracy: 0.9983\n","Epoch 241: accuracy did not improve from 0.99832\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0045 - accuracy: 0.9982\n","Epoch 242/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0215 - accuracy: 0.9921\n","Epoch 242: accuracy did not improve from 0.99832\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0219 - accuracy: 0.9922\n","Epoch 243/1000\n","380/387 [============================>.] - ETA: 0s - loss: 0.0640 - accuracy: 0.9775\n","Epoch 243: accuracy did not improve from 0.99832\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0638 - accuracy: 0.9776\n","Epoch 244/1000\n","380/387 [============================>.] - ETA: 0s - loss: 0.0286 - accuracy: 0.9874\n","Epoch 244: accuracy did not improve from 0.99832\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0289 - accuracy: 0.9874\n","Epoch 245/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0202 - accuracy: 0.9917\n","Epoch 245: accuracy did not improve from 0.99832\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0202 - accuracy: 0.9918\n","Epoch 246/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0159 - accuracy: 0.9935\n","Epoch 246: accuracy did not improve from 0.99832\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0160 - accuracy: 0.9935\n","Epoch 247/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0106 - accuracy: 0.9954\n","Epoch 247: accuracy did not improve from 0.99832\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0105 - accuracy: 0.9955\n","Epoch 248/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0205 - accuracy: 0.9911\n","Epoch 248: accuracy did not improve from 0.99832\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0207 - accuracy: 0.9909\n","Epoch 249/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0147 - accuracy: 0.9935\n","Epoch 249: accuracy did not improve from 0.99832\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0148 - accuracy: 0.9936\n","Epoch 250/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0084 - accuracy: 0.9963\n","Epoch 250: accuracy did not improve from 0.99832\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0084 - accuracy: 0.9963\n","Epoch 251/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0134 - accuracy: 0.9947\n","Epoch 251: accuracy did not improve from 0.99832\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0135 - accuracy: 0.9947\n","Epoch 252/1000\n","380/387 [============================>.] - ETA: 0s - loss: 0.0154 - accuracy: 0.9936\n","Epoch 252: accuracy did not improve from 0.99832\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0152 - accuracy: 0.9937\n","Epoch 253/1000\n","379/387 [============================>.] - ETA: 0s - loss: 0.0375 - accuracy: 0.9864\n","Epoch 253: accuracy did not improve from 0.99832\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0373 - accuracy: 0.9864\n","Epoch 254/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0318 - accuracy: 0.9876\n","Epoch 254: accuracy did not improve from 0.99832\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0319 - accuracy: 0.9874\n","Epoch 255/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0192 - accuracy: 0.9915\n","Epoch 255: accuracy did not improve from 0.99832\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0190 - accuracy: 0.9916\n","Epoch 256/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0124 - accuracy: 0.9946\n","Epoch 256: accuracy did not improve from 0.99832\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0124 - accuracy: 0.9946\n","Epoch 257/1000\n","380/387 [============================>.] - ETA: 0s - loss: 0.0110 - accuracy: 0.9954\n","Epoch 257: accuracy did not improve from 0.99832\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0111 - accuracy: 0.9954\n","Epoch 258/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0354 - accuracy: 0.9871\n","Epoch 258: accuracy did not improve from 0.99832\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0353 - accuracy: 0.9871\n","Epoch 259/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0197 - accuracy: 0.9927\n","Epoch 259: accuracy did not improve from 0.99832\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0198 - accuracy: 0.9927\n","Epoch 260/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0111 - accuracy: 0.9950\n","Epoch 260: accuracy did not improve from 0.99832\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0111 - accuracy: 0.9950\n","Epoch 261/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0075 - accuracy: 0.9969\n","Epoch 261: accuracy did not improve from 0.99832\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0074 - accuracy: 0.9969\n","Epoch 262/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0079 - accuracy: 0.9965\n","Epoch 262: accuracy did not improve from 0.99832\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0079 - accuracy: 0.9965\n","Epoch 263/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0128 - accuracy: 0.9945\n","Epoch 263: accuracy did not improve from 0.99832\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0128 - accuracy: 0.9945\n","Epoch 264/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0312 - accuracy: 0.9888\n","Epoch 264: accuracy did not improve from 0.99832\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0312 - accuracy: 0.9888\n","Epoch 265/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0318 - accuracy: 0.9876\n","Epoch 265: accuracy did not improve from 0.99832\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0318 - accuracy: 0.9874\n","Epoch 266/1000\n","380/387 [============================>.] - ETA: 0s - loss: 0.0180 - accuracy: 0.9923\n","Epoch 266: accuracy did not improve from 0.99832\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0181 - accuracy: 0.9924\n","Epoch 267/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0082 - accuracy: 0.9968\n","Epoch 267: accuracy did not improve from 0.99832\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0083 - accuracy: 0.9967\n","Epoch 268/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0128 - accuracy: 0.9949\n","Epoch 268: accuracy did not improve from 0.99832\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0129 - accuracy: 0.9949\n","Epoch 269/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0302 - accuracy: 0.9881\n","Epoch 269: accuracy did not improve from 0.99832\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0302 - accuracy: 0.9880\n","Epoch 270/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0221 - accuracy: 0.9910\n","Epoch 270: accuracy did not improve from 0.99832\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0220 - accuracy: 0.9911\n","Epoch 271/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0129 - accuracy: 0.9947\n","Epoch 271: accuracy did not improve from 0.99832\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0128 - accuracy: 0.9947\n","Epoch 272/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0071 - accuracy: 0.9969\n","Epoch 272: accuracy did not improve from 0.99832\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0071 - accuracy: 0.9969\n","Epoch 273/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0063 - accuracy: 0.9973\n","Epoch 273: accuracy did not improve from 0.99832\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0063 - accuracy: 0.9973\n","Epoch 274/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0050 - accuracy: 0.9980\n","Epoch 274: accuracy did not improve from 0.99832\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0052 - accuracy: 0.9980\n","Epoch 275/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0050 - accuracy: 0.9979\n","Epoch 275: accuracy did not improve from 0.99832\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0050 - accuracy: 0.9979\n","Epoch 276/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0262 - accuracy: 0.9915\n","Epoch 276: accuracy did not improve from 0.99832\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0262 - accuracy: 0.9914\n","Epoch 277/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0471 - accuracy: 0.9829\n","Epoch 277: accuracy did not improve from 0.99832\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0469 - accuracy: 0.9829\n","Epoch 278/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0251 - accuracy: 0.9902\n","Epoch 278: accuracy did not improve from 0.99832\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0254 - accuracy: 0.9901\n","Epoch 279/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0182 - accuracy: 0.9919\n","Epoch 279: accuracy did not improve from 0.99832\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0182 - accuracy: 0.9919\n","Epoch 280/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0091 - accuracy: 0.9960\n","Epoch 280: accuracy did not improve from 0.99832\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0091 - accuracy: 0.9960\n","Epoch 281/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0103 - accuracy: 0.9956\n","Epoch 281: accuracy did not improve from 0.99832\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0102 - accuracy: 0.9957\n","Epoch 282/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0078 - accuracy: 0.9966\n","Epoch 282: accuracy did not improve from 0.99832\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0078 - accuracy: 0.9966\n","Epoch 283/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0280 - accuracy: 0.9893\n","Epoch 283: accuracy did not improve from 0.99832\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0280 - accuracy: 0.9893\n","Epoch 284/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0410 - accuracy: 0.9848\n","Epoch 284: accuracy did not improve from 0.99832\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0409 - accuracy: 0.9848\n","Epoch 285/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0124 - accuracy: 0.9946\n","Epoch 285: accuracy did not improve from 0.99832\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0123 - accuracy: 0.9947\n","Epoch 286/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0080 - accuracy: 0.9967\n","Epoch 286: accuracy did not improve from 0.99832\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0080 - accuracy: 0.9968\n","Epoch 287/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0051 - accuracy: 0.9979\n","Epoch 287: accuracy did not improve from 0.99832\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0052 - accuracy: 0.9978\n","Epoch 288/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0044 - accuracy: 0.9982\n","Epoch 288: accuracy did not improve from 0.99832\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0044 - accuracy: 0.9982\n","Epoch 289/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0042 - accuracy: 0.9985\n","Epoch 289: accuracy improved from 0.99832 to 0.99848, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0042 - accuracy: 0.9985\n","Epoch 290/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0549 - accuracy: 0.9831\n","Epoch 290: accuracy did not improve from 0.99848\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0549 - accuracy: 0.9831\n","Epoch 291/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0286 - accuracy: 0.9892\n","Epoch 291: accuracy did not improve from 0.99848\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0285 - accuracy: 0.9892\n","Epoch 292/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0142 - accuracy: 0.9940\n","Epoch 292: accuracy did not improve from 0.99848\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0142 - accuracy: 0.9940\n","Epoch 293/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0128 - accuracy: 0.9948\n","Epoch 293: accuracy did not improve from 0.99848\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0127 - accuracy: 0.9948\n","Epoch 294/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0169 - accuracy: 0.9926\n","Epoch 294: accuracy did not improve from 0.99848\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0167 - accuracy: 0.9927\n","Epoch 295/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0142 - accuracy: 0.9940\n","Epoch 295: accuracy did not improve from 0.99848\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0145 - accuracy: 0.9940\n","Epoch 296/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0183 - accuracy: 0.9926\n","Epoch 296: accuracy did not improve from 0.99848\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0185 - accuracy: 0.9925\n","Epoch 297/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0147 - accuracy: 0.9941\n","Epoch 297: accuracy did not improve from 0.99848\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0147 - accuracy: 0.9941\n","Epoch 298/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0161 - accuracy: 0.9932\n","Epoch 298: accuracy did not improve from 0.99848\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0161 - accuracy: 0.9932\n","Epoch 299/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0152 - accuracy: 0.9935\n","Epoch 299: accuracy did not improve from 0.99848\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0152 - accuracy: 0.9936\n","Epoch 300/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0177 - accuracy: 0.9928\n","Epoch 300: accuracy did not improve from 0.99848\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0181 - accuracy: 0.9927\n","Epoch 301/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0164 - accuracy: 0.9935\n","Epoch 301: accuracy did not improve from 0.99848\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0163 - accuracy: 0.9935\n","Epoch 302/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0087 - accuracy: 0.9963\n","Epoch 302: accuracy did not improve from 0.99848\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0087 - accuracy: 0.9963\n","Epoch 303/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0052 - accuracy: 0.9979\n","Epoch 303: accuracy did not improve from 0.99848\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0052 - accuracy: 0.9979\n","Epoch 304/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0049 - accuracy: 0.9980\n","Epoch 304: accuracy did not improve from 0.99848\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0050 - accuracy: 0.9980\n","Epoch 305/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0040 - accuracy: 0.9986\n","Epoch 305: accuracy improved from 0.99848 to 0.99858, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0040 - accuracy: 0.9986\n","Epoch 306/1000\n","380/387 [============================>.] - ETA: 0s - loss: 0.0035 - accuracy: 0.9986\n","Epoch 306: accuracy improved from 0.99858 to 0.99861, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0035 - accuracy: 0.9986\n","Epoch 307/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0088 - accuracy: 0.9967\n","Epoch 307: accuracy did not improve from 0.99861\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0088 - accuracy: 0.9967\n","Epoch 308/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0475 - accuracy: 0.9842\n","Epoch 308: accuracy did not improve from 0.99861\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0473 - accuracy: 0.9842\n","Epoch 309/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0373 - accuracy: 0.9854\n","Epoch 309: accuracy did not improve from 0.99861\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0372 - accuracy: 0.9854\n","Epoch 310/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0174 - accuracy: 0.9931\n","Epoch 310: accuracy did not improve from 0.99861\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0173 - accuracy: 0.9931\n","Epoch 311/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0243 - accuracy: 0.9909\n","Epoch 311: accuracy did not improve from 0.99861\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0243 - accuracy: 0.9909\n","Epoch 312/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0102 - accuracy: 0.9959\n","Epoch 312: accuracy did not improve from 0.99861\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0103 - accuracy: 0.9959\n","Epoch 313/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0101 - accuracy: 0.9954\n","Epoch 313: accuracy did not improve from 0.99861\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0101 - accuracy: 0.9955\n","Epoch 314/1000\n","380/387 [============================>.] - ETA: 0s - loss: 0.0062 - accuracy: 0.9975\n","Epoch 314: accuracy did not improve from 0.99861\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0063 - accuracy: 0.9975\n","Epoch 315/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0051 - accuracy: 0.9979\n","Epoch 315: accuracy did not improve from 0.99861\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0051 - accuracy: 0.9979\n","Epoch 316/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0056 - accuracy: 0.9978\n","Epoch 316: accuracy did not improve from 0.99861\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0055 - accuracy: 0.9978\n","Epoch 317/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0037 - accuracy: 0.9985\n","Epoch 317: accuracy did not improve from 0.99861\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0037 - accuracy: 0.9985\n","Epoch 318/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0071 - accuracy: 0.9974\n","Epoch 318: accuracy did not improve from 0.99861\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0070 - accuracy: 0.9974\n","Epoch 319/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0200 - accuracy: 0.9931\n","Epoch 319: accuracy did not improve from 0.99861\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0210 - accuracy: 0.9926\n","Epoch 320/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0605 - accuracy: 0.9797\n","Epoch 320: accuracy did not improve from 0.99861\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0601 - accuracy: 0.9798\n","Epoch 321/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0288 - accuracy: 0.9886\n","Epoch 321: accuracy did not improve from 0.99861\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0287 - accuracy: 0.9886\n","Epoch 322/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0175 - accuracy: 0.9928\n","Epoch 322: accuracy did not improve from 0.99861\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0175 - accuracy: 0.9928\n","Epoch 323/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0078 - accuracy: 0.9967\n","Epoch 323: accuracy did not improve from 0.99861\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0078 - accuracy: 0.9967\n","Epoch 324/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0073 - accuracy: 0.9969\n","Epoch 324: accuracy did not improve from 0.99861\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0072 - accuracy: 0.9969\n","Epoch 325/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0172 - accuracy: 0.9933\n","Epoch 325: accuracy did not improve from 0.99861\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0174 - accuracy: 0.9930\n","Epoch 326/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0266 - accuracy: 0.9904\n","Epoch 326: accuracy did not improve from 0.99861\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0267 - accuracy: 0.9904\n","Epoch 327/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0151 - accuracy: 0.9937\n","Epoch 327: accuracy did not improve from 0.99861\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0150 - accuracy: 0.9937\n","Epoch 328/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0092 - accuracy: 0.9960\n","Epoch 328: accuracy did not improve from 0.99861\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0091 - accuracy: 0.9960\n","Epoch 329/1000\n","380/387 [============================>.] - ETA: 0s - loss: 0.0064 - accuracy: 0.9973\n","Epoch 329: accuracy did not improve from 0.99861\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0066 - accuracy: 0.9974\n","Epoch 330/1000\n","380/387 [============================>.] - ETA: 0s - loss: 0.0075 - accuracy: 0.9968\n","Epoch 330: accuracy did not improve from 0.99861\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0075 - accuracy: 0.9968\n","Epoch 331/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0050 - accuracy: 0.9981\n","Epoch 331: accuracy did not improve from 0.99861\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0050 - accuracy: 0.9981\n","Epoch 332/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0029 - accuracy: 0.9989\n","Epoch 332: accuracy improved from 0.99861 to 0.99893, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0028 - accuracy: 0.9989\n","Epoch 333/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0128 - accuracy: 0.9953\n","Epoch 333: accuracy did not improve from 0.99893\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0129 - accuracy: 0.9952\n","Epoch 334/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0462 - accuracy: 0.9841\n","Epoch 334: accuracy did not improve from 0.99893\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0460 - accuracy: 0.9842\n","Epoch 335/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0255 - accuracy: 0.9905\n","Epoch 335: accuracy did not improve from 0.99893\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0254 - accuracy: 0.9905\n","Epoch 336/1000\n","380/387 [============================>.] - ETA: 0s - loss: 0.0101 - accuracy: 0.9961\n","Epoch 336: accuracy did not improve from 0.99893\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0101 - accuracy: 0.9961\n","Epoch 337/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0104 - accuracy: 0.9955\n","Epoch 337: accuracy did not improve from 0.99893\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0103 - accuracy: 0.9956\n","Epoch 338/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0095 - accuracy: 0.9964\n","Epoch 338: accuracy did not improve from 0.99893\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0094 - accuracy: 0.9964\n","Epoch 339/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0046 - accuracy: 0.9981\n","Epoch 339: accuracy did not improve from 0.99893\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0048 - accuracy: 0.9981\n","Epoch 340/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0043 - accuracy: 0.9983\n","Epoch 340: accuracy did not improve from 0.99893\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0045 - accuracy: 0.9983\n","Epoch 341/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0147 - accuracy: 0.9939\n","Epoch 341: accuracy did not improve from 0.99893\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0147 - accuracy: 0.9939\n","Epoch 342/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0290 - accuracy: 0.9895\n","Epoch 342: accuracy did not improve from 0.99893\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0288 - accuracy: 0.9896\n","Epoch 343/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0313 - accuracy: 0.9889\n","Epoch 343: accuracy did not improve from 0.99893\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0312 - accuracy: 0.9889\n","Epoch 344/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0136 - accuracy: 0.9946\n","Epoch 344: accuracy did not improve from 0.99893\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0136 - accuracy: 0.9946\n","Epoch 345/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0074 - accuracy: 0.9969\n","Epoch 345: accuracy did not improve from 0.99893\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0074 - accuracy: 0.9969\n","Epoch 346/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0041 - accuracy: 0.9983\n","Epoch 346: accuracy did not improve from 0.99893\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0042 - accuracy: 0.9983\n","Epoch 347/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0070 - accuracy: 0.9975\n","Epoch 347: accuracy did not improve from 0.99893\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0070 - accuracy: 0.9975\n","Epoch 348/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0269 - accuracy: 0.9898\n","Epoch 348: accuracy did not improve from 0.99893\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0266 - accuracy: 0.9899\n","Epoch 349/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0363 - accuracy: 0.9872\n","Epoch 349: accuracy did not improve from 0.99893\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0363 - accuracy: 0.9871\n","Epoch 350/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0255 - accuracy: 0.9904\n","Epoch 350: accuracy did not improve from 0.99893\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0254 - accuracy: 0.9904\n","Epoch 351/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0145 - accuracy: 0.9946\n","Epoch 351: accuracy did not improve from 0.99893\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0144 - accuracy: 0.9946\n","Epoch 352/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0085 - accuracy: 0.9964\n","Epoch 352: accuracy did not improve from 0.99893\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0085 - accuracy: 0.9964\n","Epoch 353/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0052 - accuracy: 0.9979\n","Epoch 353: accuracy did not improve from 0.99893\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0052 - accuracy: 0.9979\n","Epoch 354/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0041 - accuracy: 0.9983\n","Epoch 354: accuracy did not improve from 0.99893\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0041 - accuracy: 0.9983\n","Epoch 355/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0041 - accuracy: 0.9984\n","Epoch 355: accuracy did not improve from 0.99893\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0041 - accuracy: 0.9984\n","Epoch 356/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0029 - accuracy: 0.9990\n","Epoch 356: accuracy improved from 0.99893 to 0.99899, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0029 - accuracy: 0.9990\n","Epoch 357/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0026 - accuracy: 0.9992\n","Epoch 357: accuracy improved from 0.99899 to 0.99915, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0027 - accuracy: 0.9992\n","Epoch 358/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0054 - accuracy: 0.9981\n","Epoch 358: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0059 - accuracy: 0.9977\n","Epoch 359/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0609 - accuracy: 0.9813\n","Epoch 359: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0609 - accuracy: 0.9813\n","Epoch 360/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0295 - accuracy: 0.9885\n","Epoch 360: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0295 - accuracy: 0.9885\n","Epoch 361/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0185 - accuracy: 0.9927\n","Epoch 361: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0190 - accuracy: 0.9926\n","Epoch 362/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0164 - accuracy: 0.9935\n","Epoch 362: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0163 - accuracy: 0.9936\n","Epoch 363/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0071 - accuracy: 0.9969\n","Epoch 363: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0071 - accuracy: 0.9969\n","Epoch 364/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0051 - accuracy: 0.9978\n","Epoch 364: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0051 - accuracy: 0.9978\n","Epoch 365/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0032 - accuracy: 0.9988\n","Epoch 365: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0033 - accuracy: 0.9987\n","Epoch 366/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0041 - accuracy: 0.9986\n","Epoch 366: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0041 - accuracy: 0.9986\n","Epoch 367/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0030 - accuracy: 0.9989\n","Epoch 367: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0030 - accuracy: 0.9988\n","Epoch 368/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0049 - accuracy: 0.9982\n","Epoch 368: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0051 - accuracy: 0.9981\n","Epoch 369/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0465 - accuracy: 0.9856\n","Epoch 369: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0465 - accuracy: 0.9856\n","Epoch 370/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0307 - accuracy: 0.9889\n","Epoch 370: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0305 - accuracy: 0.9889\n","Epoch 371/1000\n","380/387 [============================>.] - ETA: 0s - loss: 0.0136 - accuracy: 0.9945\n","Epoch 371: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0134 - accuracy: 0.9946\n","Epoch 372/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0066 - accuracy: 0.9973\n","Epoch 372: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0065 - accuracy: 0.9973\n","Epoch 373/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0036 - accuracy: 0.9984\n","Epoch 373: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0036 - accuracy: 0.9984\n","Epoch 374/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0030 - accuracy: 0.9988\n","Epoch 374: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0032 - accuracy: 0.9987\n","Epoch 375/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0032 - accuracy: 0.9989\n","Epoch 375: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0031 - accuracy: 0.9989\n","Epoch 376/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0146 - accuracy: 0.9962\n","Epoch 376: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0147 - accuracy: 0.9961\n","Epoch 377/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0420 - accuracy: 0.9843\n","Epoch 377: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0418 - accuracy: 0.9844\n","Epoch 378/1000\n","380/387 [============================>.] - ETA: 0s - loss: 0.0187 - accuracy: 0.9927\n","Epoch 378: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0186 - accuracy: 0.9928\n","Epoch 379/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0075 - accuracy: 0.9971\n","Epoch 379: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0075 - accuracy: 0.9971\n","Epoch 380/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0049 - accuracy: 0.9980\n","Epoch 380: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0049 - accuracy: 0.9980\n","Epoch 381/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0032 - accuracy: 0.9986\n","Epoch 381: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0032 - accuracy: 0.9986\n","Epoch 382/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0024 - accuracy: 0.9990\n","Epoch 382: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0024 - accuracy: 0.9990\n","Epoch 383/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0028 - accuracy: 0.9988\n","Epoch 383: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0028 - accuracy: 0.9988\n","Epoch 384/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0080 - accuracy: 0.9972\n","Epoch 384: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0081 - accuracy: 0.9971\n","Epoch 385/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0588 - accuracy: 0.9818\n","Epoch 385: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0587 - accuracy: 0.9818\n","Epoch 386/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0275 - accuracy: 0.9896\n","Epoch 386: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0275 - accuracy: 0.9896\n","Epoch 387/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0185 - accuracy: 0.9931\n","Epoch 387: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0186 - accuracy: 0.9930\n","Epoch 388/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0111 - accuracy: 0.9961\n","Epoch 388: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0111 - accuracy: 0.9961\n","Epoch 389/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0062 - accuracy: 0.9974\n","Epoch 389: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0061 - accuracy: 0.9974\n","Epoch 390/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0038 - accuracy: 0.9984\n","Epoch 390: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0039 - accuracy: 0.9984\n","Epoch 391/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0029 - accuracy: 0.9988\n","Epoch 391: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0030 - accuracy: 0.9988\n","Epoch 392/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0030 - accuracy: 0.9989\n","Epoch 392: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0030 - accuracy: 0.9988\n","Epoch 393/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0029 - accuracy: 0.9989\n","Epoch 393: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0028 - accuracy: 0.9989\n","Epoch 394/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0102 - accuracy: 0.9960\n","Epoch 394: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0102 - accuracy: 0.9960\n","Epoch 395/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0352 - accuracy: 0.9871\n","Epoch 395: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0350 - accuracy: 0.9872\n","Epoch 396/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0275 - accuracy: 0.9901\n","Epoch 396: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0274 - accuracy: 0.9901\n","Epoch 397/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0321 - accuracy: 0.9887\n","Epoch 397: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0320 - accuracy: 0.9886\n","Epoch 398/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0143 - accuracy: 0.9942\n","Epoch 398: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0145 - accuracy: 0.9941\n","Epoch 399/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0081 - accuracy: 0.9967\n","Epoch 399: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0081 - accuracy: 0.9967\n","Epoch 400/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0045 - accuracy: 0.9983\n","Epoch 400: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0045 - accuracy: 0.9983\n","Epoch 401/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0040 - accuracy: 0.9985\n","Epoch 401: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0040 - accuracy: 0.9985\n","Epoch 402/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0033 - accuracy: 0.9987\n","Epoch 402: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0033 - accuracy: 0.9987\n","Epoch 403/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0028 - accuracy: 0.9991\n","Epoch 403: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0028 - accuracy: 0.9990\n","Epoch 404/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0032 - accuracy: 0.9986\n","Epoch 404: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0032 - accuracy: 0.9986\n","Epoch 405/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0024 - accuracy: 0.9991\n","Epoch 405: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0025 - accuracy: 0.9991\n","Epoch 406/1000\n","380/387 [============================>.] - ETA: 0s - loss: 0.0541 - accuracy: 0.9827\n","Epoch 406: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0535 - accuracy: 0.9829\n","Epoch 407/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0265 - accuracy: 0.9898\n","Epoch 407: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0264 - accuracy: 0.9898\n","Epoch 408/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0155 - accuracy: 0.9940\n","Epoch 408: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0155 - accuracy: 0.9940\n","Epoch 409/1000\n","380/387 [============================>.] - ETA: 0s - loss: 0.0127 - accuracy: 0.9946\n","Epoch 409: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0126 - accuracy: 0.9947\n","Epoch 410/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0072 - accuracy: 0.9969\n","Epoch 410: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0071 - accuracy: 0.9969\n","Epoch 411/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0054 - accuracy: 0.9978\n","Epoch 411: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0055 - accuracy: 0.9978\n","Epoch 412/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0049 - accuracy: 0.9981\n","Epoch 412: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0050 - accuracy: 0.9981\n","Epoch 413/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0029 - accuracy: 0.9990\n","Epoch 413: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0029 - accuracy: 0.9990\n","Epoch 414/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0023 - accuracy: 0.9992\n","Epoch 414: accuracy improved from 0.99915 to 0.99925, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0023 - accuracy: 0.9993\n","Epoch 415/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0022 - accuracy: 0.9992\n","Epoch 415: accuracy did not improve from 0.99925\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0022 - accuracy: 0.9992\n","Epoch 416/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0141 - accuracy: 0.9955\n","Epoch 416: accuracy did not improve from 0.99925\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0142 - accuracy: 0.9955\n","Epoch 417/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0510 - accuracy: 0.9829\n","Epoch 417: accuracy did not improve from 0.99925\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0510 - accuracy: 0.9829\n","Epoch 418/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0271 - accuracy: 0.9897\n","Epoch 418: accuracy did not improve from 0.99925\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0271 - accuracy: 0.9897\n","Epoch 419/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0174 - accuracy: 0.9926\n","Epoch 419: accuracy did not improve from 0.99925\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0174 - accuracy: 0.9926\n","Epoch 420/1000\n","380/387 [============================>.] - ETA: 0s - loss: 0.0134 - accuracy: 0.9946\n","Epoch 420: accuracy did not improve from 0.99925\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0135 - accuracy: 0.9946\n","Epoch 421/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0075 - accuracy: 0.9969\n","Epoch 421: accuracy did not improve from 0.99925\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0075 - accuracy: 0.9969\n","Epoch 422/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0046 - accuracy: 0.9983\n","Epoch 422: accuracy did not improve from 0.99925\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0047 - accuracy: 0.9982\n","Epoch 423/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0066 - accuracy: 0.9975\n","Epoch 423: accuracy did not improve from 0.99925\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0066 - accuracy: 0.9975\n","Epoch 424/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0041 - accuracy: 0.9985\n","Epoch 424: accuracy did not improve from 0.99925\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0041 - accuracy: 0.9985\n","Epoch 425/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0098 - accuracy: 0.9961\n","Epoch 425: accuracy did not improve from 0.99925\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0100 - accuracy: 0.9960\n","Epoch 426/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0311 - accuracy: 0.9888\n","Epoch 426: accuracy did not improve from 0.99925\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0310 - accuracy: 0.9888\n","Epoch 427/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0207 - accuracy: 0.9922\n","Epoch 427: accuracy did not improve from 0.99925\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0207 - accuracy: 0.9922\n","Epoch 428/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0148 - accuracy: 0.9946\n","Epoch 428: accuracy did not improve from 0.99925\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0147 - accuracy: 0.9946\n","Epoch 429/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0069 - accuracy: 0.9973\n","Epoch 429: accuracy did not improve from 0.99925\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0068 - accuracy: 0.9973\n","Epoch 430/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0036 - accuracy: 0.9988\n","Epoch 430: accuracy did not improve from 0.99925\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0036 - accuracy: 0.9988\n","Epoch 431/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0033 - accuracy: 0.9986\n","Epoch 431: accuracy did not improve from 0.99925\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0033 - accuracy: 0.9986\n","Epoch 432/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0026 - accuracy: 0.9991\n","Epoch 432: accuracy did not improve from 0.99925\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0026 - accuracy: 0.9991\n","Epoch 433/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0020 - accuracy: 0.9994\n","Epoch 433: accuracy improved from 0.99925 to 0.99939, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0020 - accuracy: 0.9994\n","Epoch 434/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0024 - accuracy: 0.9991\n","Epoch 434: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0024 - accuracy: 0.9991\n","Epoch 435/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0541 - accuracy: 0.9832\n","Epoch 435: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0544 - accuracy: 0.9832\n","Epoch 436/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0270 - accuracy: 0.9893\n","Epoch 436: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0267 - accuracy: 0.9893\n","Epoch 437/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0127 - accuracy: 0.9947\n","Epoch 437: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0126 - accuracy: 0.9947\n","Epoch 438/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0075 - accuracy: 0.9967\n","Epoch 438: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0075 - accuracy: 0.9967\n","Epoch 439/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0041 - accuracy: 0.9982\n","Epoch 439: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0041 - accuracy: 0.9982\n","Epoch 440/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0027 - accuracy: 0.9990\n","Epoch 440: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0027 - accuracy: 0.9990\n","Epoch 441/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 0.9992\n","Epoch 441: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0021 - accuracy: 0.9993\n","Epoch 442/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 0.9993\n","Epoch 442: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0021 - accuracy: 0.9993\n","Epoch 443/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0179 - accuracy: 0.9937\n","Epoch 443: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0179 - accuracy: 0.9937\n","Epoch 444/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0174 - accuracy: 0.9932\n","Epoch 444: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0174 - accuracy: 0.9932\n","Epoch 445/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0202 - accuracy: 0.9926\n","Epoch 445: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0202 - accuracy: 0.9926\n","Epoch 446/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0129 - accuracy: 0.9949\n","Epoch 446: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0136 - accuracy: 0.9946\n","Epoch 447/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0104 - accuracy: 0.9960\n","Epoch 447: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0104 - accuracy: 0.9961\n","Epoch 448/1000\n","380/387 [============================>.] - ETA: 0s - loss: 0.0077 - accuracy: 0.9969\n","Epoch 448: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0076 - accuracy: 0.9969\n","Epoch 449/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0066 - accuracy: 0.9973\n","Epoch 449: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0066 - accuracy: 0.9973\n","Epoch 450/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0073 - accuracy: 0.9970\n","Epoch 450: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0075 - accuracy: 0.9970\n","Epoch 451/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0306 - accuracy: 0.9896\n","Epoch 451: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0306 - accuracy: 0.9896\n","Epoch 452/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0104 - accuracy: 0.9957\n","Epoch 452: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0103 - accuracy: 0.9957\n","Epoch 453/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0055 - accuracy: 0.9978\n","Epoch 453: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0055 - accuracy: 0.9978\n","Epoch 454/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0049 - accuracy: 0.9978\n","Epoch 454: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0049 - accuracy: 0.9978\n","Epoch 455/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0030 - accuracy: 0.9990\n","Epoch 455: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0030 - accuracy: 0.9989\n","Epoch 456/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0060 - accuracy: 0.9982\n","Epoch 456: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0060 - accuracy: 0.9982\n","Epoch 457/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0209 - accuracy: 0.9927\n","Epoch 457: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0207 - accuracy: 0.9927\n","Epoch 458/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0152 - accuracy: 0.9941\n","Epoch 458: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0152 - accuracy: 0.9941\n","Epoch 459/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0161 - accuracy: 0.9941\n","Epoch 459: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0162 - accuracy: 0.9942\n","Epoch 460/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0187 - accuracy: 0.9931\n","Epoch 460: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0187 - accuracy: 0.9931\n","Epoch 461/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0081 - accuracy: 0.9967\n","Epoch 461: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0081 - accuracy: 0.9967\n","Epoch 462/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0054 - accuracy: 0.9979\n","Epoch 462: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0053 - accuracy: 0.9980\n","Epoch 463/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0039 - accuracy: 0.9986\n","Epoch 463: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0038 - accuracy: 0.9986\n","Epoch 464/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0025 - accuracy: 0.9991\n","Epoch 464: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0024 - accuracy: 0.9991\n","Epoch 465/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 0.9992\n","Epoch 465: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0021 - accuracy: 0.9992\n","Epoch 466/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0209 - accuracy: 0.9929\n","Epoch 466: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0209 - accuracy: 0.9929\n","Epoch 467/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0361 - accuracy: 0.9874\n","Epoch 467: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0366 - accuracy: 0.9874\n","Epoch 468/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0149 - accuracy: 0.9936\n","Epoch 468: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0149 - accuracy: 0.9937\n","Epoch 469/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0129 - accuracy: 0.9950\n","Epoch 469: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0129 - accuracy: 0.9950\n","Epoch 470/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0070 - accuracy: 0.9974\n","Epoch 470: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0069 - accuracy: 0.9975\n","Epoch 471/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0040 - accuracy: 0.9984\n","Epoch 471: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0039 - accuracy: 0.9984\n","Epoch 472/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0026 - accuracy: 0.9992\n","Epoch 472: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0026 - accuracy: 0.9992\n","Epoch 473/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0028 - accuracy: 0.9991\n","Epoch 473: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0028 - accuracy: 0.9991\n","Epoch 474/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0024 - accuracy: 0.9992\n","Epoch 474: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0024 - accuracy: 0.9992\n","Epoch 475/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0032 - accuracy: 0.9989\n","Epoch 475: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0032 - accuracy: 0.9989\n","Epoch 476/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0342 - accuracy: 0.9891\n","Epoch 476: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0342 - accuracy: 0.9891\n","Epoch 477/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0321 - accuracy: 0.9897\n","Epoch 477: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0320 - accuracy: 0.9897\n","Epoch 478/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0105 - accuracy: 0.9958\n","Epoch 478: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0105 - accuracy: 0.9958\n","Epoch 479/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0053 - accuracy: 0.9981\n","Epoch 479: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0053 - accuracy: 0.9981\n","Epoch 480/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0034 - accuracy: 0.9987\n","Epoch 480: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0033 - accuracy: 0.9987\n","Epoch 481/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0026 - accuracy: 0.9991\n","Epoch 481: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0027 - accuracy: 0.9991\n","Epoch 482/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0024 - accuracy: 0.9993\n","Epoch 482: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0024 - accuracy: 0.9993\n","Epoch 483/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0084 - accuracy: 0.9970\n","Epoch 483: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0085 - accuracy: 0.9968\n","Epoch 484/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0265 - accuracy: 0.9909\n","Epoch 484: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0265 - accuracy: 0.9909\n","Epoch 485/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0261 - accuracy: 0.9903\n","Epoch 485: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0260 - accuracy: 0.9904\n","Epoch 486/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0121 - accuracy: 0.9951\n","Epoch 486: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0121 - accuracy: 0.9951\n","Epoch 487/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0083 - accuracy: 0.9967\n","Epoch 487: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0083 - accuracy: 0.9967\n","Epoch 488/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0091 - accuracy: 0.9969\n","Epoch 488: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0093 - accuracy: 0.9969\n","Epoch 489/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0064 - accuracy: 0.9973\n","Epoch 489: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0064 - accuracy: 0.9973\n","Epoch 490/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0113 - accuracy: 0.9964\n","Epoch 490: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0115 - accuracy: 0.9964\n","Epoch 491/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0068 - accuracy: 0.9974\n","Epoch 491: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0068 - accuracy: 0.9974\n","Epoch 492/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0035 - accuracy: 0.9986\n","Epoch 492: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0035 - accuracy: 0.9986\n","Epoch 493/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0028 - accuracy: 0.9991\n","Epoch 493: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0028 - accuracy: 0.9991\n","Epoch 494/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0033 - accuracy: 0.9987\n","Epoch 494: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0033 - accuracy: 0.9987\n","Epoch 495/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0103 - accuracy: 0.9968\n","Epoch 495: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0113 - accuracy: 0.9965\n","Epoch 496/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0428 - accuracy: 0.9858\n","Epoch 496: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0433 - accuracy: 0.9858\n","Epoch 497/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0100 - accuracy: 0.9957\n","Epoch 497: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0102 - accuracy: 0.9957\n","Epoch 498/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0069 - accuracy: 0.9971\n","Epoch 498: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0069 - accuracy: 0.9970\n","Epoch 499/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0047 - accuracy: 0.9984\n","Epoch 499: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0047 - accuracy: 0.9984\n","Epoch 500/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 0.9990\n","Epoch 500: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0031 - accuracy: 0.9990\n","Epoch 501/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0024 - accuracy: 0.9993\n","Epoch 501: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0024 - accuracy: 0.9993\n","Epoch 502/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0019 - accuracy: 0.9994\n","Epoch 502: accuracy improved from 0.99939 to 0.99941, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0019 - accuracy: 0.9994\n","Epoch 503/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0155 - accuracy: 0.9954\n","Epoch 503: accuracy did not improve from 0.99941\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0155 - accuracy: 0.9954\n","Epoch 504/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0407 - accuracy: 0.9877\n","Epoch 504: accuracy did not improve from 0.99941\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0418 - accuracy: 0.9877\n","Epoch 505/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0251 - accuracy: 0.9901\n","Epoch 505: accuracy did not improve from 0.99941\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0250 - accuracy: 0.9901\n","Epoch 506/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0076 - accuracy: 0.9972\n","Epoch 506: accuracy did not improve from 0.99941\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0076 - accuracy: 0.9971\n","Epoch 507/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0043 - accuracy: 0.9983\n","Epoch 507: accuracy did not improve from 0.99941\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0042 - accuracy: 0.9983\n","Epoch 508/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0028 - accuracy: 0.9991\n","Epoch 508: accuracy did not improve from 0.99941\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0028 - accuracy: 0.9991\n","Epoch 509/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0022 - accuracy: 0.9992\n","Epoch 509: accuracy did not improve from 0.99941\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0023 - accuracy: 0.9992\n","Epoch 510/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 0.9993\n","Epoch 510: accuracy did not improve from 0.99941\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0021 - accuracy: 0.9993\n","Epoch 511/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0040 - accuracy: 0.9986\n","Epoch 511: accuracy did not improve from 0.99941\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0040 - accuracy: 0.9986\n","Epoch 512/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0093 - accuracy: 0.9964\n","Epoch 512: accuracy did not improve from 0.99941\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0093 - accuracy: 0.9964\n","Epoch 513/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0279 - accuracy: 0.9912\n","Epoch 513: accuracy did not improve from 0.99941\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0282 - accuracy: 0.9912\n","Epoch 514/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0246 - accuracy: 0.9912\n","Epoch 514: accuracy did not improve from 0.99941\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0245 - accuracy: 0.9912\n","Epoch 515/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0182 - accuracy: 0.9934\n","Epoch 515: accuracy did not improve from 0.99941\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0182 - accuracy: 0.9934\n","Epoch 516/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0129 - accuracy: 0.9953\n","Epoch 516: accuracy did not improve from 0.99941\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0128 - accuracy: 0.9953\n","Epoch 517/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0055 - accuracy: 0.9982\n","Epoch 517: accuracy did not improve from 0.99941\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0055 - accuracy: 0.9982\n","Epoch 518/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0048 - accuracy: 0.9983\n","Epoch 518: accuracy did not improve from 0.99941\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0048 - accuracy: 0.9983\n","Epoch 519/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0029 - accuracy: 0.9991\n","Epoch 519: accuracy did not improve from 0.99941\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0029 - accuracy: 0.9991\n","Epoch 520/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0023 - accuracy: 0.9993\n","Epoch 520: accuracy did not improve from 0.99941\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0024 - accuracy: 0.9993\n","Epoch 521/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 0.9994\n","Epoch 521: accuracy did not improve from 0.99941\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0021 - accuracy: 0.9994\n","Epoch 522/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 0.9993\n","Epoch 522: accuracy did not improve from 0.99941\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0027 - accuracy: 0.9993\n","Epoch 523/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0217 - accuracy: 0.9938\n","Epoch 523: accuracy did not improve from 0.99941\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0224 - accuracy: 0.9936\n","Epoch 524/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0428 - accuracy: 0.9874\n","Epoch 524: accuracy did not improve from 0.99941\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0424 - accuracy: 0.9875\n","Epoch 525/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0129 - accuracy: 0.9949\n","Epoch 525: accuracy did not improve from 0.99941\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0128 - accuracy: 0.9949\n","Epoch 526/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0073 - accuracy: 0.9972\n","Epoch 526: accuracy did not improve from 0.99941\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0072 - accuracy: 0.9972\n","Epoch 527/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0057 - accuracy: 0.9980\n","Epoch 527: accuracy did not improve from 0.99941\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0057 - accuracy: 0.9980\n","Epoch 528/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0043 - accuracy: 0.9985\n","Epoch 528: accuracy did not improve from 0.99941\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0043 - accuracy: 0.9985\n","Epoch 529/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0031 - accuracy: 0.9989\n","Epoch 529: accuracy did not improve from 0.99941\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0031 - accuracy: 0.9989\n","Epoch 530/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 0.9994\n","Epoch 530: accuracy did not improve from 0.99941\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0022 - accuracy: 0.9994\n","Epoch 531/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0028 - accuracy: 0.9990\n","Epoch 531: accuracy did not improve from 0.99941\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0028 - accuracy: 0.9990\n","Epoch 532/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0019 - accuracy: 0.9995\n","Epoch 532: accuracy improved from 0.99941 to 0.99949, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0019 - accuracy: 0.9995\n","Epoch 533/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0037 - accuracy: 0.9988\n","Epoch 533: accuracy did not improve from 0.99949\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0041 - accuracy: 0.9986\n","Epoch 534/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0447 - accuracy: 0.9872\n","Epoch 534: accuracy did not improve from 0.99949\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0448 - accuracy: 0.9870\n","Epoch 535/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0189 - accuracy: 0.9929\n","Epoch 535: accuracy did not improve from 0.99949\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0197 - accuracy: 0.9928\n","Epoch 536/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0145 - accuracy: 0.9945\n","Epoch 536: accuracy did not improve from 0.99949\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0145 - accuracy: 0.9945\n","Epoch 537/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0056 - accuracy: 0.9980\n","Epoch 537: accuracy did not improve from 0.99949\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0056 - accuracy: 0.9980\n","Epoch 538/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0034 - accuracy: 0.9988\n","Epoch 538: accuracy did not improve from 0.99949\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0034 - accuracy: 0.9988\n","Epoch 539/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0025 - accuracy: 0.9991\n","Epoch 539: accuracy did not improve from 0.99949\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0025 - accuracy: 0.9991\n","Epoch 540/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0022 - accuracy: 0.9993\n","Epoch 540: accuracy did not improve from 0.99949\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0022 - accuracy: 0.9993\n","Epoch 541/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0019 - accuracy: 0.9994\n","Epoch 541: accuracy did not improve from 0.99949\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0019 - accuracy: 0.9994\n","Epoch 542/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0030 - accuracy: 0.9990\n","Epoch 542: accuracy did not improve from 0.99949\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0030 - accuracy: 0.9990\n","Epoch 543/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0158 - accuracy: 0.9949\n","Epoch 543: accuracy did not improve from 0.99949\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0159 - accuracy: 0.9949\n","Epoch 544/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0375 - accuracy: 0.9877\n","Epoch 544: accuracy did not improve from 0.99949\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0373 - accuracy: 0.9878\n","Epoch 545/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0127 - accuracy: 0.9950\n","Epoch 545: accuracy did not improve from 0.99949\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0127 - accuracy: 0.9950\n","Epoch 546/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0136 - accuracy: 0.9948\n","Epoch 546: accuracy did not improve from 0.99949\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0137 - accuracy: 0.9947\n","Epoch 547/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0079 - accuracy: 0.9969\n","Epoch 547: accuracy did not improve from 0.99949\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0079 - accuracy: 0.9969\n","Epoch 548/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0040 - accuracy: 0.9986\n","Epoch 548: accuracy did not improve from 0.99949\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0040 - accuracy: 0.9986\n","Epoch 549/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0024 - accuracy: 0.9991\n","Epoch 549: accuracy did not improve from 0.99949\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0024 - accuracy: 0.9991\n","Epoch 550/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0020 - accuracy: 0.9993\n","Epoch 550: accuracy did not improve from 0.99949\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0020 - accuracy: 0.9993\n","Epoch 551/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 0.9992\n","Epoch 551: accuracy did not improve from 0.99949\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0021 - accuracy: 0.9992\n","Epoch 552/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0018 - accuracy: 0.9995\n","Epoch 552: accuracy did not improve from 0.99949\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0018 - accuracy: 0.9995\n","Epoch 553/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0129 - accuracy: 0.9964\n","Epoch 553: accuracy did not improve from 0.99949\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0129 - accuracy: 0.9964\n","Epoch 554/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0663 - accuracy: 0.9821\n","Epoch 554: accuracy did not improve from 0.99949\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0662 - accuracy: 0.9821\n","Epoch 555/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0157 - accuracy: 0.9934\n","Epoch 555: accuracy did not improve from 0.99949\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0156 - accuracy: 0.9934\n","Epoch 556/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0078 - accuracy: 0.9968\n","Epoch 556: accuracy did not improve from 0.99949\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0077 - accuracy: 0.9968\n","Epoch 557/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0051 - accuracy: 0.9978\n","Epoch 557: accuracy did not improve from 0.99949\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0051 - accuracy: 0.9978\n","Epoch 558/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0032 - accuracy: 0.9989\n","Epoch 558: accuracy did not improve from 0.99949\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0033 - accuracy: 0.9989\n","Epoch 559/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0023 - accuracy: 0.9991\n","Epoch 559: accuracy did not improve from 0.99949\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0023 - accuracy: 0.9992\n","Epoch 560/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0019 - accuracy: 0.9993\n","Epoch 560: accuracy did not improve from 0.99949\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0019 - accuracy: 0.9993\n","Epoch 561/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 0.9994\n","Epoch 561: accuracy did not improve from 0.99949\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0018 - accuracy: 0.9994\n","Epoch 562/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0019 - accuracy: 0.9994\n","Epoch 562: accuracy did not improve from 0.99949\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0020 - accuracy: 0.9993\n","Epoch 563/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0232 - accuracy: 0.9932\n","Epoch 563: accuracy did not improve from 0.99949\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0231 - accuracy: 0.9932\n","Epoch 564/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0406 - accuracy: 0.9857\n","Epoch 564: accuracy did not improve from 0.99949\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0408 - accuracy: 0.9857\n","Epoch 565/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0141 - accuracy: 0.9945\n","Epoch 565: accuracy did not improve from 0.99949\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0141 - accuracy: 0.9946\n","Epoch 566/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0055 - accuracy: 0.9981\n","Epoch 566: accuracy did not improve from 0.99949\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0055 - accuracy: 0.9981\n","Epoch 567/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0034 - accuracy: 0.9989\n","Epoch 567: accuracy did not improve from 0.99949\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0034 - accuracy: 0.9989\n","Epoch 568/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0026 - accuracy: 0.9991\n","Epoch 568: accuracy did not improve from 0.99949\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0026 - accuracy: 0.9991\n","Epoch 569/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 0.9993\n","Epoch 569: accuracy did not improve from 0.99949\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0021 - accuracy: 0.9993\n","Epoch 570/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0019 - accuracy: 0.9994\n","Epoch 570: accuracy did not improve from 0.99949\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0019 - accuracy: 0.9994\n","Epoch 571/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0017 - accuracy: 0.9996\n","Epoch 571: accuracy improved from 0.99949 to 0.99956, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0017 - accuracy: 0.9996\n","Epoch 572/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0024 - accuracy: 0.9993\n","Epoch 572: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0024 - accuracy: 0.9993\n","Epoch 573/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0090 - accuracy: 0.9973\n","Epoch 573: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0090 - accuracy: 0.9973\n","Epoch 574/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0450 - accuracy: 0.9863\n","Epoch 574: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0446 - accuracy: 0.9864\n","Epoch 575/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0186 - accuracy: 0.9929\n","Epoch 575: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0186 - accuracy: 0.9928\n","Epoch 576/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0122 - accuracy: 0.9954\n","Epoch 576: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0122 - accuracy: 0.9954\n","Epoch 577/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0061 - accuracy: 0.9976\n","Epoch 577: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0061 - accuracy: 0.9976\n","Epoch 578/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0121 - accuracy: 0.9956\n","Epoch 578: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0121 - accuracy: 0.9956\n","Epoch 579/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0121 - accuracy: 0.9952\n","Epoch 579: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0121 - accuracy: 0.9952\n","Epoch 580/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0065 - accuracy: 0.9971\n","Epoch 580: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0065 - accuracy: 0.9971\n","Epoch 581/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0068 - accuracy: 0.9971\n","Epoch 581: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0068 - accuracy: 0.9971\n","Epoch 582/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0061 - accuracy: 0.9978\n","Epoch 582: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0061 - accuracy: 0.9978\n","Epoch 583/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0037 - accuracy: 0.9986\n","Epoch 583: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0037 - accuracy: 0.9986\n","Epoch 584/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0024 - accuracy: 0.9991\n","Epoch 584: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0024 - accuracy: 0.9992\n","Epoch 585/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0023 - accuracy: 0.9992\n","Epoch 585: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0023 - accuracy: 0.9992\n","Epoch 586/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0019 - accuracy: 0.9993\n","Epoch 586: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0020 - accuracy: 0.9993\n","Epoch 587/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0019 - accuracy: 0.9994\n","Epoch 587: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0019 - accuracy: 0.9994\n","Epoch 588/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0361 - accuracy: 0.9886\n","Epoch 588: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0361 - accuracy: 0.9886\n","Epoch 589/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0231 - accuracy: 0.9916\n","Epoch 589: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0231 - accuracy: 0.9916\n","Epoch 590/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0102 - accuracy: 0.9959\n","Epoch 590: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0104 - accuracy: 0.9958\n","Epoch 591/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0038 - accuracy: 0.9986\n","Epoch 591: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0038 - accuracy: 0.9986\n","Epoch 592/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0024 - accuracy: 0.9992\n","Epoch 592: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0024 - accuracy: 0.9992\n","Epoch 593/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 0.9993\n","Epoch 593: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0020 - accuracy: 0.9993\n","Epoch 594/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0019 - accuracy: 0.9994\n","Epoch 594: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0019 - accuracy: 0.9994\n","Epoch 595/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0017 - accuracy: 0.9994\n","Epoch 595: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0017 - accuracy: 0.9995\n","Epoch 596/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0017 - accuracy: 0.9993\n","Epoch 596: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0017 - accuracy: 0.9993\n","Epoch 597/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0237 - accuracy: 0.9924\n","Epoch 597: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0236 - accuracy: 0.9924\n","Epoch 598/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0315 - accuracy: 0.9900\n","Epoch 598: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0334 - accuracy: 0.9899\n","Epoch 599/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0198 - accuracy: 0.9918\n","Epoch 599: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0198 - accuracy: 0.9918\n","Epoch 600/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0100 - accuracy: 0.9957\n","Epoch 600: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0099 - accuracy: 0.9958\n","Epoch 601/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0065 - accuracy: 0.9973\n","Epoch 601: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0065 - accuracy: 0.9973\n","Epoch 602/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0035 - accuracy: 0.9986\n","Epoch 602: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0035 - accuracy: 0.9986\n","Epoch 603/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0030 - accuracy: 0.9987\n","Epoch 603: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0030 - accuracy: 0.9987\n","Epoch 604/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 0.9993\n","Epoch 604: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0021 - accuracy: 0.9993\n","Epoch 605/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0017 - accuracy: 0.9995\n","Epoch 605: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0016 - accuracy: 0.9995\n","Epoch 606/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0017 - accuracy: 0.9995\n","Epoch 606: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0017 - accuracy: 0.9995\n","Epoch 607/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0029 - accuracy: 0.9989\n","Epoch 607: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0028 - accuracy: 0.9989\n","Epoch 608/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0319 - accuracy: 0.9916\n","Epoch 608: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0317 - accuracy: 0.9916\n","Epoch 609/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0244 - accuracy: 0.9912\n","Epoch 609: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0244 - accuracy: 0.9912\n","Epoch 610/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0112 - accuracy: 0.9955\n","Epoch 610: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0112 - accuracy: 0.9954\n","Epoch 611/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0048 - accuracy: 0.9983\n","Epoch 611: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0048 - accuracy: 0.9983\n","Epoch 612/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0028 - accuracy: 0.9990\n","Epoch 612: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0028 - accuracy: 0.9990\n","Epoch 613/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0022 - accuracy: 0.9993\n","Epoch 613: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0022 - accuracy: 0.9993\n","Epoch 614/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0019 - accuracy: 0.9994\n","Epoch 614: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0019 - accuracy: 0.9994\n","Epoch 615/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0016 - accuracy: 0.9996\n","Epoch 615: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0016 - accuracy: 0.9996\n","Epoch 616/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 0.9996\n","Epoch 616: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0015 - accuracy: 0.9996\n","Epoch 617/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0415 - accuracy: 0.9877\n","Epoch 617: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0415 - accuracy: 0.9877\n","Epoch 618/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0302 - accuracy: 0.9903\n","Epoch 618: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0302 - accuracy: 0.9902\n","Epoch 619/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0165 - accuracy: 0.9935\n","Epoch 619: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0165 - accuracy: 0.9935\n","Epoch 620/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0072 - accuracy: 0.9970\n","Epoch 620: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0072 - accuracy: 0.9970\n","Epoch 621/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0040 - accuracy: 0.9984\n","Epoch 621: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0040 - accuracy: 0.9984\n","Epoch 622/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0028 - accuracy: 0.9991\n","Epoch 622: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0028 - accuracy: 0.9991\n","Epoch 623/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 0.9993\n","Epoch 623: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0021 - accuracy: 0.9993\n","Epoch 624/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 0.9995\n","Epoch 624: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0017 - accuracy: 0.9995\n","Epoch 625/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 0.9995\n","Epoch 625: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0015 - accuracy: 0.9995\n","Epoch 626/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0018 - accuracy: 0.9995\n","Epoch 626: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0017 - accuracy: 0.9995\n","Epoch 627/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0026 - accuracy: 0.9992\n","Epoch 627: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0025 - accuracy: 0.9992\n","Epoch 628/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0130 - accuracy: 0.9965\n","Epoch 628: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0130 - accuracy: 0.9965\n","Epoch 629/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0511 - accuracy: 0.9845\n","Epoch 629: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0518 - accuracy: 0.9845\n","Epoch 630/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0128 - accuracy: 0.9951\n","Epoch 630: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0128 - accuracy: 0.9950\n","Epoch 631/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0066 - accuracy: 0.9975\n","Epoch 631: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0066 - accuracy: 0.9975\n","Epoch 632/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0033 - accuracy: 0.9989\n","Epoch 632: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0033 - accuracy: 0.9989\n","Epoch 633/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0024 - accuracy: 0.9993\n","Epoch 633: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0024 - accuracy: 0.9993\n","Epoch 634/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0019 - accuracy: 0.9993\n","Epoch 634: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0019 - accuracy: 0.9993\n","Epoch 635/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0018 - accuracy: 0.9995\n","Epoch 635: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0018 - accuracy: 0.9995\n","Epoch 636/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0016 - accuracy: 0.9995\n","Epoch 636: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0016 - accuracy: 0.9995\n","Epoch 637/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0018 - accuracy: 0.9994\n","Epoch 637: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0018 - accuracy: 0.9994\n","Epoch 638/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0252 - accuracy: 0.9912\n","Epoch 638: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0253 - accuracy: 0.9912\n","Epoch 639/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0347 - accuracy: 0.9883\n","Epoch 639: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0346 - accuracy: 0.9883\n","Epoch 640/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0136 - accuracy: 0.9944\n","Epoch 640: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0139 - accuracy: 0.9942\n","Epoch 641/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0095 - accuracy: 0.9964\n","Epoch 641: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0101 - accuracy: 0.9964\n","Epoch 642/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0068 - accuracy: 0.9974\n","Epoch 642: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0068 - accuracy: 0.9974\n","Epoch 643/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0036 - accuracy: 0.9987\n","Epoch 643: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0036 - accuracy: 0.9987\n","Epoch 644/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0025 - accuracy: 0.9991\n","Epoch 644: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0025 - accuracy: 0.9992\n","Epoch 645/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0019 - accuracy: 0.9993\n","Epoch 645: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0019 - accuracy: 0.9993\n","Epoch 646/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0018 - accuracy: 0.9995\n","Epoch 646: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0018 - accuracy: 0.9995\n","Epoch 647/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0100 - accuracy: 0.9964\n","Epoch 647: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0100 - accuracy: 0.9964\n","Epoch 648/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0241 - accuracy: 0.9917\n","Epoch 648: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0241 - accuracy: 0.9917\n","Epoch 649/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0118 - accuracy: 0.9953\n","Epoch 649: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0118 - accuracy: 0.9953\n","Epoch 650/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0094 - accuracy: 0.9963\n","Epoch 650: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0095 - accuracy: 0.9963\n","Epoch 651/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0051 - accuracy: 0.9982\n","Epoch 651: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0051 - accuracy: 0.9982\n","Epoch 652/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0031 - accuracy: 0.9989\n","Epoch 652: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0031 - accuracy: 0.9989\n","Epoch 653/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0022 - accuracy: 0.9994\n","Epoch 653: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0022 - accuracy: 0.9994\n","Epoch 654/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0019 - accuracy: 0.9994\n","Epoch 654: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0019 - accuracy: 0.9994\n","Epoch 655/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0017 - accuracy: 0.9995\n","Epoch 655: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0017 - accuracy: 0.9995\n","Epoch 656/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0016 - accuracy: 0.9996\n","Epoch 656: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0016 - accuracy: 0.9996\n","Epoch 657/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0325 - accuracy: 0.9903\n","Epoch 657: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0329 - accuracy: 0.9903\n","Epoch 658/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0344 - accuracy: 0.9877\n","Epoch 658: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0344 - accuracy: 0.9877\n","Epoch 659/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0127 - accuracy: 0.9948\n","Epoch 659: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0126 - accuracy: 0.9948\n","Epoch 660/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0098 - accuracy: 0.9965\n","Epoch 660: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0097 - accuracy: 0.9965\n","Epoch 661/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0043 - accuracy: 0.9983\n","Epoch 661: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0043 - accuracy: 0.9983\n","Epoch 662/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0024 - accuracy: 0.9991\n","Epoch 662: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0024 - accuracy: 0.9992\n","Epoch 663/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 0.9994\n","Epoch 663: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0020 - accuracy: 0.9994\n","Epoch 664/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0017 - accuracy: 0.9994\n","Epoch 664: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0017 - accuracy: 0.9994\n","Epoch 665/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0017 - accuracy: 0.9994\n","Epoch 665: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0017 - accuracy: 0.9994\n","Epoch 666/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0016 - accuracy: 0.9994\n","Epoch 666: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0016 - accuracy: 0.9994\n","Epoch 667/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0017 - accuracy: 0.9995\n","Epoch 667: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0017 - accuracy: 0.9994\n","Epoch 668/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0397 - accuracy: 0.9883\n","Epoch 668: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0395 - accuracy: 0.9884\n","Epoch 669/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0301 - accuracy: 0.9901\n","Epoch 669: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0301 - accuracy: 0.9902\n","Epoch 670/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0160 - accuracy: 0.9937\n","Epoch 670: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0159 - accuracy: 0.9937\n","Epoch 671/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0062 - accuracy: 0.9976\n","Epoch 671: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0062 - accuracy: 0.9976\n","Epoch 672/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0032 - accuracy: 0.9988\n","Epoch 672: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0032 - accuracy: 0.9987\n","Epoch 673/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0022 - accuracy: 0.9992\n","Epoch 673: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0022 - accuracy: 0.9992\n","Epoch 674/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 0.9994\n","Epoch 674: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0018 - accuracy: 0.9994\n","Epoch 675/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 0.9995\n","Epoch 675: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0016 - accuracy: 0.9995\n","Epoch 676/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 0.9996\n","Epoch 676: accuracy improved from 0.99956 to 0.99962, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0015 - accuracy: 0.9996\n","Epoch 677/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0023 - accuracy: 0.9991\n","Epoch 677: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0023 - accuracy: 0.9992\n","Epoch 678/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0162 - accuracy: 0.9955\n","Epoch 678: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0163 - accuracy: 0.9954\n","Epoch 679/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0244 - accuracy: 0.9913\n","Epoch 679: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0241 - accuracy: 0.9914\n","Epoch 680/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0095 - accuracy: 0.9960\n","Epoch 680: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0096 - accuracy: 0.9959\n","Epoch 681/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0058 - accuracy: 0.9978\n","Epoch 681: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0058 - accuracy: 0.9978\n","Epoch 682/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0179 - accuracy: 0.9937\n","Epoch 682: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0179 - accuracy: 0.9937\n","Epoch 683/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0122 - accuracy: 0.9951\n","Epoch 683: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0128 - accuracy: 0.9951\n","Epoch 684/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0082 - accuracy: 0.9964\n","Epoch 684: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0082 - accuracy: 0.9964\n","Epoch 685/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0038 - accuracy: 0.9984\n","Epoch 685: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0038 - accuracy: 0.9984\n","Epoch 686/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0023 - accuracy: 0.9991\n","Epoch 686: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0022 - accuracy: 0.9992\n","Epoch 687/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 0.9994\n","Epoch 687: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0019 - accuracy: 0.9994\n","Epoch 688/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 0.9994\n","Epoch 688: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0018 - accuracy: 0.9994\n","Epoch 689/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 0.9995\n","Epoch 689: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0015 - accuracy: 0.9995\n","Epoch 690/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 0.9996\n","Epoch 690: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0015 - accuracy: 0.9996\n","Epoch 691/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0022 - accuracy: 0.9994\n","Epoch 691: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0022 - accuracy: 0.9994\n","Epoch 692/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0115 - accuracy: 0.9964\n","Epoch 692: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0115 - accuracy: 0.9964\n","Epoch 693/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0363 - accuracy: 0.9877\n","Epoch 693: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0361 - accuracy: 0.9877\n","Epoch 694/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0178 - accuracy: 0.9943\n","Epoch 694: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0177 - accuracy: 0.9943\n","Epoch 695/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0053 - accuracy: 0.9978\n","Epoch 695: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0053 - accuracy: 0.9978\n","Epoch 696/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0030 - accuracy: 0.9988\n","Epoch 696: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0030 - accuracy: 0.9988\n","Epoch 697/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 0.9992\n","Epoch 697: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0021 - accuracy: 0.9992\n","Epoch 698/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0017 - accuracy: 0.9994\n","Epoch 698: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0017 - accuracy: 0.9994\n","Epoch 699/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0019 - accuracy: 0.9993\n","Epoch 699: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0018 - accuracy: 0.9993\n","Epoch 700/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0022 - accuracy: 0.9993\n","Epoch 700: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0021 - accuracy: 0.9993\n","Epoch 701/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0268 - accuracy: 0.9924\n","Epoch 701: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0271 - accuracy: 0.9922\n","Epoch 702/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0317 - accuracy: 0.9894\n","Epoch 702: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0314 - accuracy: 0.9894\n","Epoch 703/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0083 - accuracy: 0.9967\n","Epoch 703: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0082 - accuracy: 0.9967\n","Epoch 704/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0073 - accuracy: 0.9972\n","Epoch 704: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0073 - accuracy: 0.9972\n","Epoch 705/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0050 - accuracy: 0.9981\n","Epoch 705: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0050 - accuracy: 0.9981\n","Epoch 706/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0031 - accuracy: 0.9988\n","Epoch 706: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0031 - accuracy: 0.9987\n","Epoch 707/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 0.9993\n","Epoch 707: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0020 - accuracy: 0.9993\n","Epoch 708/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0019 - accuracy: 0.9994\n","Epoch 708: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0020 - accuracy: 0.9993\n","Epoch 709/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0035 - accuracy: 0.9988\n","Epoch 709: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0035 - accuracy: 0.9988\n","Epoch 710/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0257 - accuracy: 0.9914\n","Epoch 710: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0256 - accuracy: 0.9914\n","Epoch 711/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0103 - accuracy: 0.9959\n","Epoch 711: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0103 - accuracy: 0.9959\n","Epoch 712/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0042 - accuracy: 0.9984\n","Epoch 712: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0042 - accuracy: 0.9984\n","Epoch 713/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0027 - accuracy: 0.9990\n","Epoch 713: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0027 - accuracy: 0.9990\n","Epoch 714/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 0.9992\n","Epoch 714: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0021 - accuracy: 0.9992\n","Epoch 715/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0038 - accuracy: 0.9988\n","Epoch 715: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0038 - accuracy: 0.9987\n","Epoch 716/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0097 - accuracy: 0.9968\n","Epoch 716: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0097 - accuracy: 0.9968\n","Epoch 717/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0120 - accuracy: 0.9953\n","Epoch 717: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0118 - accuracy: 0.9953\n","Epoch 718/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0147 - accuracy: 0.9947\n","Epoch 718: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0147 - accuracy: 0.9947\n","Epoch 719/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0195 - accuracy: 0.9935\n","Epoch 719: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0195 - accuracy: 0.9935\n","Epoch 720/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0067 - accuracy: 0.9975\n","Epoch 720: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0067 - accuracy: 0.9975\n","Epoch 721/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0033 - accuracy: 0.9988\n","Epoch 721: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0033 - accuracy: 0.9988\n","Epoch 722/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 0.9992\n","Epoch 722: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0023 - accuracy: 0.9992\n","Epoch 723/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0019 - accuracy: 0.9994\n","Epoch 723: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0019 - accuracy: 0.9994\n","Epoch 724/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0018 - accuracy: 0.9995\n","Epoch 724: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0017 - accuracy: 0.9995\n","Epoch 725/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0017 - accuracy: 0.9995\n","Epoch 725: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0017 - accuracy: 0.9995\n","Epoch 726/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0106 - accuracy: 0.9971\n","Epoch 726: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0113 - accuracy: 0.9970\n","Epoch 727/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0364 - accuracy: 0.9887\n","Epoch 727: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0363 - accuracy: 0.9887\n","Epoch 728/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0198 - accuracy: 0.9927\n","Epoch 728: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0198 - accuracy: 0.9927\n","Epoch 729/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0133 - accuracy: 0.9952\n","Epoch 729: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0132 - accuracy: 0.9952\n","Epoch 730/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0053 - accuracy: 0.9979\n","Epoch 730: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0053 - accuracy: 0.9979\n","Epoch 731/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0032 - accuracy: 0.9988\n","Epoch 731: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0032 - accuracy: 0.9988\n","Epoch 732/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 0.9992\n","Epoch 732: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0021 - accuracy: 0.9993\n","Epoch 733/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0016 - accuracy: 0.9995\n","Epoch 733: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0016 - accuracy: 0.9994\n","Epoch 734/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0016 - accuracy: 0.9996\n","Epoch 734: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0015 - accuracy: 0.9996\n","Epoch 735/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 0.9996\n","Epoch 735: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0013 - accuracy: 0.9996\n","Epoch 736/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 0.9995\n","Epoch 736: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0015 - accuracy: 0.9995\n","Epoch 737/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 0.9995\n","Epoch 737: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0016 - accuracy: 0.9995\n","Epoch 738/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0397 - accuracy: 0.9890\n","Epoch 738: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0397 - accuracy: 0.9890\n","Epoch 739/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0287 - accuracy: 0.9908\n","Epoch 739: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0286 - accuracy: 0.9909\n","Epoch 740/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0118 - accuracy: 0.9957\n","Epoch 740: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0118 - accuracy: 0.9957\n","Epoch 741/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0046 - accuracy: 0.9984\n","Epoch 741: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0046 - accuracy: 0.9984\n","Epoch 742/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0029 - accuracy: 0.9990\n","Epoch 742: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0029 - accuracy: 0.9989\n","Epoch 743/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0022 - accuracy: 0.9991\n","Epoch 743: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0022 - accuracy: 0.9991\n","Epoch 744/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0017 - accuracy: 0.9993\n","Epoch 744: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0017 - accuracy: 0.9993\n","Epoch 745/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0016 - accuracy: 0.9994\n","Epoch 745: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0016 - accuracy: 0.9994\n","Epoch 746/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 0.9992\n","Epoch 746: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0021 - accuracy: 0.9992\n","Epoch 747/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0306 - accuracy: 0.9900\n","Epoch 747: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0305 - accuracy: 0.9899\n","Epoch 748/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0109 - accuracy: 0.9956\n","Epoch 748: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0109 - accuracy: 0.9956\n","Epoch 749/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0082 - accuracy: 0.9971\n","Epoch 749: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0083 - accuracy: 0.9971\n","Epoch 750/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0046 - accuracy: 0.9982\n","Epoch 750: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0046 - accuracy: 0.9982\n","Epoch 751/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0023 - accuracy: 0.9992\n","Epoch 751: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0023 - accuracy: 0.9992\n","Epoch 752/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 0.9994\n","Epoch 752: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0018 - accuracy: 0.9994\n","Epoch 753/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0018 - accuracy: 0.9994\n","Epoch 753: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0018 - accuracy: 0.9994\n","Epoch 754/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0019 - accuracy: 0.9994\n","Epoch 754: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0019 - accuracy: 0.9994\n","Epoch 755/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0103 - accuracy: 0.9974\n","Epoch 755: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0107 - accuracy: 0.9971\n","Epoch 756/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0360 - accuracy: 0.9884\n","Epoch 756: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0360 - accuracy: 0.9884\n","Epoch 757/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0169 - accuracy: 0.9938\n","Epoch 757: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0169 - accuracy: 0.9938\n","Epoch 758/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0065 - accuracy: 0.9975\n","Epoch 758: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0065 - accuracy: 0.9975\n","Epoch 759/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0037 - accuracy: 0.9985\n","Epoch 759: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0037 - accuracy: 0.9985\n","Epoch 760/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0027 - accuracy: 0.9991\n","Epoch 760: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0027 - accuracy: 0.9992\n","Epoch 761/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0023 - accuracy: 0.9993\n","Epoch 761: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0023 - accuracy: 0.9993\n","Epoch 762/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0020 - accuracy: 0.9994\n","Epoch 762: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0020 - accuracy: 0.9994\n","Epoch 763/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 0.9995\n","Epoch 763: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0017 - accuracy: 0.9995\n","Epoch 764/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0017 - accuracy: 0.9995\n","Epoch 764: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0017 - accuracy: 0.9995\n","Epoch 765/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0058 - accuracy: 0.9978\n","Epoch 765: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0060 - accuracy: 0.9978\n","Epoch 766/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0336 - accuracy: 0.9892\n","Epoch 766: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0333 - accuracy: 0.9892\n","Epoch 767/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0147 - accuracy: 0.9947\n","Epoch 767: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0148 - accuracy: 0.9947\n","Epoch 768/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0076 - accuracy: 0.9970\n","Epoch 768: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0076 - accuracy: 0.9970\n","Epoch 769/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0073 - accuracy: 0.9972\n","Epoch 769: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0073 - accuracy: 0.9972\n","Epoch 770/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0053 - accuracy: 0.9980\n","Epoch 770: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0053 - accuracy: 0.9980\n","Epoch 771/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0033 - accuracy: 0.9986\n","Epoch 771: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0033 - accuracy: 0.9986\n","Epoch 772/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0025 - accuracy: 0.9991\n","Epoch 772: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0025 - accuracy: 0.9991\n","Epoch 773/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0019 - accuracy: 0.9994\n","Epoch 773: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0019 - accuracy: 0.9994\n","Epoch 774/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0016 - accuracy: 0.9995\n","Epoch 774: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0016 - accuracy: 0.9995\n","Epoch 775/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 0.9995\n","Epoch 775: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0016 - accuracy: 0.9995\n","Epoch 776/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0016 - accuracy: 0.9995\n","Epoch 776: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0016 - accuracy: 0.9995\n","Epoch 777/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0403 - accuracy: 0.9902\n","Epoch 777: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0402 - accuracy: 0.9902\n","Epoch 778/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0189 - accuracy: 0.9932\n","Epoch 778: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0188 - accuracy: 0.9933\n","Epoch 779/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0070 - accuracy: 0.9972\n","Epoch 779: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0069 - accuracy: 0.9972\n","Epoch 780/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0060 - accuracy: 0.9976\n","Epoch 780: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0060 - accuracy: 0.9976\n","Epoch 781/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0044 - accuracy: 0.9985\n","Epoch 781: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0043 - accuracy: 0.9985\n","Epoch 782/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0023 - accuracy: 0.9992\n","Epoch 782: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0023 - accuracy: 0.9992\n","Epoch 783/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 0.9993\n","Epoch 783: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0021 - accuracy: 0.9993\n","Epoch 784/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0017 - accuracy: 0.9994\n","Epoch 784: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0017 - accuracy: 0.9994\n","Epoch 785/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 0.9995\n","Epoch 785: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0015 - accuracy: 0.9995\n","Epoch 786/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0014 - accuracy: 0.9996\n","Epoch 786: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0014 - accuracy: 0.9996\n","Epoch 787/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 0.9997\n","Epoch 787: accuracy improved from 0.99962 to 0.99966, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0013 - accuracy: 0.9997\n","Epoch 788/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0275 - accuracy: 0.9933\n","Epoch 788: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0273 - accuracy: 0.9933\n","Epoch 789/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0343 - accuracy: 0.9893\n","Epoch 789: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0345 - accuracy: 0.9893\n","Epoch 790/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0117 - accuracy: 0.9959\n","Epoch 790: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0117 - accuracy: 0.9959\n","Epoch 791/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0065 - accuracy: 0.9978\n","Epoch 791: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0064 - accuracy: 0.9979\n","Epoch 792/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0037 - accuracy: 0.9988\n","Epoch 792: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0037 - accuracy: 0.9988\n","Epoch 793/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0026 - accuracy: 0.9992\n","Epoch 793: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0026 - accuracy: 0.9992\n","Epoch 794/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0020 - accuracy: 0.9995\n","Epoch 794: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0020 - accuracy: 0.9995\n","Epoch 795/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0017 - accuracy: 0.9996\n","Epoch 795: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0017 - accuracy: 0.9996\n","Epoch 796/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 0.9996\n","Epoch 796: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0015 - accuracy: 0.9996\n","Epoch 797/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0014 - accuracy: 0.9995\n","Epoch 797: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0014 - accuracy: 0.9995\n","Epoch 798/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0152 - accuracy: 0.9950\n","Epoch 798: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0152 - accuracy: 0.9950\n","Epoch 799/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0372 - accuracy: 0.9880\n","Epoch 799: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0372 - accuracy: 0.9880\n","Epoch 800/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0104 - accuracy: 0.9960\n","Epoch 800: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0104 - accuracy: 0.9960\n","Epoch 801/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0054 - accuracy: 0.9978\n","Epoch 801: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0054 - accuracy: 0.9978\n","Epoch 802/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0036 - accuracy: 0.9988\n","Epoch 802: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0035 - accuracy: 0.9988\n","Epoch 803/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0024 - accuracy: 0.9992\n","Epoch 803: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0024 - accuracy: 0.9992\n","Epoch 804/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0019 - accuracy: 0.9994\n","Epoch 804: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0019 - accuracy: 0.9994\n","Epoch 805/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 0.9995\n","Epoch 805: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0016 - accuracy: 0.9995\n","Epoch 806/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 0.9995\n","Epoch 806: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0015 - accuracy: 0.9995\n","Epoch 807/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 0.9994\n","Epoch 807: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0021 - accuracy: 0.9994\n","Epoch 808/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 0.9996\n","Epoch 808: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0015 - accuracy: 0.9996\n","Epoch 809/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0405 - accuracy: 0.9892\n","Epoch 809: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0401 - accuracy: 0.9892\n","Epoch 810/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0192 - accuracy: 0.9925\n","Epoch 810: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0193 - accuracy: 0.9924\n","Epoch 811/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0113 - accuracy: 0.9959\n","Epoch 811: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0112 - accuracy: 0.9959\n","Epoch 812/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9978\n","Epoch 812: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0060 - accuracy: 0.9977\n","Epoch 813/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0033 - accuracy: 0.9986\n","Epoch 813: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0033 - accuracy: 0.9986\n","Epoch 814/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0020 - accuracy: 0.9994\n","Epoch 814: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0020 - accuracy: 0.9994\n","Epoch 815/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 0.9996\n","Epoch 815: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0015 - accuracy: 0.9995\n","Epoch 816/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 0.9996\n","Epoch 816: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0013 - accuracy: 0.9996\n","Epoch 817/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 0.9997\n","Epoch 817: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0013 - accuracy: 0.9997\n","Epoch 818/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0266 - accuracy: 0.9916\n","Epoch 818: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0264 - accuracy: 0.9916\n","Epoch 819/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0124 - accuracy: 0.9957\n","Epoch 819: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0124 - accuracy: 0.9958\n","Epoch 820/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0060 - accuracy: 0.9977\n","Epoch 820: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0060 - accuracy: 0.9977\n","Epoch 821/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0054 - accuracy: 0.9980\n","Epoch 821: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0054 - accuracy: 0.9980\n","Epoch 822/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0041 - accuracy: 0.9985\n","Epoch 822: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0041 - accuracy: 0.9985\n","Epoch 823/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 0.9993\n","Epoch 823: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0021 - accuracy: 0.9993\n","Epoch 824/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0016 - accuracy: 0.9995\n","Epoch 824: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0016 - accuracy: 0.9995\n","Epoch 825/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 0.9995\n","Epoch 825: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0015 - accuracy: 0.9995\n","Epoch 826/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0016 - accuracy: 0.9995\n","Epoch 826: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0015 - accuracy: 0.9995\n","Epoch 827/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0138 - accuracy: 0.9962\n","Epoch 827: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0139 - accuracy: 0.9962\n","Epoch 828/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0297 - accuracy: 0.9909\n","Epoch 828: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0297 - accuracy: 0.9907\n","Epoch 829/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0138 - accuracy: 0.9952\n","Epoch 829: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0139 - accuracy: 0.9952\n","Epoch 830/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0063 - accuracy: 0.9976\n","Epoch 830: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0064 - accuracy: 0.9975\n","Epoch 831/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0033 - accuracy: 0.9988\n","Epoch 831: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0033 - accuracy: 0.9988\n","Epoch 832/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 0.9993\n","Epoch 832: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0023 - accuracy: 0.9993\n","Epoch 833/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0019 - accuracy: 0.9994\n","Epoch 833: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0019 - accuracy: 0.9994\n","Epoch 834/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0016 - accuracy: 0.9995\n","Epoch 834: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0016 - accuracy: 0.9995\n","Epoch 835/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0013 - accuracy: 0.9996\n","Epoch 835: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0014 - accuracy: 0.9996\n","Epoch 836/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0243 - accuracy: 0.9927\n","Epoch 836: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0241 - accuracy: 0.9928\n","Epoch 837/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0227 - accuracy: 0.9924\n","Epoch 837: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0228 - accuracy: 0.9924\n","Epoch 838/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0074 - accuracy: 0.9975\n","Epoch 838: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0074 - accuracy: 0.9975\n","Epoch 839/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0048 - accuracy: 0.9982\n","Epoch 839: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0048 - accuracy: 0.9982\n","Epoch 840/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0032 - accuracy: 0.9990\n","Epoch 840: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0032 - accuracy: 0.9990\n","Epoch 841/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0026 - accuracy: 0.9991\n","Epoch 841: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0025 - accuracy: 0.9992\n","Epoch 842/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0018 - accuracy: 0.9994\n","Epoch 842: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0018 - accuracy: 0.9994\n","Epoch 843/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 0.9995\n","Epoch 843: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0015 - accuracy: 0.9995\n","Epoch 844/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0048 - accuracy: 0.9983\n","Epoch 844: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0048 - accuracy: 0.9983\n","Epoch 845/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0322 - accuracy: 0.9901\n","Epoch 845: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0323 - accuracy: 0.9902\n","Epoch 846/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0130 - accuracy: 0.9947\n","Epoch 846: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0130 - accuracy: 0.9947\n","Epoch 847/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0057 - accuracy: 0.9978\n","Epoch 847: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0058 - accuracy: 0.9977\n","Epoch 848/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0031 - accuracy: 0.9989\n","Epoch 848: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0031 - accuracy: 0.9989\n","Epoch 849/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0035 - accuracy: 0.9989\n","Epoch 849: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0034 - accuracy: 0.9989\n","Epoch 850/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 0.9993\n","Epoch 850: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0020 - accuracy: 0.9994\n","Epoch 851/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0017 - accuracy: 0.9995\n","Epoch 851: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0017 - accuracy: 0.9995\n","Epoch 852/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0016 - accuracy: 0.9996\n","Epoch 852: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0016 - accuracy: 0.9996\n","Epoch 853/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0047 - accuracy: 0.9983\n","Epoch 853: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0047 - accuracy: 0.9983\n","Epoch 854/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0419 - accuracy: 0.9875\n","Epoch 854: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0419 - accuracy: 0.9875\n","Epoch 855/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0092 - accuracy: 0.9963\n","Epoch 855: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0092 - accuracy: 0.9963\n","Epoch 856/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0046 - accuracy: 0.9982\n","Epoch 856: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0046 - accuracy: 0.9982\n","Epoch 857/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 0.9989\n","Epoch 857: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0031 - accuracy: 0.9989\n","Epoch 858/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 0.9994\n","Epoch 858: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0021 - accuracy: 0.9994\n","Epoch 859/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0017 - accuracy: 0.9996\n","Epoch 859: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0016 - accuracy: 0.9996\n","Epoch 860/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 0.9996\n","Epoch 860: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0015 - accuracy: 0.9996\n","Epoch 861/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 0.9996\n","Epoch 861: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0014 - accuracy: 0.9996\n","Epoch 862/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 0.9996\n","Epoch 862: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0014 - accuracy: 0.9996\n","Epoch 863/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0109 - accuracy: 0.9966\n","Epoch 863: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0111 - accuracy: 0.9964\n","Epoch 864/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0190 - accuracy: 0.9929\n","Epoch 864: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0189 - accuracy: 0.9929\n","Epoch 865/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0207 - accuracy: 0.9936\n","Epoch 865: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0212 - accuracy: 0.9936\n","Epoch 866/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0098 - accuracy: 0.9962\n","Epoch 866: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0098 - accuracy: 0.9962\n","Epoch 867/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0051 - accuracy: 0.9984\n","Epoch 867: accuracy did not improve from 0.99966\n","387/387 [==============================] - 4s 10ms/step - loss: 0.0052 - accuracy: 0.9983\n","Epoch 868/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0030 - accuracy: 0.9991\n","Epoch 868: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0030 - accuracy: 0.9991\n","Epoch 869/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0024 - accuracy: 0.9993\n","Epoch 869: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0024 - accuracy: 0.9993\n","Epoch 870/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0020 - accuracy: 0.9994\n","Epoch 870: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0020 - accuracy: 0.9994\n","Epoch 871/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 0.9994\n","Epoch 871: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0018 - accuracy: 0.9994\n","Epoch 872/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 0.9994\n","Epoch 872: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0019 - accuracy: 0.9994\n","Epoch 873/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0198 - accuracy: 0.9938\n","Epoch 873: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0198 - accuracy: 0.9938\n","Epoch 874/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0107 - accuracy: 0.9960\n","Epoch 874: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0107 - accuracy: 0.9961\n","Epoch 875/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0056 - accuracy: 0.9980\n","Epoch 875: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0056 - accuracy: 0.9980\n","Epoch 876/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0026 - accuracy: 0.9991\n","Epoch 876: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0026 - accuracy: 0.9992\n","Epoch 877/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0018 - accuracy: 0.9995\n","Epoch 877: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0018 - accuracy: 0.9995\n","Epoch 878/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 0.9995\n","Epoch 878: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0015 - accuracy: 0.9995\n","Epoch 879/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0014 - accuracy: 0.9995\n","Epoch 879: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0014 - accuracy: 0.9995\n","Epoch 880/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0013 - accuracy: 0.9996\n","Epoch 880: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0013 - accuracy: 0.9996\n","Epoch 881/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0480 - accuracy: 0.9884\n","Epoch 881: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0479 - accuracy: 0.9883\n","Epoch 882/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0196 - accuracy: 0.9938\n","Epoch 882: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0194 - accuracy: 0.9939\n","Epoch 883/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0066 - accuracy: 0.9976\n","Epoch 883: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0066 - accuracy: 0.9976\n","Epoch 884/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0039 - accuracy: 0.9986\n","Epoch 884: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0039 - accuracy: 0.9986\n","Epoch 885/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 0.9993\n","Epoch 885: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0025 - accuracy: 0.9993\n","Epoch 886/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 0.9994\n","Epoch 886: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0020 - accuracy: 0.9994\n","Epoch 887/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0019 - accuracy: 0.9995\n","Epoch 887: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0019 - accuracy: 0.9995\n","Epoch 888/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0017 - accuracy: 0.9995\n","Epoch 888: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0017 - accuracy: 0.9995\n","Epoch 889/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0025 - accuracy: 0.9991\n","Epoch 889: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0025 - accuracy: 0.9991\n","Epoch 890/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0211 - accuracy: 0.9926\n","Epoch 890: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0211 - accuracy: 0.9926\n","Epoch 891/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0177 - accuracy: 0.9939\n","Epoch 891: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0176 - accuracy: 0.9939\n","Epoch 892/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0150 - accuracy: 0.9946\n","Epoch 892: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0150 - accuracy: 0.9946\n","Epoch 893/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0057 - accuracy: 0.9980\n","Epoch 893: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0057 - accuracy: 0.9980\n","Epoch 894/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0026 - accuracy: 0.9990\n","Epoch 894: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0027 - accuracy: 0.9990\n","Epoch 895/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0022 - accuracy: 0.9991\n","Epoch 895: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0023 - accuracy: 0.9991\n","Epoch 896/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0017 - accuracy: 0.9994\n","Epoch 896: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0017 - accuracy: 0.9994\n","Epoch 897/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 0.9996\n","Epoch 897: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0014 - accuracy: 0.9996\n","Epoch 898/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0012 - accuracy: 0.9997\n","Epoch 898: accuracy improved from 0.99966 to 0.99970, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0012 - accuracy: 0.9997\n","Epoch 899/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0023 - accuracy: 0.9993\n","Epoch 899: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0023 - accuracy: 0.9993\n","Epoch 900/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0040 - accuracy: 0.9984\n","Epoch 900: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0041 - accuracy: 0.9984\n","Epoch 901/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0332 - accuracy: 0.9902\n","Epoch 901: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0333 - accuracy: 0.9901\n","Epoch 902/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0116 - accuracy: 0.9955\n","Epoch 902: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0119 - accuracy: 0.9955\n","Epoch 903/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0103 - accuracy: 0.9959\n","Epoch 903: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0102 - accuracy: 0.9959\n","Epoch 904/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0044 - accuracy: 0.9985\n","Epoch 904: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0043 - accuracy: 0.9985\n","Epoch 905/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 0.9991\n","Epoch 905: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0025 - accuracy: 0.9991\n","Epoch 906/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 0.9994\n","Epoch 906: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0019 - accuracy: 0.9994\n","Epoch 907/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0016 - accuracy: 0.9995\n","Epoch 907: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0016 - accuracy: 0.9995\n","Epoch 908/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0016 - accuracy: 0.9996\n","Epoch 908: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0016 - accuracy: 0.9996\n","Epoch 909/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 0.9995\n","Epoch 909: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0014 - accuracy: 0.9995\n","Epoch 910/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0029 - accuracy: 0.9991\n","Epoch 910: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0028 - accuracy: 0.9991\n","Epoch 911/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0332 - accuracy: 0.9899\n","Epoch 911: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0330 - accuracy: 0.9900\n","Epoch 912/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0200 - accuracy: 0.9928\n","Epoch 912: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0200 - accuracy: 0.9928\n","Epoch 913/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0084 - accuracy: 0.9967\n","Epoch 913: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0084 - accuracy: 0.9967\n","Epoch 914/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0053 - accuracy: 0.9978\n","Epoch 914: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0053 - accuracy: 0.9978\n","Epoch 915/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0035 - accuracy: 0.9987\n","Epoch 915: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0035 - accuracy: 0.9987\n","Epoch 916/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0020 - accuracy: 0.9993\n","Epoch 916: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0020 - accuracy: 0.9993\n","Epoch 917/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0018 - accuracy: 0.9994\n","Epoch 917: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0017 - accuracy: 0.9994\n","Epoch 918/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 0.9995\n","Epoch 918: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0015 - accuracy: 0.9995\n","Epoch 919/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0016 - accuracy: 0.9996\n","Epoch 919: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0016 - accuracy: 0.9996\n","Epoch 920/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0033 - accuracy: 0.9990\n","Epoch 920: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0034 - accuracy: 0.9989\n","Epoch 921/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0345 - accuracy: 0.9896\n","Epoch 921: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0345 - accuracy: 0.9896\n","Epoch 922/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0166 - accuracy: 0.9942\n","Epoch 922: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0166 - accuracy: 0.9942\n","Epoch 923/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0073 - accuracy: 0.9968\n","Epoch 923: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0073 - accuracy: 0.9968\n","Epoch 924/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0034 - accuracy: 0.9987\n","Epoch 924: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0034 - accuracy: 0.9987\n","Epoch 925/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0036 - accuracy: 0.9985\n","Epoch 925: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0036 - accuracy: 0.9985\n","Epoch 926/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0020 - accuracy: 0.9993\n","Epoch 926: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0020 - accuracy: 0.9994\n","Epoch 927/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0014 - accuracy: 0.9996\n","Epoch 927: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0015 - accuracy: 0.9996\n","Epoch 928/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0014 - accuracy: 0.9996\n","Epoch 928: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0014 - accuracy: 0.9996\n","Epoch 929/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0013 - accuracy: 0.9996\n","Epoch 929: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0013 - accuracy: 0.9996\n","Epoch 930/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0018 - accuracy: 0.9994\n","Epoch 930: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0018 - accuracy: 0.9995\n","Epoch 931/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 0.9995\n","Epoch 931: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0017 - accuracy: 0.9995\n","Epoch 932/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0232 - accuracy: 0.9939\n","Epoch 932: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0233 - accuracy: 0.9938\n","Epoch 933/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0263 - accuracy: 0.9908\n","Epoch 933: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0261 - accuracy: 0.9908\n","Epoch 934/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0067 - accuracy: 0.9973\n","Epoch 934: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0067 - accuracy: 0.9973\n","Epoch 935/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0043 - accuracy: 0.9983\n","Epoch 935: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0043 - accuracy: 0.9983\n","Epoch 936/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 0.9993\n","Epoch 936: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0021 - accuracy: 0.9993\n","Epoch 937/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0017 - accuracy: 0.9995\n","Epoch 937: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0017 - accuracy: 0.9995\n","Epoch 938/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0014 - accuracy: 0.9996\n","Epoch 938: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0014 - accuracy: 0.9996\n","Epoch 939/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0013 - accuracy: 0.9996\n","Epoch 939: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0013 - accuracy: 0.9996\n","Epoch 940/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0019 - accuracy: 0.9994\n","Epoch 940: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0019 - accuracy: 0.9993\n","Epoch 941/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0030 - accuracy: 0.9990\n","Epoch 941: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0030 - accuracy: 0.9990\n","Epoch 942/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0325 - accuracy: 0.9914\n","Epoch 942: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0325 - accuracy: 0.9914\n","Epoch 943/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0143 - accuracy: 0.9944\n","Epoch 943: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0143 - accuracy: 0.9944\n","Epoch 944/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0067 - accuracy: 0.9975\n","Epoch 944: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0067 - accuracy: 0.9975\n","Epoch 945/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0064 - accuracy: 0.9974\n","Epoch 945: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0064 - accuracy: 0.9974\n","Epoch 946/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0028 - accuracy: 0.9989\n","Epoch 946: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0028 - accuracy: 0.9989\n","Epoch 947/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 0.9994\n","Epoch 947: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0018 - accuracy: 0.9994\n","Epoch 948/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0014 - accuracy: 0.9994\n","Epoch 948: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0014 - accuracy: 0.9994\n","Epoch 949/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0013 - accuracy: 0.9996\n","Epoch 949: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0013 - accuracy: 0.9996\n","Epoch 950/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0013 - accuracy: 0.9995\n","Epoch 950: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0013 - accuracy: 0.9995\n","Epoch 951/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 0.9996\n","Epoch 951: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0013 - accuracy: 0.9996\n","Epoch 952/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0308 - accuracy: 0.9925\n","Epoch 952: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0310 - accuracy: 0.9925\n","Epoch 953/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0194 - accuracy: 0.9936\n","Epoch 953: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0193 - accuracy: 0.9937\n","Epoch 954/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0078 - accuracy: 0.9967\n","Epoch 954: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0078 - accuracy: 0.9967\n","Epoch 955/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0040 - accuracy: 0.9985\n","Epoch 955: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0040 - accuracy: 0.9985\n","Epoch 956/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0025 - accuracy: 0.9993\n","Epoch 956: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0025 - accuracy: 0.9993\n","Epoch 957/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0018 - accuracy: 0.9994\n","Epoch 957: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0018 - accuracy: 0.9995\n","Epoch 958/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0016 - accuracy: 0.9995\n","Epoch 958: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0016 - accuracy: 0.9995\n","Epoch 959/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0014 - accuracy: 0.9996\n","Epoch 959: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0014 - accuracy: 0.9996\n","Epoch 960/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0014 - accuracy: 0.9996\n","Epoch 960: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0014 - accuracy: 0.9996\n","Epoch 961/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0013 - accuracy: 0.9996\n","Epoch 961: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0013 - accuracy: 0.9996\n","Epoch 962/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 0.9995\n","Epoch 962: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0015 - accuracy: 0.9995\n","Epoch 963/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0351 - accuracy: 0.9905\n","Epoch 963: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0351 - accuracy: 0.9905\n","Epoch 964/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0235 - accuracy: 0.9924\n","Epoch 964: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0234 - accuracy: 0.9924\n","Epoch 965/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0110 - accuracy: 0.9958\n","Epoch 965: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0110 - accuracy: 0.9958\n","Epoch 966/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0045 - accuracy: 0.9982\n","Epoch 966: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0045 - accuracy: 0.9982\n","Epoch 967/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0024 - accuracy: 0.9990\n","Epoch 967: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0024 - accuracy: 0.9990\n","Epoch 968/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 0.9995\n","Epoch 968: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0015 - accuracy: 0.9995\n","Epoch 969/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0012 - accuracy: 0.9996\n","Epoch 969: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0012 - accuracy: 0.9996\n","Epoch 970/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 0.9996\n","Epoch 970: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0011 - accuracy: 0.9996\n","Epoch 971/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 0.9997\n","Epoch 971: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0011 - accuracy: 0.9997\n","Epoch 972/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0018 - accuracy: 0.9994\n","Epoch 972: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0018 - accuracy: 0.9994\n","Epoch 973/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 0.9996\n","Epoch 973: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0013 - accuracy: 0.9996\n","Epoch 974/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0017 - accuracy: 0.9996\n","Epoch 974: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0017 - accuracy: 0.9996\n","Epoch 975/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0340 - accuracy: 0.9914\n","Epoch 975: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0340 - accuracy: 0.9914\n","Epoch 976/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0318 - accuracy: 0.9899\n","Epoch 976: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0318 - accuracy: 0.9900\n","Epoch 977/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0090 - accuracy: 0.9969\n","Epoch 977: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0090 - accuracy: 0.9969\n","Epoch 978/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0036 - accuracy: 0.9989\n","Epoch 978: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0036 - accuracy: 0.9989\n","Epoch 979/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 0.9993\n","Epoch 979: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0023 - accuracy: 0.9993\n","Epoch 980/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0018 - accuracy: 0.9995\n","Epoch 980: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0018 - accuracy: 0.9995\n","Epoch 981/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 0.9995\n","Epoch 981: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0015 - accuracy: 0.9995\n","Epoch 982/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 0.9996\n","Epoch 982: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0014 - accuracy: 0.9996\n","Epoch 983/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0013 - accuracy: 0.9996\n","Epoch 983: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0013 - accuracy: 0.9996\n","Epoch 984/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0073 - accuracy: 0.9978\n","Epoch 984: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0073 - accuracy: 0.9978\n","Epoch 985/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0198 - accuracy: 0.9942\n","Epoch 985: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0197 - accuracy: 0.9942\n","Epoch 986/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0141 - accuracy: 0.9953\n","Epoch 986: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0140 - accuracy: 0.9953\n","Epoch 987/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0072 - accuracy: 0.9975\n","Epoch 987: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0072 - accuracy: 0.9975\n","Epoch 988/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0039 - accuracy: 0.9985\n","Epoch 988: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0039 - accuracy: 0.9985\n","Epoch 989/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0028 - accuracy: 0.9990\n","Epoch 989: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0028 - accuracy: 0.9990\n","Epoch 990/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 0.9993\n","Epoch 990: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0021 - accuracy: 0.9993\n","Epoch 991/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0016 - accuracy: 0.9996\n","Epoch 991: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0016 - accuracy: 0.9996\n","Epoch 992/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0014 - accuracy: 0.9996\n","Epoch 992: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0013 - accuracy: 0.9996\n","Epoch 993/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0014 - accuracy: 0.9996\n","Epoch 993: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0014 - accuracy: 0.9996\n","Epoch 994/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 0.9996\n","Epoch 994: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0016 - accuracy: 0.9996\n","Epoch 995/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0082 - accuracy: 0.9984\n","Epoch 995: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0083 - accuracy: 0.9983\n","Epoch 996/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0674 - accuracy: 0.9851\n","Epoch 996: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0674 - accuracy: 0.9851\n","Epoch 997/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0155 - accuracy: 0.9949\n","Epoch 997: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0153 - accuracy: 0.9950\n","Epoch 998/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0047 - accuracy: 0.9983\n","Epoch 998: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0047 - accuracy: 0.9983\n","Epoch 999/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0028 - accuracy: 0.9991\n","Epoch 999: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0028 - accuracy: 0.9991\n","Epoch 1000/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 0.9994\n","Epoch 1000: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0022 - accuracy: 0.9994\n"]}]},{"cell_type":"markdown","metadata":{"id":"JpiuEoig5iId"},"source":["# Training the lyric/word prediction model"]},{"cell_type":"code","metadata":{"id":"Ua_XN1vN0YxE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1645399019093,"user_tz":-360,"elapsed":1925077,"user":{"displayName":"Mimsadi Islam","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07228862094531790502"}},"outputId":"de6ecd91-2cd0-4cc5-8ace-5470361698b7"},"source":["list_of_training = [\"model_3\"]\n","\n","K.set_value(model_3.optimizer.learning_rate, 0.001)\n","for each_model in list_of_training:\n","    filepath = f\"best_{each_model}.hdf5\"\n","    model_checkpoint = ModelCheckpoint(filepath, monitor=\"loss\", save_best_only=True, verbose=1)\n","\n","    if each_model == \"model_1\":\n","        history = model_1.fit(predictors, label,batch_size=1024, epochs=4000 , verbose=1, callbacks=[model_checkpoint])\n","    elif each_model == \"model_2\":\n","        history = model_2.fit(predictors, label,batch_size=1024, epochs=4000 , verbose=1, callbacks=[model_checkpoint])\n","    elif each_model == \"model_3\":\n","        history = model_3.fit(predictors, label,batch_size=1024, epochs=4000 , verbose=1, callbacks=[model_checkpoint])\n","\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n","Epoch 2751/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.4905 - accuracy: 0.8862\n","Epoch 2751: loss did not improve from 0.33690\n","8/8 [==============================] - 0s 56ms/step - loss: 0.4962 - accuracy: 0.8844\n","Epoch 2752/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.4646 - accuracy: 0.8905\n","Epoch 2752: loss did not improve from 0.33690\n","8/8 [==============================] - 0s 53ms/step - loss: 0.4697 - accuracy: 0.8888\n","Epoch 2753/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.4521 - accuracy: 0.8924\n","Epoch 2753: loss did not improve from 0.33690\n","8/8 [==============================] - 0s 51ms/step - loss: 0.4534 - accuracy: 0.8913\n","Epoch 2754/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.4271 - accuracy: 0.8961\n","Epoch 2754: loss did not improve from 0.33690\n","8/8 [==============================] - 0s 56ms/step - loss: 0.4305 - accuracy: 0.8943\n","Epoch 2755/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.4172 - accuracy: 0.8969\n","Epoch 2755: loss did not improve from 0.33690\n","8/8 [==============================] - 0s 55ms/step - loss: 0.4157 - accuracy: 0.8967\n","Epoch 2756/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3982 - accuracy: 0.9003\n","Epoch 2756: loss did not improve from 0.33690\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3994 - accuracy: 0.8994\n","Epoch 2757/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3861 - accuracy: 0.9019\n","Epoch 2757: loss did not improve from 0.33690\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3878 - accuracy: 0.9009\n","Epoch 2758/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3743 - accuracy: 0.9014\n","Epoch 2758: loss did not improve from 0.33690\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3753 - accuracy: 0.9007\n","Epoch 2759/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3660 - accuracy: 0.8989\n","Epoch 2759: loss did not improve from 0.33690\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3663 - accuracy: 0.8990\n","Epoch 2760/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3624 - accuracy: 0.9005\n","Epoch 2760: loss did not improve from 0.33690\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3604 - accuracy: 0.9011\n","Epoch 2761/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3518 - accuracy: 0.9003\n","Epoch 2761: loss did not improve from 0.33690\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3560 - accuracy: 0.8992\n","Epoch 2762/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3496 - accuracy: 0.8993\n","Epoch 2762: loss did not improve from 0.33690\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3496 - accuracy: 0.8993\n","Epoch 2763/4000\n","8/8 [==============================] - ETA: 0s - loss: 0.3484 - accuracy: 0.9009\n","Epoch 2763: loss did not improve from 0.33690\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3484 - accuracy: 0.9009\n","Epoch 2764/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3443 - accuracy: 0.9016\n","Epoch 2764: loss did not improve from 0.33690\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3468 - accuracy: 0.9009\n","Epoch 2765/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3445 - accuracy: 0.8996\n","Epoch 2765: loss did not improve from 0.33690\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3462 - accuracy: 0.8989\n","Epoch 2766/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3394 - accuracy: 0.9028\n","Epoch 2766: loss did not improve from 0.33690\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3427 - accuracy: 0.9012\n","Epoch 2767/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3435 - accuracy: 0.9005\n","Epoch 2767: loss did not improve from 0.33690\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3435 - accuracy: 0.9003\n","Epoch 2768/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3421 - accuracy: 0.9021\n","Epoch 2768: loss did not improve from 0.33690\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3441 - accuracy: 0.9009\n","Epoch 2769/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3403 - accuracy: 0.9008\n","Epoch 2769: loss did not improve from 0.33690\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3419 - accuracy: 0.8998\n","Epoch 2770/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3424 - accuracy: 0.9007\n","Epoch 2770: loss did not improve from 0.33690\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3383 - accuracy: 0.9014\n","Epoch 2771/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3374 - accuracy: 0.9029\n","Epoch 2771: loss did not improve from 0.33690\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3394 - accuracy: 0.9015\n","Epoch 2772/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3349 - accuracy: 0.9000\n","Epoch 2772: loss did not improve from 0.33690\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3388 - accuracy: 0.8997\n","Epoch 2773/4000\n","8/8 [==============================] - ETA: 0s - loss: 0.3379 - accuracy: 0.9002\n","Epoch 2773: loss did not improve from 0.33690\n","8/8 [==============================] - 0s 57ms/step - loss: 0.3379 - accuracy: 0.9002\n","Epoch 2774/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3395 - accuracy: 0.9021\n","Epoch 2774: loss did not improve from 0.33690\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3370 - accuracy: 0.9028\n","Epoch 2775/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3363 - accuracy: 0.9014\n","Epoch 2775: loss did not improve from 0.33690\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3383 - accuracy: 0.8998\n","Epoch 2776/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3317 - accuracy: 0.9021\n","Epoch 2776: loss improved from 0.33690 to 0.33596, saving model to best_model_3.hdf5\n","8/8 [==============================] - 1s 110ms/step - loss: 0.3360 - accuracy: 0.9006\n","Epoch 2777/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3409 - accuracy: 0.9009\n","Epoch 2777: loss did not improve from 0.33596\n","8/8 [==============================] - 0s 56ms/step - loss: 0.3392 - accuracy: 0.9012\n","Epoch 2778/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3382 - accuracy: 0.8993\n","Epoch 2778: loss did not improve from 0.33596\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3386 - accuracy: 0.8987\n","Epoch 2779/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3365 - accuracy: 0.9019\n","Epoch 2779: loss did not improve from 0.33596\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3374 - accuracy: 0.9011\n","Epoch 2780/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3342 - accuracy: 0.9014\n","Epoch 2780: loss did not improve from 0.33596\n","8/8 [==============================] - 0s 56ms/step - loss: 0.3371 - accuracy: 0.9001\n","Epoch 2781/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3312 - accuracy: 0.9015\n","Epoch 2781: loss improved from 0.33596 to 0.33575, saving model to best_model_3.hdf5\n","8/8 [==============================] - 1s 105ms/step - loss: 0.3358 - accuracy: 0.9001\n","Epoch 2782/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3397 - accuracy: 0.9032\n","Epoch 2782: loss did not improve from 0.33575\n","8/8 [==============================] - 0s 48ms/step - loss: 0.3365 - accuracy: 0.9034\n","Epoch 2783/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3404 - accuracy: 0.9015\n","Epoch 2783: loss did not improve from 0.33575\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3397 - accuracy: 0.9016\n","Epoch 2784/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3360 - accuracy: 0.9026\n","Epoch 2784: loss did not improve from 0.33575\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3395 - accuracy: 0.9006\n","Epoch 2785/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3386 - accuracy: 0.8980\n","Epoch 2785: loss did not improve from 0.33575\n","8/8 [==============================] - 0s 49ms/step - loss: 0.3408 - accuracy: 0.8979\n","Epoch 2786/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3321 - accuracy: 0.9019\n","Epoch 2786: loss improved from 0.33575 to 0.33467, saving model to best_model_3.hdf5\n","8/8 [==============================] - 1s 105ms/step - loss: 0.3347 - accuracy: 0.9015\n","Epoch 2787/4000\n","8/8 [==============================] - ETA: 0s - loss: 0.3353 - accuracy: 0.8994\n","Epoch 2787: loss did not improve from 0.33467\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3353 - accuracy: 0.8994\n","Epoch 2788/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3292 - accuracy: 0.9044\n","Epoch 2788: loss improved from 0.33467 to 0.33115, saving model to best_model_3.hdf5\n","8/8 [==============================] - 1s 104ms/step - loss: 0.3312 - accuracy: 0.9031\n","Epoch 2789/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3368 - accuracy: 0.9005\n","Epoch 2789: loss did not improve from 0.33115\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3369 - accuracy: 0.9002\n","Epoch 2790/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3335 - accuracy: 0.9036\n","Epoch 2790: loss did not improve from 0.33115\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3358 - accuracy: 0.9021\n","Epoch 2791/4000\n","8/8 [==============================] - ETA: 0s - loss: 0.3358 - accuracy: 0.9006\n","Epoch 2791: loss did not improve from 0.33115\n","8/8 [==============================] - 0s 56ms/step - loss: 0.3358 - accuracy: 0.9006\n","Epoch 2792/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3308 - accuracy: 0.9026\n","Epoch 2792: loss did not improve from 0.33115\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3325 - accuracy: 0.9011\n","Epoch 2793/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3374 - accuracy: 0.8965\n","Epoch 2793: loss did not improve from 0.33115\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3355 - accuracy: 0.8974\n","Epoch 2794/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3330 - accuracy: 0.9011\n","Epoch 2794: loss did not improve from 0.33115\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3333 - accuracy: 0.9005\n","Epoch 2795/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3280 - accuracy: 0.9004\n","Epoch 2795: loss did not improve from 0.33115\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3329 - accuracy: 0.8988\n","Epoch 2796/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3322 - accuracy: 0.8993\n","Epoch 2796: loss did not improve from 0.33115\n","8/8 [==============================] - 0s 56ms/step - loss: 0.3348 - accuracy: 0.8983\n","Epoch 2797/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3272 - accuracy: 0.9032\n","Epoch 2797: loss did not improve from 0.33115\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3360 - accuracy: 0.9005\n","Epoch 2798/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3315 - accuracy: 0.9029\n","Epoch 2798: loss did not improve from 0.33115\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3340 - accuracy: 0.9010\n","Epoch 2799/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3299 - accuracy: 0.9009\n","Epoch 2799: loss did not improve from 0.33115\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3334 - accuracy: 0.8996\n","Epoch 2800/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3277 - accuracy: 0.9033\n","Epoch 2800: loss did not improve from 0.33115\n","8/8 [==============================] - 0s 56ms/step - loss: 0.3325 - accuracy: 0.9024\n","Epoch 2801/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3344 - accuracy: 0.9012\n","Epoch 2801: loss did not improve from 0.33115\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3327 - accuracy: 0.9012\n","Epoch 2802/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3348 - accuracy: 0.8987\n","Epoch 2802: loss did not improve from 0.33115\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3337 - accuracy: 0.8988\n","Epoch 2803/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3300 - accuracy: 0.9012\n","Epoch 2803: loss did not improve from 0.33115\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3337 - accuracy: 0.8993\n","Epoch 2804/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3216 - accuracy: 0.9039\n","Epoch 2804: loss improved from 0.33115 to 0.32847, saving model to best_model_3.hdf5\n","8/8 [==============================] - 1s 104ms/step - loss: 0.3285 - accuracy: 0.9015\n","Epoch 2805/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3314 - accuracy: 0.9022\n","Epoch 2805: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 58ms/step - loss: 0.3308 - accuracy: 0.9023\n","Epoch 2806/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3307 - accuracy: 0.9016\n","Epoch 2806: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3316 - accuracy: 0.9014\n","Epoch 2807/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3271 - accuracy: 0.9030\n","Epoch 2807: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3323 - accuracy: 0.9010\n","Epoch 2808/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3265 - accuracy: 0.9032\n","Epoch 2808: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3310 - accuracy: 0.9007\n","Epoch 2809/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3310 - accuracy: 0.8998\n","Epoch 2809: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3331 - accuracy: 0.8990\n","Epoch 2810/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3308 - accuracy: 0.9004\n","Epoch 2810: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3337 - accuracy: 0.8992\n","Epoch 2811/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3328 - accuracy: 0.9015\n","Epoch 2811: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3337 - accuracy: 0.9015\n","Epoch 2812/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3293 - accuracy: 0.9004\n","Epoch 2812: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 49ms/step - loss: 0.3329 - accuracy: 0.8994\n","Epoch 2813/4000\n","8/8 [==============================] - ETA: 0s - loss: 0.3325 - accuracy: 0.9009\n","Epoch 2813: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 56ms/step - loss: 0.3325 - accuracy: 0.9009\n","Epoch 2814/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3346 - accuracy: 0.9009\n","Epoch 2814: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3390 - accuracy: 0.8993\n","Epoch 2815/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3299 - accuracy: 0.9019\n","Epoch 2815: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3336 - accuracy: 0.9005\n","Epoch 2816/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3338 - accuracy: 0.9009\n","Epoch 2816: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3366 - accuracy: 0.8997\n","Epoch 2817/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3367 - accuracy: 0.8991\n","Epoch 2817: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3347 - accuracy: 0.8998\n","Epoch 2818/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3316 - accuracy: 0.9026\n","Epoch 2818: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 57ms/step - loss: 0.3337 - accuracy: 0.9019\n","Epoch 2819/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3327 - accuracy: 0.9003\n","Epoch 2819: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3317 - accuracy: 0.9011\n","Epoch 2820/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3280 - accuracy: 0.9026\n","Epoch 2820: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3311 - accuracy: 0.9006\n","Epoch 2821/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3339 - accuracy: 0.9028\n","Epoch 2821: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3336 - accuracy: 0.9024\n","Epoch 2822/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3342 - accuracy: 0.9012\n","Epoch 2822: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3358 - accuracy: 0.9006\n","Epoch 2823/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3318 - accuracy: 0.9018\n","Epoch 2823: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3350 - accuracy: 0.9011\n","Epoch 2824/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3326 - accuracy: 0.9012\n","Epoch 2824: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3335 - accuracy: 0.9007\n","Epoch 2825/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3339 - accuracy: 0.9001\n","Epoch 2825: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3340 - accuracy: 0.8993\n","Epoch 2826/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3365 - accuracy: 0.9005\n","Epoch 2826: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3392 - accuracy: 0.9003\n","Epoch 2827/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3337 - accuracy: 0.9033\n","Epoch 2827: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3372 - accuracy: 0.9016\n","Epoch 2828/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3373 - accuracy: 0.9014\n","Epoch 2828: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3390 - accuracy: 0.9009\n","Epoch 2829/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3326 - accuracy: 0.9003\n","Epoch 2829: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 49ms/step - loss: 0.3363 - accuracy: 0.8989\n","Epoch 2830/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3365 - accuracy: 0.8998\n","Epoch 2830: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3385 - accuracy: 0.8989\n","Epoch 2831/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3303 - accuracy: 0.9039\n","Epoch 2831: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3354 - accuracy: 0.9015\n","Epoch 2832/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3311 - accuracy: 0.9025\n","Epoch 2832: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3356 - accuracy: 0.9003\n","Epoch 2833/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3366 - accuracy: 0.8996\n","Epoch 2833: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3331 - accuracy: 0.9006\n","Epoch 2834/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3330 - accuracy: 0.9011\n","Epoch 2834: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3334 - accuracy: 0.9015\n","Epoch 2835/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3337 - accuracy: 0.8975\n","Epoch 2835: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3325 - accuracy: 0.8977\n","Epoch 2836/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3311 - accuracy: 0.9004\n","Epoch 2836: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3318 - accuracy: 0.9002\n","Epoch 2837/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3319 - accuracy: 0.9023\n","Epoch 2837: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3352 - accuracy: 0.9019\n","Epoch 2838/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3279 - accuracy: 0.9018\n","Epoch 2838: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3338 - accuracy: 0.8999\n","Epoch 2839/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3300 - accuracy: 0.9025\n","Epoch 2839: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3347 - accuracy: 0.9007\n","Epoch 2840/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3318 - accuracy: 0.9003\n","Epoch 2840: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3343 - accuracy: 0.8990\n","Epoch 2841/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3342 - accuracy: 0.9025\n","Epoch 2841: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3365 - accuracy: 0.9015\n","Epoch 2842/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3331 - accuracy: 0.9016\n","Epoch 2842: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3345 - accuracy: 0.9010\n","Epoch 2843/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3295 - accuracy: 0.9011\n","Epoch 2843: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3331 - accuracy: 0.8998\n","Epoch 2844/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3338 - accuracy: 0.9015\n","Epoch 2844: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3365 - accuracy: 0.9011\n","Epoch 2845/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3339 - accuracy: 0.9015\n","Epoch 2845: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3344 - accuracy: 0.9018\n","Epoch 2846/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3333 - accuracy: 0.9019\n","Epoch 2846: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3317 - accuracy: 0.9023\n","Epoch 2847/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3307 - accuracy: 0.9025\n","Epoch 2847: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3326 - accuracy: 0.9011\n","Epoch 2848/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3299 - accuracy: 0.9008\n","Epoch 2848: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3324 - accuracy: 0.9003\n","Epoch 2849/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3348 - accuracy: 0.8989\n","Epoch 2849: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3343 - accuracy: 0.8992\n","Epoch 2850/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3287 - accuracy: 0.9005\n","Epoch 2850: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3307 - accuracy: 0.8994\n","Epoch 2851/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3236 - accuracy: 0.9028\n","Epoch 2851: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3298 - accuracy: 0.9001\n","Epoch 2852/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3338 - accuracy: 0.9012\n","Epoch 2852: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3333 - accuracy: 0.9009\n","Epoch 2853/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3346 - accuracy: 0.8997\n","Epoch 2853: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3314 - accuracy: 0.9006\n","Epoch 2854/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3259 - accuracy: 0.9009\n","Epoch 2854: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3286 - accuracy: 0.8994\n","Epoch 2855/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3330 - accuracy: 0.8996\n","Epoch 2855: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3293 - accuracy: 0.9005\n","Epoch 2856/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3319 - accuracy: 0.9000\n","Epoch 2856: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3298 - accuracy: 0.9006\n","Epoch 2857/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3324 - accuracy: 0.8991\n","Epoch 2857: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 56ms/step - loss: 0.3300 - accuracy: 0.8998\n","Epoch 2858/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3269 - accuracy: 0.8997\n","Epoch 2858: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3300 - accuracy: 0.8988\n","Epoch 2859/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3312 - accuracy: 0.9003\n","Epoch 2859: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3318 - accuracy: 0.9002\n","Epoch 2860/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3362 - accuracy: 0.8996\n","Epoch 2860: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3361 - accuracy: 0.8994\n","Epoch 2861/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3352 - accuracy: 0.8998\n","Epoch 2861: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3360 - accuracy: 0.8990\n","Epoch 2862/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3325 - accuracy: 0.9011\n","Epoch 2862: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3349 - accuracy: 0.8996\n","Epoch 2863/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3348 - accuracy: 0.8972\n","Epoch 2863: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3335 - accuracy: 0.8983\n","Epoch 2864/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3314 - accuracy: 0.9015\n","Epoch 2864: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3332 - accuracy: 0.9010\n","Epoch 2865/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3306 - accuracy: 0.9021\n","Epoch 2865: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3330 - accuracy: 0.9009\n","Epoch 2866/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3341 - accuracy: 0.9014\n","Epoch 2866: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3351 - accuracy: 0.9014\n","Epoch 2867/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3375 - accuracy: 0.9008\n","Epoch 2867: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3345 - accuracy: 0.9018\n","Epoch 2868/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3279 - accuracy: 0.9022\n","Epoch 2868: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3332 - accuracy: 0.8999\n","Epoch 2869/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3286 - accuracy: 0.9019\n","Epoch 2869: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3304 - accuracy: 0.9006\n","Epoch 2870/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3314 - accuracy: 0.9003\n","Epoch 2870: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3327 - accuracy: 0.8998\n","Epoch 2871/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3337 - accuracy: 0.9007\n","Epoch 2871: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 56ms/step - loss: 0.3357 - accuracy: 0.8997\n","Epoch 2872/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3272 - accuracy: 0.9022\n","Epoch 2872: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3303 - accuracy: 0.9010\n","Epoch 2873/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3335 - accuracy: 0.9046\n","Epoch 2873: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3336 - accuracy: 0.9046\n","Epoch 2874/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3324 - accuracy: 0.9009\n","Epoch 2874: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3362 - accuracy: 0.9001\n","Epoch 2875/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3301 - accuracy: 0.9012\n","Epoch 2875: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3309 - accuracy: 0.9011\n","Epoch 2876/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3230 - accuracy: 0.9014\n","Epoch 2876: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3290 - accuracy: 0.8994\n","Epoch 2877/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3342 - accuracy: 0.9005\n","Epoch 2877: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3327 - accuracy: 0.9005\n","Epoch 2878/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3293 - accuracy: 0.9033\n","Epoch 2878: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3329 - accuracy: 0.9019\n","Epoch 2879/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3277 - accuracy: 0.9016\n","Epoch 2879: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3325 - accuracy: 0.8999\n","Epoch 2880/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3276 - accuracy: 0.9032\n","Epoch 2880: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3295 - accuracy: 0.9023\n","Epoch 2881/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3311 - accuracy: 0.9019\n","Epoch 2881: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3325 - accuracy: 0.9009\n","Epoch 2882/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3328 - accuracy: 0.9015\n","Epoch 2882: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3353 - accuracy: 0.9003\n","Epoch 2883/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3293 - accuracy: 0.9032\n","Epoch 2883: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 57ms/step - loss: 0.3328 - accuracy: 0.9020\n","Epoch 2884/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3308 - accuracy: 0.9018\n","Epoch 2884: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3351 - accuracy: 0.9007\n","Epoch 2885/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3366 - accuracy: 0.9015\n","Epoch 2885: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3331 - accuracy: 0.9021\n","Epoch 2886/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3348 - accuracy: 0.9004\n","Epoch 2886: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3356 - accuracy: 0.9002\n","Epoch 2887/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3351 - accuracy: 0.9015\n","Epoch 2887: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3351 - accuracy: 0.9009\n","Epoch 2888/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3249 - accuracy: 0.9044\n","Epoch 2888: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 56ms/step - loss: 0.3316 - accuracy: 0.9019\n","Epoch 2889/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3322 - accuracy: 0.8993\n","Epoch 2889: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3337 - accuracy: 0.8990\n","Epoch 2890/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3316 - accuracy: 0.9011\n","Epoch 2890: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3316 - accuracy: 0.9018\n","Epoch 2891/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3247 - accuracy: 0.9036\n","Epoch 2891: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3309 - accuracy: 0.9015\n","Epoch 2892/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3281 - accuracy: 0.9035\n","Epoch 2892: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3344 - accuracy: 0.9007\n","Epoch 2893/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3313 - accuracy: 0.9021\n","Epoch 2893: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3331 - accuracy: 0.9014\n","Epoch 2894/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3335 - accuracy: 0.9008\n","Epoch 2894: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3321 - accuracy: 0.9011\n","Epoch 2895/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3292 - accuracy: 0.9012\n","Epoch 2895: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 56ms/step - loss: 0.3336 - accuracy: 0.8997\n","Epoch 2896/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3322 - accuracy: 0.9011\n","Epoch 2896: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3334 - accuracy: 0.9011\n","Epoch 2897/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3314 - accuracy: 0.8996\n","Epoch 2897: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3317 - accuracy: 0.8993\n","Epoch 2898/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3320 - accuracy: 0.8991\n","Epoch 2898: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3321 - accuracy: 0.8990\n","Epoch 2899/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3343 - accuracy: 0.8996\n","Epoch 2899: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3349 - accuracy: 0.8992\n","Epoch 2900/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3305 - accuracy: 0.9001\n","Epoch 2900: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3310 - accuracy: 0.8997\n","Epoch 2901/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3290 - accuracy: 0.9011\n","Epoch 2901: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3321 - accuracy: 0.9003\n","Epoch 2902/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3280 - accuracy: 0.9011\n","Epoch 2902: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3314 - accuracy: 0.8999\n","Epoch 2903/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3300 - accuracy: 0.8998\n","Epoch 2903: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3326 - accuracy: 0.8985\n","Epoch 2904/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3281 - accuracy: 0.9026\n","Epoch 2904: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3309 - accuracy: 0.9005\n","Epoch 2905/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3284 - accuracy: 0.9011\n","Epoch 2905: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3318 - accuracy: 0.8993\n","Epoch 2906/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3286 - accuracy: 0.9008\n","Epoch 2906: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3322 - accuracy: 0.8999\n","Epoch 2907/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3221 - accuracy: 0.9036\n","Epoch 2907: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3305 - accuracy: 0.9015\n","Epoch 2908/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3345 - accuracy: 0.8991\n","Epoch 2908: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3332 - accuracy: 0.8994\n","Epoch 2909/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3302 - accuracy: 0.9030\n","Epoch 2909: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3331 - accuracy: 0.9014\n","Epoch 2910/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3291 - accuracy: 0.9022\n","Epoch 2910: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3344 - accuracy: 0.9010\n","Epoch 2911/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3340 - accuracy: 0.9008\n","Epoch 2911: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3353 - accuracy: 0.9006\n","Epoch 2912/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3284 - accuracy: 0.9004\n","Epoch 2912: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3317 - accuracy: 0.8993\n","Epoch 2913/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3262 - accuracy: 0.9016\n","Epoch 2913: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3320 - accuracy: 0.8999\n","Epoch 2914/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3319 - accuracy: 0.9014\n","Epoch 2914: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3331 - accuracy: 0.9010\n","Epoch 2915/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3360 - accuracy: 0.8965\n","Epoch 2915: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3332 - accuracy: 0.8974\n","Epoch 2916/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3335 - accuracy: 0.9007\n","Epoch 2916: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3343 - accuracy: 0.9006\n","Epoch 2917/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3355 - accuracy: 0.8994\n","Epoch 2917: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3349 - accuracy: 0.8992\n","Epoch 2918/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3319 - accuracy: 0.9025\n","Epoch 2918: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3331 - accuracy: 0.9012\n","Epoch 2919/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3331 - accuracy: 0.8996\n","Epoch 2919: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 57ms/step - loss: 0.3359 - accuracy: 0.8987\n","Epoch 2920/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3301 - accuracy: 0.9028\n","Epoch 2920: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3321 - accuracy: 0.9024\n","Epoch 2921/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3315 - accuracy: 0.9016\n","Epoch 2921: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3309 - accuracy: 0.9019\n","Epoch 2922/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3317 - accuracy: 0.9012\n","Epoch 2922: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3336 - accuracy: 0.9002\n","Epoch 2923/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3343 - accuracy: 0.9003\n","Epoch 2923: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3322 - accuracy: 0.9012\n","Epoch 2924/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3241 - accuracy: 0.9032\n","Epoch 2924: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3341 - accuracy: 0.9005\n","Epoch 2925/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3342 - accuracy: 0.8997\n","Epoch 2925: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3341 - accuracy: 0.8994\n","Epoch 2926/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3337 - accuracy: 0.9003\n","Epoch 2926: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3333 - accuracy: 0.9007\n","Epoch 2927/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3293 - accuracy: 0.8998\n","Epoch 2927: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3351 - accuracy: 0.8984\n","Epoch 2928/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3288 - accuracy: 0.9019\n","Epoch 2928: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3359 - accuracy: 0.8988\n","Epoch 2929/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3299 - accuracy: 0.9032\n","Epoch 2929: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3357 - accuracy: 0.9009\n","Epoch 2930/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3316 - accuracy: 0.9035\n","Epoch 2930: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3355 - accuracy: 0.9011\n","Epoch 2931/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3379 - accuracy: 0.8970\n","Epoch 2931: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3384 - accuracy: 0.8970\n","Epoch 2932/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3342 - accuracy: 0.9003\n","Epoch 2932: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3370 - accuracy: 0.8997\n","Epoch 2933/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3369 - accuracy: 0.9011\n","Epoch 2933: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3369 - accuracy: 0.9005\n","Epoch 2934/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3345 - accuracy: 0.8987\n","Epoch 2934: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 56ms/step - loss: 0.3332 - accuracy: 0.8989\n","Epoch 2935/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3295 - accuracy: 0.9000\n","Epoch 2935: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3307 - accuracy: 0.9002\n","Epoch 2936/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3293 - accuracy: 0.9014\n","Epoch 2936: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3352 - accuracy: 0.8996\n","Epoch 2937/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3319 - accuracy: 0.8963\n","Epoch 2937: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3299 - accuracy: 0.8976\n","Epoch 2938/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3307 - accuracy: 0.8998\n","Epoch 2938: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3340 - accuracy: 0.8990\n","Epoch 2939/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3235 - accuracy: 0.9021\n","Epoch 2939: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3300 - accuracy: 0.8996\n","Epoch 2940/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3286 - accuracy: 0.9016\n","Epoch 2940: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3333 - accuracy: 0.9002\n","Epoch 2941/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3301 - accuracy: 0.8996\n","Epoch 2941: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3344 - accuracy: 0.8992\n","Epoch 2942/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3352 - accuracy: 0.8986\n","Epoch 2942: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3369 - accuracy: 0.8990\n","Epoch 2943/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3348 - accuracy: 0.9036\n","Epoch 2943: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3351 - accuracy: 0.9027\n","Epoch 2944/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3286 - accuracy: 0.9008\n","Epoch 2944: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3309 - accuracy: 0.9002\n","Epoch 2945/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3359 - accuracy: 0.9000\n","Epoch 2945: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3343 - accuracy: 0.8998\n","Epoch 2946/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3303 - accuracy: 0.8975\n","Epoch 2946: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3321 - accuracy: 0.8977\n","Epoch 2947/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3300 - accuracy: 0.9015\n","Epoch 2947: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3313 - accuracy: 0.9009\n","Epoch 2948/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3306 - accuracy: 0.8987\n","Epoch 2948: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3287 - accuracy: 0.9001\n","Epoch 2949/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3272 - accuracy: 0.8996\n","Epoch 2949: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3306 - accuracy: 0.8989\n","Epoch 2950/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3266 - accuracy: 0.8993\n","Epoch 2950: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3285 - accuracy: 0.8983\n","Epoch 2951/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3300 - accuracy: 0.8986\n","Epoch 2951: loss improved from 0.32847 to 0.32644, saving model to best_model_3.hdf5\n","8/8 [==============================] - 1s 109ms/step - loss: 0.3264 - accuracy: 0.9003\n","Epoch 2952/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3210 - accuracy: 0.9019\n","Epoch 2952: loss improved from 0.32644 to 0.32579, saving model to best_model_3.hdf5\n","8/8 [==============================] - 1s 103ms/step - loss: 0.3258 - accuracy: 0.9006\n","Epoch 2953/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3293 - accuracy: 0.8990\n","Epoch 2953: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3297 - accuracy: 0.8987\n","Epoch 2954/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3281 - accuracy: 0.9018\n","Epoch 2954: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3304 - accuracy: 0.9009\n","Epoch 2955/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3308 - accuracy: 0.8994\n","Epoch 2955: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 56ms/step - loss: 0.3316 - accuracy: 0.8994\n","Epoch 2956/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3236 - accuracy: 0.9019\n","Epoch 2956: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3319 - accuracy: 0.8999\n","Epoch 2957/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3302 - accuracy: 0.9025\n","Epoch 2957: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3319 - accuracy: 0.9018\n","Epoch 2958/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3275 - accuracy: 0.9009\n","Epoch 2958: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3300 - accuracy: 0.8999\n","Epoch 2959/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3262 - accuracy: 0.9039\n","Epoch 2959: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3318 - accuracy: 0.9018\n","Epoch 2960/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3296 - accuracy: 0.9003\n","Epoch 2960: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3333 - accuracy: 0.8987\n","Epoch 2961/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3317 - accuracy: 0.8986\n","Epoch 2961: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 56ms/step - loss: 0.3328 - accuracy: 0.8981\n","Epoch 2962/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3264 - accuracy: 0.9016\n","Epoch 2962: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3326 - accuracy: 0.9003\n","Epoch 2963/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3358 - accuracy: 0.9012\n","Epoch 2963: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3335 - accuracy: 0.9012\n","Epoch 2964/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3310 - accuracy: 0.9019\n","Epoch 2964: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3349 - accuracy: 0.9001\n","Epoch 2965/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3340 - accuracy: 0.9023\n","Epoch 2965: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3332 - accuracy: 0.9018\n","Epoch 2966/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3288 - accuracy: 0.9028\n","Epoch 2966: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3334 - accuracy: 0.9006\n","Epoch 2967/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3354 - accuracy: 0.8990\n","Epoch 2967: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3341 - accuracy: 0.8998\n","Epoch 2968/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3295 - accuracy: 0.9001\n","Epoch 2968: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3316 - accuracy: 0.8990\n","Epoch 2969/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3321 - accuracy: 0.9011\n","Epoch 2969: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3314 - accuracy: 0.9007\n","Epoch 2970/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3329 - accuracy: 0.9005\n","Epoch 2970: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3335 - accuracy: 0.8999\n","Epoch 2971/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3302 - accuracy: 0.9003\n","Epoch 2971: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3316 - accuracy: 0.8998\n","Epoch 2972/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3279 - accuracy: 0.9040\n","Epoch 2972: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3319 - accuracy: 0.9015\n","Epoch 2973/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3322 - accuracy: 0.9005\n","Epoch 2973: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3339 - accuracy: 0.9001\n","Epoch 2974/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3298 - accuracy: 0.9012\n","Epoch 2974: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3320 - accuracy: 0.9005\n","Epoch 2975/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3341 - accuracy: 0.8989\n","Epoch 2975: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3321 - accuracy: 0.8994\n","Epoch 2976/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3303 - accuracy: 0.9019\n","Epoch 2976: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3287 - accuracy: 0.9024\n","Epoch 2977/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3267 - accuracy: 0.9005\n","Epoch 2977: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3282 - accuracy: 0.9003\n","Epoch 2978/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3250 - accuracy: 0.9016\n","Epoch 2978: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3321 - accuracy: 0.8996\n","Epoch 2979/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3303 - accuracy: 0.9008\n","Epoch 2979: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3290 - accuracy: 0.8999\n","Epoch 2980/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3301 - accuracy: 0.8991\n","Epoch 2980: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3326 - accuracy: 0.8990\n","Epoch 2981/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3290 - accuracy: 0.9012\n","Epoch 2981: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3332 - accuracy: 0.8999\n","Epoch 2982/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3330 - accuracy: 0.8989\n","Epoch 2982: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3326 - accuracy: 0.8987\n","Epoch 2983/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3372 - accuracy: 0.8987\n","Epoch 2983: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3393 - accuracy: 0.8977\n","Epoch 2984/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3376 - accuracy: 0.9008\n","Epoch 2984: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3382 - accuracy: 0.9002\n","Epoch 2985/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3338 - accuracy: 0.9044\n","Epoch 2985: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3401 - accuracy: 0.9019\n","Epoch 2986/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3409 - accuracy: 0.8993\n","Epoch 2986: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3444 - accuracy: 0.8983\n","Epoch 2987/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3445 - accuracy: 0.9008\n","Epoch 2987: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3456 - accuracy: 0.8999\n","Epoch 2988/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3467 - accuracy: 0.9018\n","Epoch 2988: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3502 - accuracy: 0.9005\n","Epoch 2989/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3390 - accuracy: 0.9003\n","Epoch 2989: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3468 - accuracy: 0.8984\n","Epoch 2990/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3553 - accuracy: 0.8955\n","Epoch 2990: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3538 - accuracy: 0.8958\n","Epoch 2991/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3555 - accuracy: 0.8966\n","Epoch 2991: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3563 - accuracy: 0.8967\n","Epoch 2992/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3530 - accuracy: 0.8998\n","Epoch 2992: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3582 - accuracy: 0.8985\n","Epoch 2993/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3631 - accuracy: 0.8976\n","Epoch 2993: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3586 - accuracy: 0.8994\n","Epoch 2994/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3583 - accuracy: 0.8966\n","Epoch 2994: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3572 - accuracy: 0.8966\n","Epoch 2995/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3663 - accuracy: 0.8980\n","Epoch 2995: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3677 - accuracy: 0.8967\n","Epoch 2996/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3673 - accuracy: 0.8973\n","Epoch 2996: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3721 - accuracy: 0.8954\n","Epoch 2997/4000\n","8/8 [==============================] - ETA: 0s - loss: 0.3904 - accuracy: 0.8939\n","Epoch 2997: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3904 - accuracy: 0.8939\n","Epoch 2998/4000\n","8/8 [==============================] - ETA: 0s - loss: 0.3966 - accuracy: 0.8895\n","Epoch 2998: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 49ms/step - loss: 0.3966 - accuracy: 0.8895\n","Epoch 2999/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.4201 - accuracy: 0.8876\n","Epoch 2999: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 54ms/step - loss: 0.4272 - accuracy: 0.8862\n","Epoch 3000/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.4388 - accuracy: 0.8799\n","Epoch 3000: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 54ms/step - loss: 0.4444 - accuracy: 0.8778\n","Epoch 3001/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.4808 - accuracy: 0.8749\n","Epoch 3001: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 50ms/step - loss: 0.4890 - accuracy: 0.8730\n","Epoch 3002/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.5292 - accuracy: 0.8655\n","Epoch 3002: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 50ms/step - loss: 0.5334 - accuracy: 0.8629\n","Epoch 3003/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.5899 - accuracy: 0.8523\n","Epoch 3003: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 53ms/step - loss: 0.5964 - accuracy: 0.8499\n","Epoch 3004/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.6230 - accuracy: 0.8436\n","Epoch 3004: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 52ms/step - loss: 0.6330 - accuracy: 0.8420\n","Epoch 3005/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.7175 - accuracy: 0.8306\n","Epoch 3005: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 51ms/step - loss: 0.7262 - accuracy: 0.8282\n","Epoch 3006/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.7358 - accuracy: 0.8227\n","Epoch 3006: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 54ms/step - loss: 0.7459 - accuracy: 0.8203\n","Epoch 3007/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.6986 - accuracy: 0.8361\n","Epoch 3007: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 53ms/step - loss: 0.7088 - accuracy: 0.8328\n","Epoch 3008/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.7198 - accuracy: 0.8316\n","Epoch 3008: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 52ms/step - loss: 0.7284 - accuracy: 0.8306\n","Epoch 3009/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.7276 - accuracy: 0.8387\n","Epoch 3009: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 56ms/step - loss: 0.7343 - accuracy: 0.8379\n","Epoch 3010/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.6929 - accuracy: 0.8432\n","Epoch 3010: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 54ms/step - loss: 0.6942 - accuracy: 0.8420\n","Epoch 3011/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.6491 - accuracy: 0.8525\n","Epoch 3011: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 51ms/step - loss: 0.6547 - accuracy: 0.8505\n","Epoch 3012/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.6343 - accuracy: 0.8590\n","Epoch 3012: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 51ms/step - loss: 0.6366 - accuracy: 0.8583\n","Epoch 3013/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.6385 - accuracy: 0.8523\n","Epoch 3013: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 50ms/step - loss: 0.6443 - accuracy: 0.8512\n","Epoch 3014/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.6065 - accuracy: 0.8598\n","Epoch 3014: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 51ms/step - loss: 0.6102 - accuracy: 0.8572\n","Epoch 3015/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.5521 - accuracy: 0.8733\n","Epoch 3015: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 52ms/step - loss: 0.5554 - accuracy: 0.8726\n","Epoch 3016/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.5098 - accuracy: 0.8863\n","Epoch 3016: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 51ms/step - loss: 0.5125 - accuracy: 0.8845\n","Epoch 3017/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.4937 - accuracy: 0.8825\n","Epoch 3017: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 54ms/step - loss: 0.4982 - accuracy: 0.8812\n","Epoch 3018/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.4513 - accuracy: 0.8902\n","Epoch 3018: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 51ms/step - loss: 0.4515 - accuracy: 0.8901\n","Epoch 3019/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.4199 - accuracy: 0.8977\n","Epoch 3019: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 52ms/step - loss: 0.4258 - accuracy: 0.8962\n","Epoch 3020/4000\n","8/8 [==============================] - ETA: 0s - loss: 0.4077 - accuracy: 0.8975\n","Epoch 3020: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 50ms/step - loss: 0.4077 - accuracy: 0.8975\n","Epoch 3021/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3866 - accuracy: 0.9007\n","Epoch 3021: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3870 - accuracy: 0.9007\n","Epoch 3022/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3729 - accuracy: 0.9008\n","Epoch 3022: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3769 - accuracy: 0.9002\n","Epoch 3023/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3641 - accuracy: 0.9023\n","Epoch 3023: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3685 - accuracy: 0.9011\n","Epoch 3024/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3597 - accuracy: 0.9004\n","Epoch 3024: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3611 - accuracy: 0.8997\n","Epoch 3025/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3491 - accuracy: 0.9026\n","Epoch 3025: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3547 - accuracy: 0.9006\n","Epoch 3026/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3486 - accuracy: 0.9029\n","Epoch 3026: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3500 - accuracy: 0.9031\n","Epoch 3027/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3423 - accuracy: 0.9014\n","Epoch 3027: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3440 - accuracy: 0.9007\n","Epoch 3028/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3424 - accuracy: 0.9014\n","Epoch 3028: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3442 - accuracy: 0.9003\n","Epoch 3029/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3377 - accuracy: 0.9016\n","Epoch 3029: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3401 - accuracy: 0.8997\n","Epoch 3030/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3374 - accuracy: 0.8993\n","Epoch 3030: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3386 - accuracy: 0.8993\n","Epoch 3031/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3325 - accuracy: 0.9021\n","Epoch 3031: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3353 - accuracy: 0.9006\n","Epoch 3032/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3348 - accuracy: 0.9012\n","Epoch 3032: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3364 - accuracy: 0.9006\n","Epoch 3033/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3252 - accuracy: 0.9046\n","Epoch 3033: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3328 - accuracy: 0.9021\n","Epoch 3034/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3320 - accuracy: 0.9046\n","Epoch 3034: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3332 - accuracy: 0.9033\n","Epoch 3035/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3341 - accuracy: 0.9018\n","Epoch 3035: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3317 - accuracy: 0.9023\n","Epoch 3036/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3239 - accuracy: 0.9035\n","Epoch 3036: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3298 - accuracy: 0.9009\n","Epoch 3037/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3297 - accuracy: 0.9000\n","Epoch 3037: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3282 - accuracy: 0.9009\n","Epoch 3038/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3285 - accuracy: 0.9016\n","Epoch 3038: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3297 - accuracy: 0.9014\n","Epoch 3039/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3307 - accuracy: 0.8996\n","Epoch 3039: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3289 - accuracy: 0.9003\n","Epoch 3040/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3242 - accuracy: 0.9009\n","Epoch 3040: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3265 - accuracy: 0.9001\n","Epoch 3041/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3240 - accuracy: 0.9011\n","Epoch 3041: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3268 - accuracy: 0.8992\n","Epoch 3042/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3246 - accuracy: 0.9012\n","Epoch 3042: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3294 - accuracy: 0.9002\n","Epoch 3043/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3277 - accuracy: 0.9022\n","Epoch 3043: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3289 - accuracy: 0.9021\n","Epoch 3044/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3307 - accuracy: 0.9008\n","Epoch 3044: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3304 - accuracy: 0.9010\n","Epoch 3045/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3297 - accuracy: 0.8994\n","Epoch 3045: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3289 - accuracy: 0.8996\n","Epoch 3046/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3225 - accuracy: 0.9032\n","Epoch 3046: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3270 - accuracy: 0.9009\n","Epoch 3047/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3303 - accuracy: 0.9014\n","Epoch 3047: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3294 - accuracy: 0.9014\n","Epoch 3048/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3238 - accuracy: 0.9021\n","Epoch 3048: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3279 - accuracy: 0.9006\n","Epoch 3049/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3307 - accuracy: 0.8998\n","Epoch 3049: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3288 - accuracy: 0.9003\n","Epoch 3050/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3202 - accuracy: 0.9036\n","Epoch 3050: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3272 - accuracy: 0.9009\n","Epoch 3051/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3209 - accuracy: 0.9018\n","Epoch 3051: loss improved from 0.32579 to 0.32540, saving model to best_model_3.hdf5\n","8/8 [==============================] - 1s 109ms/step - loss: 0.3254 - accuracy: 0.8997\n","Epoch 3052/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3224 - accuracy: 0.9016\n","Epoch 3052: loss did not improve from 0.32540\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3266 - accuracy: 0.8999\n","Epoch 3053/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3306 - accuracy: 0.8990\n","Epoch 3053: loss did not improve from 0.32540\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3280 - accuracy: 0.9001\n","Epoch 3054/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3254 - accuracy: 0.9029\n","Epoch 3054: loss did not improve from 0.32540\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3285 - accuracy: 0.9010\n","Epoch 3055/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3256 - accuracy: 0.9009\n","Epoch 3055: loss did not improve from 0.32540\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3277 - accuracy: 0.8999\n","Epoch 3056/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3274 - accuracy: 0.9019\n","Epoch 3056: loss did not improve from 0.32540\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3296 - accuracy: 0.9014\n","Epoch 3057/4000\n","8/8 [==============================] - ETA: 0s - loss: 0.3250 - accuracy: 0.9029\n","Epoch 3057: loss improved from 0.32540 to 0.32498, saving model to best_model_3.hdf5\n","8/8 [==============================] - 1s 111ms/step - loss: 0.3250 - accuracy: 0.9029\n","Epoch 3058/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3281 - accuracy: 0.9004\n","Epoch 3058: loss did not improve from 0.32498\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3282 - accuracy: 0.9003\n","Epoch 3059/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3223 - accuracy: 0.9033\n","Epoch 3059: loss did not improve from 0.32498\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3260 - accuracy: 0.9020\n","Epoch 3060/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3264 - accuracy: 0.9005\n","Epoch 3060: loss improved from 0.32498 to 0.32382, saving model to best_model_3.hdf5\n","8/8 [==============================] - 1s 92ms/step - loss: 0.3238 - accuracy: 0.9011\n","Epoch 3061/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3318 - accuracy: 0.8991\n","Epoch 3061: loss did not improve from 0.32382\n","8/8 [==============================] - 0s 56ms/step - loss: 0.3281 - accuracy: 0.9001\n","Epoch 3062/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3184 - accuracy: 0.9043\n","Epoch 3062: loss did not improve from 0.32382\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3249 - accuracy: 0.9025\n","Epoch 3063/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3252 - accuracy: 0.9019\n","Epoch 3063: loss did not improve from 0.32382\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3270 - accuracy: 0.9014\n","Epoch 3064/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3218 - accuracy: 0.9042\n","Epoch 3064: loss did not improve from 0.32382\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3251 - accuracy: 0.9023\n","Epoch 3065/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3279 - accuracy: 0.9015\n","Epoch 3065: loss did not improve from 0.32382\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3297 - accuracy: 0.9007\n","Epoch 3066/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3209 - accuracy: 0.9018\n","Epoch 3066: loss did not improve from 0.32382\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3261 - accuracy: 0.9001\n","Epoch 3067/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3246 - accuracy: 0.9015\n","Epoch 3067: loss did not improve from 0.32382\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3266 - accuracy: 0.9006\n","Epoch 3068/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3242 - accuracy: 0.9016\n","Epoch 3068: loss did not improve from 0.32382\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3254 - accuracy: 0.9012\n","Epoch 3069/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3234 - accuracy: 0.9016\n","Epoch 3069: loss did not improve from 0.32382\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3272 - accuracy: 0.9009\n","Epoch 3070/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3196 - accuracy: 0.8989\n","Epoch 3070: loss did not improve from 0.32382\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3238 - accuracy: 0.8977\n","Epoch 3071/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3222 - accuracy: 0.9001\n","Epoch 3071: loss improved from 0.32382 to 0.32333, saving model to best_model_3.hdf5\n","8/8 [==============================] - 1s 103ms/step - loss: 0.3233 - accuracy: 0.9006\n","Epoch 3072/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3270 - accuracy: 0.9016\n","Epoch 3072: loss did not improve from 0.32333\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3296 - accuracy: 0.9007\n","Epoch 3073/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3237 - accuracy: 0.9016\n","Epoch 3073: loss did not improve from 0.32333\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3273 - accuracy: 0.8997\n","Epoch 3074/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3270 - accuracy: 0.8996\n","Epoch 3074: loss did not improve from 0.32333\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3296 - accuracy: 0.8996\n","Epoch 3075/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3233 - accuracy: 0.8994\n","Epoch 3075: loss did not improve from 0.32333\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3265 - accuracy: 0.8981\n","Epoch 3076/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3214 - accuracy: 0.9023\n","Epoch 3076: loss did not improve from 0.32333\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3272 - accuracy: 0.9003\n","Epoch 3077/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3248 - accuracy: 0.9008\n","Epoch 3077: loss improved from 0.32333 to 0.32275, saving model to best_model_3.hdf5\n","8/8 [==============================] - 1s 108ms/step - loss: 0.3228 - accuracy: 0.9019\n","Epoch 3078/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3250 - accuracy: 0.8975\n","Epoch 3078: loss did not improve from 0.32275\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3269 - accuracy: 0.8974\n","Epoch 3079/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3253 - accuracy: 0.9011\n","Epoch 3079: loss did not improve from 0.32275\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3257 - accuracy: 0.9010\n","Epoch 3080/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3196 - accuracy: 0.9018\n","Epoch 3080: loss did not improve from 0.32275\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3247 - accuracy: 0.8994\n","Epoch 3081/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3213 - accuracy: 0.9011\n","Epoch 3081: loss did not improve from 0.32275\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3232 - accuracy: 0.9001\n","Epoch 3082/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3214 - accuracy: 0.9026\n","Epoch 3082: loss did not improve from 0.32275\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3248 - accuracy: 0.9016\n","Epoch 3083/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3245 - accuracy: 0.9011\n","Epoch 3083: loss did not improve from 0.32275\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3266 - accuracy: 0.9001\n","Epoch 3084/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3256 - accuracy: 0.8993\n","Epoch 3084: loss did not improve from 0.32275\n","8/8 [==============================] - 0s 49ms/step - loss: 0.3255 - accuracy: 0.8992\n","Epoch 3085/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3176 - accuracy: 0.9046\n","Epoch 3085: loss improved from 0.32275 to 0.32239, saving model to best_model_3.hdf5\n","8/8 [==============================] - 1s 110ms/step - loss: 0.3224 - accuracy: 0.9021\n","Epoch 3086/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3208 - accuracy: 0.9026\n","Epoch 3086: loss did not improve from 0.32239\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3251 - accuracy: 0.9006\n","Epoch 3087/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3246 - accuracy: 0.8986\n","Epoch 3087: loss did not improve from 0.32239\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3267 - accuracy: 0.8977\n","Epoch 3088/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3236 - accuracy: 0.9008\n","Epoch 3088: loss did not improve from 0.32239\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3267 - accuracy: 0.8990\n","Epoch 3089/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3214 - accuracy: 0.9026\n","Epoch 3089: loss did not improve from 0.32239\n","8/8 [==============================] - 0s 56ms/step - loss: 0.3277 - accuracy: 0.9001\n","Epoch 3090/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3280 - accuracy: 0.9007\n","Epoch 3090: loss did not improve from 0.32239\n","8/8 [==============================] - 0s 48ms/step - loss: 0.3313 - accuracy: 0.8998\n","Epoch 3091/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3264 - accuracy: 0.9008\n","Epoch 3091: loss did not improve from 0.32239\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3269 - accuracy: 0.8999\n","Epoch 3092/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3201 - accuracy: 0.9043\n","Epoch 3092: loss did not improve from 0.32239\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3240 - accuracy: 0.9029\n","Epoch 3093/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3303 - accuracy: 0.8991\n","Epoch 3093: loss did not improve from 0.32239\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3271 - accuracy: 0.8996\n","Epoch 3094/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3280 - accuracy: 0.9032\n","Epoch 3094: loss did not improve from 0.32239\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3280 - accuracy: 0.9020\n","Epoch 3095/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3280 - accuracy: 0.8975\n","Epoch 3095: loss did not improve from 0.32239\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3250 - accuracy: 0.8988\n","Epoch 3096/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3203 - accuracy: 0.9029\n","Epoch 3096: loss did not improve from 0.32239\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3244 - accuracy: 0.9014\n","Epoch 3097/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3250 - accuracy: 0.9019\n","Epoch 3097: loss did not improve from 0.32239\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3241 - accuracy: 0.9018\n","Epoch 3098/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3186 - accuracy: 0.9044\n","Epoch 3098: loss did not improve from 0.32239\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3233 - accuracy: 0.9025\n","Epoch 3099/4000\n","8/8 [==============================] - ETA: 0s - loss: 0.3248 - accuracy: 0.9012\n","Epoch 3099: loss did not improve from 0.32239\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3248 - accuracy: 0.9012\n","Epoch 3100/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3328 - accuracy: 0.9003\n","Epoch 3100: loss did not improve from 0.32239\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3328 - accuracy: 0.8994\n","Epoch 3101/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3250 - accuracy: 0.9023\n","Epoch 3101: loss did not improve from 0.32239\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3268 - accuracy: 0.9015\n","Epoch 3102/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3275 - accuracy: 0.8991\n","Epoch 3102: loss did not improve from 0.32239\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3287 - accuracy: 0.8992\n","Epoch 3103/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3219 - accuracy: 0.9021\n","Epoch 3103: loss did not improve from 0.32239\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3279 - accuracy: 0.8989\n","Epoch 3104/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3264 - accuracy: 0.9032\n","Epoch 3104: loss did not improve from 0.32239\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3278 - accuracy: 0.9028\n","Epoch 3105/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3225 - accuracy: 0.9019\n","Epoch 3105: loss did not improve from 0.32239\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3287 - accuracy: 0.8997\n","Epoch 3106/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3274 - accuracy: 0.9005\n","Epoch 3106: loss did not improve from 0.32239\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3276 - accuracy: 0.9007\n","Epoch 3107/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3260 - accuracy: 0.8997\n","Epoch 3107: loss did not improve from 0.32239\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3247 - accuracy: 0.9001\n","Epoch 3108/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3183 - accuracy: 0.9035\n","Epoch 3108: loss did not improve from 0.32239\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3251 - accuracy: 0.9011\n","Epoch 3109/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3221 - accuracy: 0.9026\n","Epoch 3109: loss did not improve from 0.32239\n","8/8 [==============================] - 0s 49ms/step - loss: 0.3264 - accuracy: 0.9009\n","Epoch 3110/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3270 - accuracy: 0.9007\n","Epoch 3110: loss did not improve from 0.32239\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3277 - accuracy: 0.9002\n","Epoch 3111/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3225 - accuracy: 0.9016\n","Epoch 3111: loss did not improve from 0.32239\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3245 - accuracy: 0.9011\n","Epoch 3112/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3262 - accuracy: 0.9008\n","Epoch 3112: loss did not improve from 0.32239\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3259 - accuracy: 0.9009\n","Epoch 3113/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3280 - accuracy: 0.8986\n","Epoch 3113: loss did not improve from 0.32239\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3257 - accuracy: 0.8996\n","Epoch 3114/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3209 - accuracy: 0.9012\n","Epoch 3114: loss improved from 0.32239 to 0.32175, saving model to best_model_3.hdf5\n","8/8 [==============================] - 1s 108ms/step - loss: 0.3217 - accuracy: 0.9015\n","Epoch 3115/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3209 - accuracy: 0.9011\n","Epoch 3115: loss did not improve from 0.32175\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3250 - accuracy: 0.8998\n","Epoch 3116/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3240 - accuracy: 0.9046\n","Epoch 3116: loss did not improve from 0.32175\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3270 - accuracy: 0.9033\n","Epoch 3117/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3232 - accuracy: 0.9007\n","Epoch 3117: loss did not improve from 0.32175\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3265 - accuracy: 0.8990\n","Epoch 3118/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3177 - accuracy: 0.9025\n","Epoch 3118: loss improved from 0.32175 to 0.32123, saving model to best_model_3.hdf5\n","8/8 [==============================] - 1s 106ms/step - loss: 0.3212 - accuracy: 0.9018\n","Epoch 3119/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3273 - accuracy: 0.9014\n","Epoch 3119: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3297 - accuracy: 0.9003\n","Epoch 3120/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3312 - accuracy: 0.9000\n","Epoch 3120: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3281 - accuracy: 0.9014\n","Epoch 3121/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3258 - accuracy: 0.9028\n","Epoch 3121: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3274 - accuracy: 0.9016\n","Epoch 3122/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3194 - accuracy: 0.9032\n","Epoch 3122: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3266 - accuracy: 0.9009\n","Epoch 3123/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3251 - accuracy: 0.9001\n","Epoch 3123: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3251 - accuracy: 0.8998\n","Epoch 3124/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3236 - accuracy: 0.9014\n","Epoch 3124: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3280 - accuracy: 0.9003\n","Epoch 3125/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3271 - accuracy: 0.9029\n","Epoch 3125: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3271 - accuracy: 0.9023\n","Epoch 3126/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3246 - accuracy: 0.9003\n","Epoch 3126: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3246 - accuracy: 0.9007\n","Epoch 3127/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3280 - accuracy: 0.9009\n","Epoch 3127: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3247 - accuracy: 0.9016\n","Epoch 3128/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3224 - accuracy: 0.9019\n","Epoch 3128: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3246 - accuracy: 0.9012\n","Epoch 3129/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3291 - accuracy: 0.9023\n","Epoch 3129: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3270 - accuracy: 0.9021\n","Epoch 3130/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3211 - accuracy: 0.9015\n","Epoch 3130: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3247 - accuracy: 0.9006\n","Epoch 3131/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3208 - accuracy: 0.9011\n","Epoch 3131: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3242 - accuracy: 0.8998\n","Epoch 3132/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3192 - accuracy: 0.9012\n","Epoch 3132: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3219 - accuracy: 0.9005\n","Epoch 3133/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3250 - accuracy: 0.9018\n","Epoch 3133: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3267 - accuracy: 0.9014\n","Epoch 3134/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3222 - accuracy: 0.9001\n","Epoch 3134: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3245 - accuracy: 0.8998\n","Epoch 3135/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3208 - accuracy: 0.9036\n","Epoch 3135: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3245 - accuracy: 0.9018\n","Epoch 3136/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3175 - accuracy: 0.9028\n","Epoch 3136: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3241 - accuracy: 0.9003\n","Epoch 3137/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3221 - accuracy: 0.9003\n","Epoch 3137: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3228 - accuracy: 0.8996\n","Epoch 3138/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3204 - accuracy: 0.9030\n","Epoch 3138: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3257 - accuracy: 0.9016\n","Epoch 3139/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3271 - accuracy: 0.9008\n","Epoch 3139: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 56ms/step - loss: 0.3296 - accuracy: 0.9006\n","Epoch 3140/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3280 - accuracy: 0.9014\n","Epoch 3140: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3306 - accuracy: 0.8998\n","Epoch 3141/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3223 - accuracy: 0.9019\n","Epoch 3141: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3269 - accuracy: 0.8997\n","Epoch 3142/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3290 - accuracy: 0.8994\n","Epoch 3142: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3274 - accuracy: 0.8997\n","Epoch 3143/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3207 - accuracy: 0.9053\n","Epoch 3143: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3251 - accuracy: 0.9034\n","Epoch 3144/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3244 - accuracy: 0.9004\n","Epoch 3144: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3284 - accuracy: 0.8990\n","Epoch 3145/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3277 - accuracy: 0.9007\n","Epoch 3145: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3282 - accuracy: 0.8999\n","Epoch 3146/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3222 - accuracy: 0.9028\n","Epoch 3146: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3267 - accuracy: 0.9010\n","Epoch 3147/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3243 - accuracy: 0.9000\n","Epoch 3147: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3248 - accuracy: 0.8999\n","Epoch 3148/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3293 - accuracy: 0.8989\n","Epoch 3148: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3303 - accuracy: 0.8981\n","Epoch 3149/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3236 - accuracy: 0.9026\n","Epoch 3149: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3257 - accuracy: 0.9015\n","Epoch 3150/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3269 - accuracy: 0.9016\n","Epoch 3150: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3289 - accuracy: 0.9005\n","Epoch 3151/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3285 - accuracy: 0.9012\n","Epoch 3151: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3290 - accuracy: 0.9011\n","Epoch 3152/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3286 - accuracy: 0.8996\n","Epoch 3152: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3257 - accuracy: 0.8994\n","Epoch 3153/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3203 - accuracy: 0.9016\n","Epoch 3153: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3245 - accuracy: 0.8996\n","Epoch 3154/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3255 - accuracy: 0.8991\n","Epoch 3154: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3270 - accuracy: 0.8983\n","Epoch 3155/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3215 - accuracy: 0.9032\n","Epoch 3155: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3244 - accuracy: 0.9020\n","Epoch 3156/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3240 - accuracy: 0.9004\n","Epoch 3156: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3300 - accuracy: 0.8990\n","Epoch 3157/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3275 - accuracy: 0.9021\n","Epoch 3157: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3287 - accuracy: 0.9019\n","Epoch 3158/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3261 - accuracy: 0.9009\n","Epoch 3158: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3303 - accuracy: 0.8990\n","Epoch 3159/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3289 - accuracy: 0.9004\n","Epoch 3159: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3279 - accuracy: 0.9009\n","Epoch 3160/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3300 - accuracy: 0.8998\n","Epoch 3160: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3287 - accuracy: 0.9005\n","Epoch 3161/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3203 - accuracy: 0.9008\n","Epoch 3161: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3268 - accuracy: 0.8999\n","Epoch 3162/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3273 - accuracy: 0.9001\n","Epoch 3162: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3284 - accuracy: 0.8987\n","Epoch 3163/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3263 - accuracy: 0.8997\n","Epoch 3163: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3247 - accuracy: 0.8999\n","Epoch 3164/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3243 - accuracy: 0.9007\n","Epoch 3164: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3294 - accuracy: 0.8985\n","Epoch 3165/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3272 - accuracy: 0.9030\n","Epoch 3165: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3282 - accuracy: 0.9023\n","Epoch 3166/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3274 - accuracy: 0.9023\n","Epoch 3166: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3302 - accuracy: 0.9014\n","Epoch 3167/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3292 - accuracy: 0.9003\n","Epoch 3167: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3300 - accuracy: 0.8993\n","Epoch 3168/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3259 - accuracy: 0.9019\n","Epoch 3168: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3282 - accuracy: 0.9007\n","Epoch 3169/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3285 - accuracy: 0.8984\n","Epoch 3169: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3273 - accuracy: 0.8989\n","Epoch 3170/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3213 - accuracy: 0.9009\n","Epoch 3170: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3234 - accuracy: 0.8994\n","Epoch 3171/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3201 - accuracy: 0.9026\n","Epoch 3171: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3248 - accuracy: 0.9011\n","Epoch 3172/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3280 - accuracy: 0.9003\n","Epoch 3172: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3278 - accuracy: 0.9007\n","Epoch 3173/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3250 - accuracy: 0.9019\n","Epoch 3173: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3256 - accuracy: 0.9014\n","Epoch 3174/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3284 - accuracy: 0.9007\n","Epoch 3174: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3287 - accuracy: 0.8996\n","Epoch 3175/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3239 - accuracy: 0.9015\n","Epoch 3175: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 48ms/step - loss: 0.3253 - accuracy: 0.9009\n","Epoch 3176/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3210 - accuracy: 0.9040\n","Epoch 3176: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3253 - accuracy: 0.9025\n","Epoch 3177/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3261 - accuracy: 0.9028\n","Epoch 3177: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3294 - accuracy: 0.9015\n","Epoch 3178/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3244 - accuracy: 0.9012\n","Epoch 3178: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3262 - accuracy: 0.8990\n","Epoch 3179/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3211 - accuracy: 0.9009\n","Epoch 3179: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3236 - accuracy: 0.9007\n","Epoch 3180/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3232 - accuracy: 0.9029\n","Epoch 3180: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3259 - accuracy: 0.9020\n","Epoch 3181/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3238 - accuracy: 0.9019\n","Epoch 3181: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3247 - accuracy: 0.9010\n","Epoch 3182/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3246 - accuracy: 0.9018\n","Epoch 3182: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3261 - accuracy: 0.9010\n","Epoch 3183/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3289 - accuracy: 0.8990\n","Epoch 3183: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3266 - accuracy: 0.8992\n","Epoch 3184/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3237 - accuracy: 0.8986\n","Epoch 3184: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 56ms/step - loss: 0.3267 - accuracy: 0.8983\n","Epoch 3185/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3239 - accuracy: 0.9011\n","Epoch 3185: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3247 - accuracy: 0.9014\n","Epoch 3186/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3251 - accuracy: 0.9003\n","Epoch 3186: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3235 - accuracy: 0.9005\n","Epoch 3187/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3249 - accuracy: 0.8994\n","Epoch 3187: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3273 - accuracy: 0.8987\n","Epoch 3188/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3250 - accuracy: 0.9026\n","Epoch 3188: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3254 - accuracy: 0.9031\n","Epoch 3189/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3225 - accuracy: 0.9007\n","Epoch 3189: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3247 - accuracy: 0.8997\n","Epoch 3190/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3244 - accuracy: 0.9008\n","Epoch 3190: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3249 - accuracy: 0.9009\n","Epoch 3191/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3235 - accuracy: 0.9004\n","Epoch 3191: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3231 - accuracy: 0.8999\n","Epoch 3192/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3220 - accuracy: 0.9018\n","Epoch 3192: loss improved from 0.32123 to 0.32110, saving model to best_model_3.hdf5\n","8/8 [==============================] - 1s 106ms/step - loss: 0.3211 - accuracy: 0.9019\n","Epoch 3193/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3191 - accuracy: 0.8998\n","Epoch 3193: loss improved from 0.32110 to 0.32027, saving model to best_model_3.hdf5\n","8/8 [==============================] - 1s 98ms/step - loss: 0.3203 - accuracy: 0.8993\n","Epoch 3194/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3198 - accuracy: 0.9012\n","Epoch 3194: loss did not improve from 0.32027\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3208 - accuracy: 0.9006\n","Epoch 3195/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3171 - accuracy: 0.9019\n","Epoch 3195: loss did not improve from 0.32027\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3216 - accuracy: 0.9005\n","Epoch 3196/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3176 - accuracy: 0.9019\n","Epoch 3196: loss did not improve from 0.32027\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3239 - accuracy: 0.8992\n","Epoch 3197/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3229 - accuracy: 0.9023\n","Epoch 3197: loss did not improve from 0.32027\n","8/8 [==============================] - 0s 49ms/step - loss: 0.3235 - accuracy: 0.9021\n","Epoch 3198/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3284 - accuracy: 0.9011\n","Epoch 3198: loss did not improve from 0.32027\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3287 - accuracy: 0.9007\n","Epoch 3199/4000\n","8/8 [==============================] - ETA: 0s - loss: 0.3280 - accuracy: 0.9010\n","Epoch 3199: loss did not improve from 0.32027\n","8/8 [==============================] - 0s 48ms/step - loss: 0.3280 - accuracy: 0.9010\n","Epoch 3200/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3191 - accuracy: 0.9011\n","Epoch 3200: loss did not improve from 0.32027\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3237 - accuracy: 0.9003\n","Epoch 3201/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3233 - accuracy: 0.9004\n","Epoch 3201: loss did not improve from 0.32027\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3241 - accuracy: 0.8997\n","Epoch 3202/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3214 - accuracy: 0.9012\n","Epoch 3202: loss did not improve from 0.32027\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3249 - accuracy: 0.9001\n","Epoch 3203/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3274 - accuracy: 0.8965\n","Epoch 3203: loss did not improve from 0.32027\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3245 - accuracy: 0.8977\n","Epoch 3204/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3193 - accuracy: 0.9021\n","Epoch 3204: loss did not improve from 0.32027\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3246 - accuracy: 0.9006\n","Epoch 3205/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3272 - accuracy: 0.9025\n","Epoch 3205: loss did not improve from 0.32027\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3247 - accuracy: 0.9027\n","Epoch 3206/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3302 - accuracy: 0.9007\n","Epoch 3206: loss did not improve from 0.32027\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3322 - accuracy: 0.9011\n","Epoch 3207/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3306 - accuracy: 0.9009\n","Epoch 3207: loss did not improve from 0.32027\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3349 - accuracy: 0.8994\n","Epoch 3208/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3259 - accuracy: 0.9012\n","Epoch 3208: loss did not improve from 0.32027\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3359 - accuracy: 0.8981\n","Epoch 3209/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3351 - accuracy: 0.8998\n","Epoch 3209: loss did not improve from 0.32027\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3371 - accuracy: 0.8993\n","Epoch 3210/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3337 - accuracy: 0.8994\n","Epoch 3210: loss did not improve from 0.32027\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3349 - accuracy: 0.8984\n","Epoch 3211/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3296 - accuracy: 0.9030\n","Epoch 3211: loss did not improve from 0.32027\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3352 - accuracy: 0.9016\n","Epoch 3212/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3340 - accuracy: 0.8970\n","Epoch 3212: loss did not improve from 0.32027\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3348 - accuracy: 0.8975\n","Epoch 3213/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3269 - accuracy: 0.9032\n","Epoch 3213: loss did not improve from 0.32027\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3321 - accuracy: 0.9023\n","Epoch 3214/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3283 - accuracy: 0.8994\n","Epoch 3214: loss did not improve from 0.32027\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3293 - accuracy: 0.8996\n","Epoch 3215/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3305 - accuracy: 0.8982\n","Epoch 3215: loss did not improve from 0.32027\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3334 - accuracy: 0.8975\n","Epoch 3216/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3267 - accuracy: 0.8986\n","Epoch 3216: loss did not improve from 0.32027\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3261 - accuracy: 0.8980\n","Epoch 3217/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3265 - accuracy: 0.9019\n","Epoch 3217: loss did not improve from 0.32027\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3238 - accuracy: 0.9033\n","Epoch 3218/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3273 - accuracy: 0.8997\n","Epoch 3218: loss did not improve from 0.32027\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3259 - accuracy: 0.8998\n","Epoch 3219/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3197 - accuracy: 0.9009\n","Epoch 3219: loss did not improve from 0.32027\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3227 - accuracy: 0.8999\n","Epoch 3220/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3260 - accuracy: 0.9007\n","Epoch 3220: loss did not improve from 0.32027\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3255 - accuracy: 0.9011\n","Epoch 3221/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3259 - accuracy: 0.9007\n","Epoch 3221: loss did not improve from 0.32027\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3244 - accuracy: 0.9011\n","Epoch 3222/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3184 - accuracy: 0.9007\n","Epoch 3222: loss did not improve from 0.32027\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3222 - accuracy: 0.8994\n","Epoch 3223/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3214 - accuracy: 0.9003\n","Epoch 3223: loss did not improve from 0.32027\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3230 - accuracy: 0.8992\n","Epoch 3224/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3278 - accuracy: 0.8987\n","Epoch 3224: loss did not improve from 0.32027\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3258 - accuracy: 0.8996\n","Epoch 3225/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3172 - accuracy: 0.9026\n","Epoch 3225: loss did not improve from 0.32027\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3244 - accuracy: 0.9002\n","Epoch 3226/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3251 - accuracy: 0.8996\n","Epoch 3226: loss did not improve from 0.32027\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3255 - accuracy: 0.8997\n","Epoch 3227/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3200 - accuracy: 0.8997\n","Epoch 3227: loss did not improve from 0.32027\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3222 - accuracy: 0.9001\n","Epoch 3228/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3211 - accuracy: 0.9007\n","Epoch 3228: loss did not improve from 0.32027\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3216 - accuracy: 0.9005\n","Epoch 3229/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3266 - accuracy: 0.8991\n","Epoch 3229: loss did not improve from 0.32027\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3232 - accuracy: 0.9009\n","Epoch 3230/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3204 - accuracy: 0.8990\n","Epoch 3230: loss did not improve from 0.32027\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3207 - accuracy: 0.8990\n","Epoch 3231/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3235 - accuracy: 0.9015\n","Epoch 3231: loss did not improve from 0.32027\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3240 - accuracy: 0.9018\n","Epoch 3232/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3237 - accuracy: 0.8998\n","Epoch 3232: loss did not improve from 0.32027\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3241 - accuracy: 0.8996\n","Epoch 3233/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3240 - accuracy: 0.9003\n","Epoch 3233: loss did not improve from 0.32027\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3238 - accuracy: 0.8996\n","Epoch 3234/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3267 - accuracy: 0.8989\n","Epoch 3234: loss did not improve from 0.32027\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3248 - accuracy: 0.8994\n","Epoch 3235/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3294 - accuracy: 0.8994\n","Epoch 3235: loss did not improve from 0.32027\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3236 - accuracy: 0.8998\n","Epoch 3236/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3220 - accuracy: 0.8987\n","Epoch 3236: loss did not improve from 0.32027\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3240 - accuracy: 0.8983\n","Epoch 3237/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3179 - accuracy: 0.9025\n","Epoch 3237: loss did not improve from 0.32027\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3212 - accuracy: 0.9019\n","Epoch 3238/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3271 - accuracy: 0.9012\n","Epoch 3238: loss did not improve from 0.32027\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3258 - accuracy: 0.9014\n","Epoch 3239/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3209 - accuracy: 0.9021\n","Epoch 3239: loss did not improve from 0.32027\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3218 - accuracy: 0.9016\n","Epoch 3240/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3222 - accuracy: 0.9001\n","Epoch 3240: loss improved from 0.32027 to 0.32010, saving model to best_model_3.hdf5\n","8/8 [==============================] - 1s 114ms/step - loss: 0.3201 - accuracy: 0.9009\n","Epoch 3241/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3246 - accuracy: 0.8997\n","Epoch 3241: loss did not improve from 0.32010\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3240 - accuracy: 0.8994\n","Epoch 3242/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3164 - accuracy: 0.9018\n","Epoch 3242: loss did not improve from 0.32010\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3205 - accuracy: 0.9006\n","Epoch 3243/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3241 - accuracy: 0.9016\n","Epoch 3243: loss did not improve from 0.32010\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3259 - accuracy: 0.9001\n","Epoch 3244/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3287 - accuracy: 0.8983\n","Epoch 3244: loss did not improve from 0.32010\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3281 - accuracy: 0.8988\n","Epoch 3245/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3226 - accuracy: 0.9014\n","Epoch 3245: loss did not improve from 0.32010\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3239 - accuracy: 0.9012\n","Epoch 3246/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3158 - accuracy: 0.9040\n","Epoch 3246: loss did not improve from 0.32010\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3222 - accuracy: 0.9016\n","Epoch 3247/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3240 - accuracy: 0.8987\n","Epoch 3247: loss did not improve from 0.32010\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3247 - accuracy: 0.8983\n","Epoch 3248/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3217 - accuracy: 0.8987\n","Epoch 3248: loss did not improve from 0.32010\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3210 - accuracy: 0.8989\n","Epoch 3249/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3235 - accuracy: 0.9011\n","Epoch 3249: loss did not improve from 0.32010\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3259 - accuracy: 0.8996\n","Epoch 3250/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3136 - accuracy: 0.9015\n","Epoch 3250: loss improved from 0.32010 to 0.31912, saving model to best_model_3.hdf5\n","8/8 [==============================] - 1s 108ms/step - loss: 0.3191 - accuracy: 0.8996\n","Epoch 3251/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3232 - accuracy: 0.8998\n","Epoch 3251: loss did not improve from 0.31912\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3253 - accuracy: 0.8989\n","Epoch 3252/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3202 - accuracy: 0.9018\n","Epoch 3252: loss did not improve from 0.31912\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3242 - accuracy: 0.8998\n","Epoch 3253/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3223 - accuracy: 0.9018\n","Epoch 3253: loss did not improve from 0.31912\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3253 - accuracy: 0.9009\n","Epoch 3254/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3237 - accuracy: 0.9001\n","Epoch 3254: loss did not improve from 0.31912\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3233 - accuracy: 0.9001\n","Epoch 3255/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3220 - accuracy: 0.9019\n","Epoch 3255: loss did not improve from 0.31912\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3237 - accuracy: 0.9007\n","Epoch 3256/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3234 - accuracy: 0.8996\n","Epoch 3256: loss did not improve from 0.31912\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3233 - accuracy: 0.8992\n","Epoch 3257/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3192 - accuracy: 0.9022\n","Epoch 3257: loss did not improve from 0.31912\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3241 - accuracy: 0.9003\n","Epoch 3258/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3260 - accuracy: 0.9009\n","Epoch 3258: loss did not improve from 0.31912\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3249 - accuracy: 0.9014\n","Epoch 3259/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3223 - accuracy: 0.9001\n","Epoch 3259: loss did not improve from 0.31912\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3220 - accuracy: 0.8994\n","Epoch 3260/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3228 - accuracy: 0.9007\n","Epoch 3260: loss did not improve from 0.31912\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3218 - accuracy: 0.9009\n","Epoch 3261/4000\n","8/8 [==============================] - ETA: 0s - loss: 0.3191 - accuracy: 0.9009\n","Epoch 3261: loss improved from 0.31912 to 0.31911, saving model to best_model_3.hdf5\n","8/8 [==============================] - 1s 103ms/step - loss: 0.3191 - accuracy: 0.9009\n","Epoch 3262/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3128 - accuracy: 0.9039\n","Epoch 3262: loss improved from 0.31911 to 0.31749, saving model to best_model_3.hdf5\n","8/8 [==============================] - 1s 105ms/step - loss: 0.3175 - accuracy: 0.9024\n","Epoch 3263/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3188 - accuracy: 0.8997\n","Epoch 3263: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3180 - accuracy: 0.8990\n","Epoch 3264/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3269 - accuracy: 0.8977\n","Epoch 3264: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3244 - accuracy: 0.8976\n","Epoch 3265/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3235 - accuracy: 0.9028\n","Epoch 3265: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3238 - accuracy: 0.9031\n","Epoch 3266/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3218 - accuracy: 0.9009\n","Epoch 3266: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3267 - accuracy: 0.8994\n","Epoch 3267/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3291 - accuracy: 0.8994\n","Epoch 3267: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3284 - accuracy: 0.8997\n","Epoch 3268/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3221 - accuracy: 0.9029\n","Epoch 3268: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3250 - accuracy: 0.9010\n","Epoch 3269/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3274 - accuracy: 0.9012\n","Epoch 3269: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3271 - accuracy: 0.9014\n","Epoch 3270/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3209 - accuracy: 0.9008\n","Epoch 3270: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3255 - accuracy: 0.8994\n","Epoch 3271/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3275 - accuracy: 0.9005\n","Epoch 3271: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3286 - accuracy: 0.8996\n","Epoch 3272/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3174 - accuracy: 0.9054\n","Epoch 3272: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3246 - accuracy: 0.9027\n","Epoch 3273/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3259 - accuracy: 0.9015\n","Epoch 3273: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 49ms/step - loss: 0.3265 - accuracy: 0.9010\n","Epoch 3274/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3225 - accuracy: 0.9035\n","Epoch 3274: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3306 - accuracy: 0.9009\n","Epoch 3275/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3343 - accuracy: 0.8986\n","Epoch 3275: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3305 - accuracy: 0.8987\n","Epoch 3276/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3338 - accuracy: 0.8996\n","Epoch 3276: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3310 - accuracy: 0.9002\n","Epoch 3277/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3257 - accuracy: 0.9012\n","Epoch 3277: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3292 - accuracy: 0.8999\n","Epoch 3278/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3248 - accuracy: 0.9018\n","Epoch 3278: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3287 - accuracy: 0.9010\n","Epoch 3279/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3291 - accuracy: 0.9001\n","Epoch 3279: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3292 - accuracy: 0.8996\n","Epoch 3280/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3242 - accuracy: 0.9015\n","Epoch 3280: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3267 - accuracy: 0.9014\n","Epoch 3281/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3231 - accuracy: 0.8998\n","Epoch 3281: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3273 - accuracy: 0.8988\n","Epoch 3282/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3279 - accuracy: 0.9023\n","Epoch 3282: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3286 - accuracy: 0.9019\n","Epoch 3283/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3223 - accuracy: 0.9040\n","Epoch 3283: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3275 - accuracy: 0.9027\n","Epoch 3284/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3215 - accuracy: 0.9016\n","Epoch 3284: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3253 - accuracy: 0.9002\n","Epoch 3285/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3282 - accuracy: 0.9019\n","Epoch 3285: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3287 - accuracy: 0.9020\n","Epoch 3286/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3275 - accuracy: 0.9009\n","Epoch 3286: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3268 - accuracy: 0.9009\n","Epoch 3287/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3315 - accuracy: 0.8997\n","Epoch 3287: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3301 - accuracy: 0.8999\n","Epoch 3288/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3209 - accuracy: 0.9016\n","Epoch 3288: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3265 - accuracy: 0.9001\n","Epoch 3289/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3238 - accuracy: 0.8993\n","Epoch 3289: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3269 - accuracy: 0.8979\n","Epoch 3290/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3222 - accuracy: 0.9008\n","Epoch 3290: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3258 - accuracy: 0.8999\n","Epoch 3291/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3249 - accuracy: 0.8984\n","Epoch 3291: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3214 - accuracy: 0.8999\n","Epoch 3292/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3216 - accuracy: 0.8989\n","Epoch 3292: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3224 - accuracy: 0.8987\n","Epoch 3293/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3171 - accuracy: 0.9021\n","Epoch 3293: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3232 - accuracy: 0.8998\n","Epoch 3294/4000\n","8/8 [==============================] - ETA: 0s - loss: 0.3210 - accuracy: 0.9011\n","Epoch 3294: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3210 - accuracy: 0.9011\n","Epoch 3295/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3151 - accuracy: 0.9029\n","Epoch 3295: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 49ms/step - loss: 0.3219 - accuracy: 0.8996\n","Epoch 3296/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3181 - accuracy: 0.9005\n","Epoch 3296: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3200 - accuracy: 0.9005\n","Epoch 3297/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3205 - accuracy: 0.9021\n","Epoch 3297: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3240 - accuracy: 0.9012\n","Epoch 3298/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3231 - accuracy: 0.9007\n","Epoch 3298: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3232 - accuracy: 0.9003\n","Epoch 3299/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3240 - accuracy: 0.9040\n","Epoch 3299: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3246 - accuracy: 0.9033\n","Epoch 3300/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3233 - accuracy: 0.9000\n","Epoch 3300: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 49ms/step - loss: 0.3241 - accuracy: 0.9003\n","Epoch 3301/4000\n","8/8 [==============================] - ETA: 0s - loss: 0.3224 - accuracy: 0.9011\n","Epoch 3301: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3224 - accuracy: 0.9011\n","Epoch 3302/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3165 - accuracy: 0.9001\n","Epoch 3302: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3229 - accuracy: 0.8974\n","Epoch 3303/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3263 - accuracy: 0.9003\n","Epoch 3303: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3265 - accuracy: 0.9003\n","Epoch 3304/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3195 - accuracy: 0.9028\n","Epoch 3304: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 56ms/step - loss: 0.3240 - accuracy: 0.9018\n","Epoch 3305/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3218 - accuracy: 0.9028\n","Epoch 3305: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3254 - accuracy: 0.8999\n","Epoch 3306/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3236 - accuracy: 0.9001\n","Epoch 3306: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3266 - accuracy: 0.8993\n","Epoch 3307/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3198 - accuracy: 0.9040\n","Epoch 3307: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3268 - accuracy: 0.9016\n","Epoch 3308/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3286 - accuracy: 0.8991\n","Epoch 3308: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3267 - accuracy: 0.9002\n","Epoch 3309/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3215 - accuracy: 0.9011\n","Epoch 3309: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3276 - accuracy: 0.8999\n","Epoch 3310/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3260 - accuracy: 0.9033\n","Epoch 3310: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3315 - accuracy: 0.9007\n","Epoch 3311/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3322 - accuracy: 0.9005\n","Epoch 3311: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3339 - accuracy: 0.9003\n","Epoch 3312/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3337 - accuracy: 0.9026\n","Epoch 3312: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3356 - accuracy: 0.9018\n","Epoch 3313/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3354 - accuracy: 0.8990\n","Epoch 3313: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3392 - accuracy: 0.8979\n","Epoch 3314/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3421 - accuracy: 0.9005\n","Epoch 3314: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3459 - accuracy: 0.8985\n","Epoch 3315/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3490 - accuracy: 0.8980\n","Epoch 3315: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3509 - accuracy: 0.8971\n","Epoch 3316/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3615 - accuracy: 0.8956\n","Epoch 3316: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3644 - accuracy: 0.8944\n","Epoch 3317/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3817 - accuracy: 0.8891\n","Epoch 3317: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3834 - accuracy: 0.8887\n","Epoch 3318/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.4273 - accuracy: 0.8806\n","Epoch 3318: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 49ms/step - loss: 0.4488 - accuracy: 0.8741\n","Epoch 3319/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.6032 - accuracy: 0.8415\n","Epoch 3319: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 52ms/step - loss: 0.6195 - accuracy: 0.8377\n","Epoch 3320/4000\n","8/8 [==============================] - ETA: 0s - loss: 0.7664 - accuracy: 0.8108\n","Epoch 3320: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 53ms/step - loss: 0.7664 - accuracy: 0.8108\n","Epoch 3321/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.7935 - accuracy: 0.8128\n","Epoch 3321: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 50ms/step - loss: 0.7940 - accuracy: 0.8121\n","Epoch 3322/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.8225 - accuracy: 0.8072\n","Epoch 3322: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 54ms/step - loss: 0.8319 - accuracy: 0.8055\n","Epoch 3323/4000\n","8/8 [==============================] - ETA: 0s - loss: 0.8590 - accuracy: 0.8078\n","Epoch 3323: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 50ms/step - loss: 0.8590 - accuracy: 0.8078\n","Epoch 3324/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.8113 - accuracy: 0.8175\n","Epoch 3324: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 53ms/step - loss: 0.8231 - accuracy: 0.8145\n","Epoch 3325/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.7663 - accuracy: 0.8337\n","Epoch 3325: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 51ms/step - loss: 0.7706 - accuracy: 0.8315\n","Epoch 3326/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.7193 - accuracy: 0.8390\n","Epoch 3326: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 52ms/step - loss: 0.7180 - accuracy: 0.8394\n","Epoch 3327/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.6497 - accuracy: 0.8601\n","Epoch 3327: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 51ms/step - loss: 0.6549 - accuracy: 0.8579\n","Epoch 3328/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.6068 - accuracy: 0.8676\n","Epoch 3328: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 53ms/step - loss: 0.6095 - accuracy: 0.8662\n","Epoch 3329/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.5761 - accuracy: 0.8733\n","Epoch 3329: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 52ms/step - loss: 0.5760 - accuracy: 0.8738\n","Epoch 3330/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.5264 - accuracy: 0.8845\n","Epoch 3330: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 55ms/step - loss: 0.5279 - accuracy: 0.8835\n","Epoch 3331/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.4850 - accuracy: 0.8910\n","Epoch 3331: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 52ms/step - loss: 0.4895 - accuracy: 0.8888\n","Epoch 3332/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.4567 - accuracy: 0.8915\n","Epoch 3332: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 54ms/step - loss: 0.4600 - accuracy: 0.8908\n","Epoch 3333/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.4304 - accuracy: 0.8961\n","Epoch 3333: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 52ms/step - loss: 0.4345 - accuracy: 0.8953\n","Epoch 3334/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.4147 - accuracy: 0.8989\n","Epoch 3334: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 53ms/step - loss: 0.4189 - accuracy: 0.8971\n","Epoch 3335/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3934 - accuracy: 0.9008\n","Epoch 3335: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3953 - accuracy: 0.8989\n","Epoch 3336/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3792 - accuracy: 0.8993\n","Epoch 3336: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3836 - accuracy: 0.8977\n","Epoch 3337/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3689 - accuracy: 0.9014\n","Epoch 3337: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3723 - accuracy: 0.8996\n","Epoch 3338/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3574 - accuracy: 0.9029\n","Epoch 3338: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3637 - accuracy: 0.9006\n","Epoch 3339/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3494 - accuracy: 0.9032\n","Epoch 3339: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3538 - accuracy: 0.9019\n","Epoch 3340/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3492 - accuracy: 0.8983\n","Epoch 3340: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3485 - accuracy: 0.8993\n","Epoch 3341/4000\n","8/8 [==============================] - ETA: 0s - loss: 0.3428 - accuracy: 0.8987\n","Epoch 3341: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3428 - accuracy: 0.8987\n","Epoch 3342/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3374 - accuracy: 0.9023\n","Epoch 3342: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3381 - accuracy: 0.9021\n","Epoch 3343/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3344 - accuracy: 0.9012\n","Epoch 3343: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3342 - accuracy: 0.9005\n","Epoch 3344/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3305 - accuracy: 0.9037\n","Epoch 3344: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3312 - accuracy: 0.9033\n","Epoch 3345/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3271 - accuracy: 0.9044\n","Epoch 3345: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3314 - accuracy: 0.9023\n","Epoch 3346/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3309 - accuracy: 0.9015\n","Epoch 3346: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3287 - accuracy: 0.9016\n","Epoch 3347/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3236 - accuracy: 0.9011\n","Epoch 3347: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3270 - accuracy: 0.8996\n","Epoch 3348/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3334 - accuracy: 0.8994\n","Epoch 3348: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3305 - accuracy: 0.9002\n","Epoch 3349/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3233 - accuracy: 0.9008\n","Epoch 3349: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3267 - accuracy: 0.9002\n","Epoch 3350/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3216 - accuracy: 0.9029\n","Epoch 3350: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3246 - accuracy: 0.9020\n","Epoch 3351/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3245 - accuracy: 0.9029\n","Epoch 3351: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3249 - accuracy: 0.9019\n","Epoch 3352/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3221 - accuracy: 0.9001\n","Epoch 3352: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3235 - accuracy: 0.8987\n","Epoch 3353/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3197 - accuracy: 0.9012\n","Epoch 3353: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3240 - accuracy: 0.8993\n","Epoch 3354/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3231 - accuracy: 0.9018\n","Epoch 3354: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3241 - accuracy: 0.9011\n","Epoch 3355/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3207 - accuracy: 0.9007\n","Epoch 3355: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3248 - accuracy: 0.8987\n","Epoch 3356/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3243 - accuracy: 0.9018\n","Epoch 3356: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3232 - accuracy: 0.9014\n","Epoch 3357/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3220 - accuracy: 0.9000\n","Epoch 3357: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3217 - accuracy: 0.9003\n","Epoch 3358/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3205 - accuracy: 0.9022\n","Epoch 3358: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3253 - accuracy: 0.9007\n","Epoch 3359/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3187 - accuracy: 0.8997\n","Epoch 3359: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3209 - accuracy: 0.8998\n","Epoch 3360/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3248 - accuracy: 0.9009\n","Epoch 3360: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3244 - accuracy: 0.9010\n","Epoch 3361/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3138 - accuracy: 0.9036\n","Epoch 3361: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3201 - accuracy: 0.9016\n","Epoch 3362/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3199 - accuracy: 0.9008\n","Epoch 3362: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3195 - accuracy: 0.9007\n","Epoch 3363/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3213 - accuracy: 0.9018\n","Epoch 3363: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3195 - accuracy: 0.9027\n","Epoch 3364/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3188 - accuracy: 0.9026\n","Epoch 3364: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3194 - accuracy: 0.9014\n","Epoch 3365/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3166 - accuracy: 0.9042\n","Epoch 3365: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3197 - accuracy: 0.9034\n","Epoch 3366/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3135 - accuracy: 0.9012\n","Epoch 3366: loss improved from 0.31749 to 0.31482, saving model to best_model_3.hdf5\n","8/8 [==============================] - 1s 108ms/step - loss: 0.3148 - accuracy: 0.9010\n","Epoch 3367/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3168 - accuracy: 0.8991\n","Epoch 3367: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3156 - accuracy: 0.8994\n","Epoch 3368/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3158 - accuracy: 0.9003\n","Epoch 3368: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3187 - accuracy: 0.8994\n","Epoch 3369/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3132 - accuracy: 0.9035\n","Epoch 3369: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3174 - accuracy: 0.9011\n","Epoch 3370/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3165 - accuracy: 0.9021\n","Epoch 3370: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3186 - accuracy: 0.9010\n","Epoch 3371/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3137 - accuracy: 0.8993\n","Epoch 3371: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 56ms/step - loss: 0.3194 - accuracy: 0.8979\n","Epoch 3372/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3152 - accuracy: 0.9040\n","Epoch 3372: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3205 - accuracy: 0.9018\n","Epoch 3373/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3148 - accuracy: 0.9018\n","Epoch 3373: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3221 - accuracy: 0.8993\n","Epoch 3374/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3155 - accuracy: 0.9015\n","Epoch 3374: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3196 - accuracy: 0.8998\n","Epoch 3375/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3152 - accuracy: 0.9025\n","Epoch 3375: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3168 - accuracy: 0.9023\n","Epoch 3376/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3180 - accuracy: 0.8993\n","Epoch 3376: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3181 - accuracy: 0.8992\n","Epoch 3377/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3177 - accuracy: 0.9035\n","Epoch 3377: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3194 - accuracy: 0.9027\n","Epoch 3378/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3165 - accuracy: 0.9015\n","Epoch 3378: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3223 - accuracy: 0.8998\n","Epoch 3379/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3230 - accuracy: 0.9008\n","Epoch 3379: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3213 - accuracy: 0.9001\n","Epoch 3380/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3164 - accuracy: 0.9037\n","Epoch 3380: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3204 - accuracy: 0.9027\n","Epoch 3381/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3180 - accuracy: 0.9023\n","Epoch 3381: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3192 - accuracy: 0.9011\n","Epoch 3382/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3210 - accuracy: 0.9015\n","Epoch 3382: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3197 - accuracy: 0.9025\n","Epoch 3383/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3099 - accuracy: 0.9014\n","Epoch 3383: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3184 - accuracy: 0.8989\n","Epoch 3384/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3118 - accuracy: 0.9039\n","Epoch 3384: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3183 - accuracy: 0.9014\n","Epoch 3385/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3190 - accuracy: 0.8996\n","Epoch 3385: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3192 - accuracy: 0.8993\n","Epoch 3386/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3182 - accuracy: 0.9023\n","Epoch 3386: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3209 - accuracy: 0.8999\n","Epoch 3387/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3159 - accuracy: 0.9030\n","Epoch 3387: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3188 - accuracy: 0.9016\n","Epoch 3388/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3203 - accuracy: 0.9007\n","Epoch 3388: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3191 - accuracy: 0.9006\n","Epoch 3389/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3101 - accuracy: 0.9033\n","Epoch 3389: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3171 - accuracy: 0.9010\n","Epoch 3390/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3183 - accuracy: 0.9015\n","Epoch 3390: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3191 - accuracy: 0.9011\n","Epoch 3391/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3243 - accuracy: 0.8987\n","Epoch 3391: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3205 - accuracy: 0.9006\n","Epoch 3392/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3192 - accuracy: 0.9000\n","Epoch 3392: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3197 - accuracy: 0.9003\n","Epoch 3393/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3223 - accuracy: 0.8993\n","Epoch 3393: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3209 - accuracy: 0.8998\n","Epoch 3394/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3182 - accuracy: 0.9023\n","Epoch 3394: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3182 - accuracy: 0.9015\n","Epoch 3395/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3179 - accuracy: 0.9005\n","Epoch 3395: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3164 - accuracy: 0.9010\n","Epoch 3396/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3162 - accuracy: 0.8979\n","Epoch 3396: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3177 - accuracy: 0.8976\n","Epoch 3397/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3146 - accuracy: 0.9003\n","Epoch 3397: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3161 - accuracy: 0.8996\n","Epoch 3398/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3154 - accuracy: 0.8996\n","Epoch 3398: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3194 - accuracy: 0.8992\n","Epoch 3399/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3176 - accuracy: 0.8977\n","Epoch 3399: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3198 - accuracy: 0.8965\n","Epoch 3400/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3187 - accuracy: 0.9026\n","Epoch 3400: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3212 - accuracy: 0.9014\n","Epoch 3401/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3168 - accuracy: 0.9023\n","Epoch 3401: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3192 - accuracy: 0.9009\n","Epoch 3402/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3172 - accuracy: 0.9016\n","Epoch 3402: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3198 - accuracy: 0.8999\n","Epoch 3403/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3157 - accuracy: 0.9019\n","Epoch 3403: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3162 - accuracy: 0.9014\n","Epoch 3404/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3205 - accuracy: 0.8976\n","Epoch 3404: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3224 - accuracy: 0.8968\n","Epoch 3405/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3209 - accuracy: 0.9007\n","Epoch 3405: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3186 - accuracy: 0.9014\n","Epoch 3406/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3181 - accuracy: 0.9001\n","Epoch 3406: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3167 - accuracy: 0.9006\n","Epoch 3407/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3163 - accuracy: 0.9025\n","Epoch 3407: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3179 - accuracy: 0.9012\n","Epoch 3408/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3218 - accuracy: 0.8987\n","Epoch 3408: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3224 - accuracy: 0.8983\n","Epoch 3409/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3133 - accuracy: 0.9018\n","Epoch 3409: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3171 - accuracy: 0.9005\n","Epoch 3410/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3149 - accuracy: 0.9021\n","Epoch 3410: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3195 - accuracy: 0.8998\n","Epoch 3411/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3136 - accuracy: 0.9011\n","Epoch 3411: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3174 - accuracy: 0.8992\n","Epoch 3412/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3161 - accuracy: 0.9000\n","Epoch 3412: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3169 - accuracy: 0.9006\n","Epoch 3413/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3210 - accuracy: 0.9001\n","Epoch 3413: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3207 - accuracy: 0.8997\n","Epoch 3414/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3146 - accuracy: 0.9032\n","Epoch 3414: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3178 - accuracy: 0.9015\n","Epoch 3415/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3106 - accuracy: 0.9016\n","Epoch 3415: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3165 - accuracy: 0.8992\n","Epoch 3416/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3161 - accuracy: 0.9026\n","Epoch 3416: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3196 - accuracy: 0.9014\n","Epoch 3417/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3125 - accuracy: 0.9037\n","Epoch 3417: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3158 - accuracy: 0.9021\n","Epoch 3418/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3189 - accuracy: 0.8998\n","Epoch 3418: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3166 - accuracy: 0.9005\n","Epoch 3419/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3131 - accuracy: 0.9019\n","Epoch 3419: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3172 - accuracy: 0.9006\n","Epoch 3420/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3155 - accuracy: 0.9019\n","Epoch 3420: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3158 - accuracy: 0.9012\n","Epoch 3421/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3135 - accuracy: 0.9005\n","Epoch 3421: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3168 - accuracy: 0.8993\n","Epoch 3422/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3142 - accuracy: 0.9016\n","Epoch 3422: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3179 - accuracy: 0.8999\n","Epoch 3423/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3198 - accuracy: 0.9003\n","Epoch 3423: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3167 - accuracy: 0.9012\n","Epoch 3424/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3185 - accuracy: 0.9018\n","Epoch 3424: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3194 - accuracy: 0.9016\n","Epoch 3425/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3105 - accuracy: 0.9047\n","Epoch 3425: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3160 - accuracy: 0.9028\n","Epoch 3426/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3155 - accuracy: 0.9005\n","Epoch 3426: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3167 - accuracy: 0.9011\n","Epoch 3427/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3116 - accuracy: 0.9022\n","Epoch 3427: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3164 - accuracy: 0.9007\n","Epoch 3428/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3128 - accuracy: 0.9007\n","Epoch 3428: loss improved from 0.31482 to 0.31266, saving model to best_model_3.hdf5\n","8/8 [==============================] - 1s 100ms/step - loss: 0.3127 - accuracy: 0.9010\n","Epoch 3429/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3151 - accuracy: 0.9009\n","Epoch 3429: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3142 - accuracy: 0.9014\n","Epoch 3430/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3111 - accuracy: 0.9012\n","Epoch 3430: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3143 - accuracy: 0.9003\n","Epoch 3431/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3137 - accuracy: 0.9007\n","Epoch 3431: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 56ms/step - loss: 0.3150 - accuracy: 0.8997\n","Epoch 3432/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3108 - accuracy: 0.9028\n","Epoch 3432: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3169 - accuracy: 0.9002\n","Epoch 3433/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3137 - accuracy: 0.9009\n","Epoch 3433: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3151 - accuracy: 0.9007\n","Epoch 3434/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3172 - accuracy: 0.8996\n","Epoch 3434: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3178 - accuracy: 0.8998\n","Epoch 3435/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3159 - accuracy: 0.9018\n","Epoch 3435: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3170 - accuracy: 0.9002\n","Epoch 3436/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3159 - accuracy: 0.8986\n","Epoch 3436: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3140 - accuracy: 0.8992\n","Epoch 3437/4000\n","8/8 [==============================] - ETA: 0s - loss: 0.3152 - accuracy: 0.9007\n","Epoch 3437: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3152 - accuracy: 0.9007\n","Epoch 3438/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3192 - accuracy: 0.8979\n","Epoch 3438: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3163 - accuracy: 0.8997\n","Epoch 3439/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3149 - accuracy: 0.9015\n","Epoch 3439: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3173 - accuracy: 0.9005\n","Epoch 3440/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3154 - accuracy: 0.9028\n","Epoch 3440: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3160 - accuracy: 0.9023\n","Epoch 3441/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3165 - accuracy: 0.8996\n","Epoch 3441: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3168 - accuracy: 0.9001\n","Epoch 3442/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3182 - accuracy: 0.9005\n","Epoch 3442: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3175 - accuracy: 0.9010\n","Epoch 3443/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3137 - accuracy: 0.9030\n","Epoch 3443: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3182 - accuracy: 0.9011\n","Epoch 3444/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3152 - accuracy: 0.8996\n","Epoch 3444: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3170 - accuracy: 0.8987\n","Epoch 3445/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3133 - accuracy: 0.9014\n","Epoch 3445: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3156 - accuracy: 0.9007\n","Epoch 3446/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3185 - accuracy: 0.8998\n","Epoch 3446: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3167 - accuracy: 0.9007\n","Epoch 3447/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3109 - accuracy: 0.9035\n","Epoch 3447: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3168 - accuracy: 0.9012\n","Epoch 3448/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3154 - accuracy: 0.8996\n","Epoch 3448: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3170 - accuracy: 0.8984\n","Epoch 3449/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3101 - accuracy: 0.9035\n","Epoch 3449: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3173 - accuracy: 0.9006\n","Epoch 3450/4000\n","8/8 [==============================] - ETA: 0s - loss: 0.3169 - accuracy: 0.9005\n","Epoch 3450: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3169 - accuracy: 0.9005\n","Epoch 3451/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3155 - accuracy: 0.9019\n","Epoch 3451: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3192 - accuracy: 0.9002\n","Epoch 3452/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3169 - accuracy: 0.8998\n","Epoch 3452: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3205 - accuracy: 0.8976\n","Epoch 3453/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3134 - accuracy: 0.9036\n","Epoch 3453: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3203 - accuracy: 0.9015\n","Epoch 3454/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3137 - accuracy: 0.9028\n","Epoch 3454: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3211 - accuracy: 0.8999\n","Epoch 3455/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3167 - accuracy: 0.9016\n","Epoch 3455: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3185 - accuracy: 0.9007\n","Epoch 3456/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3133 - accuracy: 0.8997\n","Epoch 3456: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3180 - accuracy: 0.8985\n","Epoch 3457/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3145 - accuracy: 0.9015\n","Epoch 3457: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3162 - accuracy: 0.9006\n","Epoch 3458/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3159 - accuracy: 0.9025\n","Epoch 3458: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3186 - accuracy: 0.9015\n","Epoch 3459/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3168 - accuracy: 0.9000\n","Epoch 3459: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3157 - accuracy: 0.9005\n","Epoch 3460/4000\n","8/8 [==============================] - ETA: 0s - loss: 0.3137 - accuracy: 0.9001\n","Epoch 3460: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 62ms/step - loss: 0.3137 - accuracy: 0.9001\n","Epoch 3461/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3157 - accuracy: 0.9003\n","Epoch 3461: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3163 - accuracy: 0.8990\n","Epoch 3462/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3208 - accuracy: 0.8994\n","Epoch 3462: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3174 - accuracy: 0.9009\n","Epoch 3463/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3127 - accuracy: 0.9040\n","Epoch 3463: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3178 - accuracy: 0.9010\n","Epoch 3464/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3145 - accuracy: 0.9046\n","Epoch 3464: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3169 - accuracy: 0.9033\n","Epoch 3465/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3177 - accuracy: 0.9011\n","Epoch 3465: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3191 - accuracy: 0.9005\n","Epoch 3466/4000\n","8/8 [==============================] - ETA: 0s - loss: 0.3143 - accuracy: 0.9012\n","Epoch 3466: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3143 - accuracy: 0.9012\n","Epoch 3467/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3179 - accuracy: 0.8994\n","Epoch 3467: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3176 - accuracy: 0.8987\n","Epoch 3468/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3186 - accuracy: 0.9018\n","Epoch 3468: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3184 - accuracy: 0.9018\n","Epoch 3469/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3136 - accuracy: 0.9022\n","Epoch 3469: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3184 - accuracy: 0.8998\n","Epoch 3470/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3134 - accuracy: 0.9040\n","Epoch 3470: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 56ms/step - loss: 0.3174 - accuracy: 0.9025\n","Epoch 3471/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3132 - accuracy: 0.9028\n","Epoch 3471: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3200 - accuracy: 0.9009\n","Epoch 3472/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3182 - accuracy: 0.9021\n","Epoch 3472: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3196 - accuracy: 0.9011\n","Epoch 3473/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3168 - accuracy: 0.9022\n","Epoch 3473: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3190 - accuracy: 0.9012\n","Epoch 3474/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3157 - accuracy: 0.9028\n","Epoch 3474: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3194 - accuracy: 0.9014\n","Epoch 3475/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3170 - accuracy: 0.9021\n","Epoch 3475: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3197 - accuracy: 0.9002\n","Epoch 3476/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3220 - accuracy: 0.9015\n","Epoch 3476: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3181 - accuracy: 0.9019\n","Epoch 3477/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3154 - accuracy: 0.9015\n","Epoch 3477: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3173 - accuracy: 0.9009\n","Epoch 3478/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3176 - accuracy: 0.9003\n","Epoch 3478: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3188 - accuracy: 0.8993\n","Epoch 3479/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3147 - accuracy: 0.9012\n","Epoch 3479: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3183 - accuracy: 0.8997\n","Epoch 3480/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3164 - accuracy: 0.9004\n","Epoch 3480: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3157 - accuracy: 0.9003\n","Epoch 3481/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3223 - accuracy: 0.8993\n","Epoch 3481: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3186 - accuracy: 0.9001\n","Epoch 3482/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3140 - accuracy: 0.9023\n","Epoch 3482: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3173 - accuracy: 0.9006\n","Epoch 3483/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3163 - accuracy: 0.9004\n","Epoch 3483: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 49ms/step - loss: 0.3196 - accuracy: 0.8996\n","Epoch 3484/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3170 - accuracy: 0.9016\n","Epoch 3484: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 49ms/step - loss: 0.3168 - accuracy: 0.9016\n","Epoch 3485/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3191 - accuracy: 0.9000\n","Epoch 3485: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3190 - accuracy: 0.8989\n","Epoch 3486/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3146 - accuracy: 0.9012\n","Epoch 3486: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3162 - accuracy: 0.8998\n","Epoch 3487/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3209 - accuracy: 0.9004\n","Epoch 3487: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3162 - accuracy: 0.9018\n","Epoch 3488/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3154 - accuracy: 0.9008\n","Epoch 3488: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3151 - accuracy: 0.9011\n","Epoch 3489/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3136 - accuracy: 0.9018\n","Epoch 3489: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3183 - accuracy: 0.9001\n","Epoch 3490/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3218 - accuracy: 0.8996\n","Epoch 3490: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3188 - accuracy: 0.9009\n","Epoch 3491/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3161 - accuracy: 0.8994\n","Epoch 3491: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3183 - accuracy: 0.8985\n","Epoch 3492/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3160 - accuracy: 0.9019\n","Epoch 3492: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3167 - accuracy: 0.9018\n","Epoch 3493/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3095 - accuracy: 0.9028\n","Epoch 3493: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3154 - accuracy: 0.9012\n","Epoch 3494/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3142 - accuracy: 0.9035\n","Epoch 3494: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3157 - accuracy: 0.9031\n","Epoch 3495/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3143 - accuracy: 0.8997\n","Epoch 3495: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3172 - accuracy: 0.8990\n","Epoch 3496/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3211 - accuracy: 0.9039\n","Epoch 3496: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3162 - accuracy: 0.9049\n","Epoch 3497/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3231 - accuracy: 0.8996\n","Epoch 3497: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3216 - accuracy: 0.9003\n","Epoch 3498/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3147 - accuracy: 0.9000\n","Epoch 3498: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3158 - accuracy: 0.8989\n","Epoch 3499/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3124 - accuracy: 0.9023\n","Epoch 3499: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 56ms/step - loss: 0.3181 - accuracy: 0.9002\n","Epoch 3500/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3163 - accuracy: 0.9015\n","Epoch 3500: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3177 - accuracy: 0.9011\n","Epoch 3501/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3156 - accuracy: 0.9005\n","Epoch 3501: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3186 - accuracy: 0.8994\n","Epoch 3502/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3118 - accuracy: 0.9033\n","Epoch 3502: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3177 - accuracy: 0.9012\n","Epoch 3503/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3140 - accuracy: 0.9025\n","Epoch 3503: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3171 - accuracy: 0.9016\n","Epoch 3504/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3111 - accuracy: 0.9039\n","Epoch 3504: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3167 - accuracy: 0.9012\n","Epoch 3505/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3201 - accuracy: 0.9016\n","Epoch 3505: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3140 - accuracy: 0.9028\n","Epoch 3506/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3111 - accuracy: 0.9014\n","Epoch 3506: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3153 - accuracy: 0.8996\n","Epoch 3507/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3097 - accuracy: 0.9022\n","Epoch 3507: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3158 - accuracy: 0.9003\n","Epoch 3508/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3200 - accuracy: 0.8993\n","Epoch 3508: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3181 - accuracy: 0.8996\n","Epoch 3509/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3131 - accuracy: 0.9023\n","Epoch 3509: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3176 - accuracy: 0.9006\n","Epoch 3510/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3152 - accuracy: 0.8980\n","Epoch 3510: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3178 - accuracy: 0.8975\n","Epoch 3511/4000\n","8/8 [==============================] - ETA: 0s - loss: 0.3173 - accuracy: 0.9003\n","Epoch 3511: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3173 - accuracy: 0.9003\n","Epoch 3512/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3102 - accuracy: 0.9018\n","Epoch 3512: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3166 - accuracy: 0.8990\n","Epoch 3513/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3153 - accuracy: 0.9008\n","Epoch 3513: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3190 - accuracy: 0.8994\n","Epoch 3514/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3122 - accuracy: 0.9023\n","Epoch 3514: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3196 - accuracy: 0.9012\n","Epoch 3515/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3156 - accuracy: 0.9009\n","Epoch 3515: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3172 - accuracy: 0.9005\n","Epoch 3516/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3178 - accuracy: 0.9008\n","Epoch 3516: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3194 - accuracy: 0.8998\n","Epoch 3517/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3105 - accuracy: 0.9026\n","Epoch 3517: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3171 - accuracy: 0.9005\n","Epoch 3518/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3148 - accuracy: 0.9001\n","Epoch 3518: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 48ms/step - loss: 0.3168 - accuracy: 0.8993\n","Epoch 3519/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3142 - accuracy: 0.9032\n","Epoch 3519: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3178 - accuracy: 0.9010\n","Epoch 3520/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3208 - accuracy: 0.8998\n","Epoch 3520: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3175 - accuracy: 0.9011\n","Epoch 3521/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3165 - accuracy: 0.9011\n","Epoch 3521: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3190 - accuracy: 0.8996\n","Epoch 3522/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3173 - accuracy: 0.9014\n","Epoch 3522: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3186 - accuracy: 0.8997\n","Epoch 3523/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3124 - accuracy: 0.9019\n","Epoch 3523: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3169 - accuracy: 0.9007\n","Epoch 3524/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3142 - accuracy: 0.9019\n","Epoch 3524: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3157 - accuracy: 0.9007\n","Epoch 3525/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3155 - accuracy: 0.9019\n","Epoch 3525: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3193 - accuracy: 0.9005\n","Epoch 3526/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3158 - accuracy: 0.8993\n","Epoch 3526: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3193 - accuracy: 0.8983\n","Epoch 3527/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3165 - accuracy: 0.9011\n","Epoch 3527: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3185 - accuracy: 0.9011\n","Epoch 3528/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3206 - accuracy: 0.9004\n","Epoch 3528: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3191 - accuracy: 0.9005\n","Epoch 3529/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3171 - accuracy: 0.9001\n","Epoch 3529: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3180 - accuracy: 0.9001\n","Epoch 3530/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3155 - accuracy: 0.9012\n","Epoch 3530: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3170 - accuracy: 0.9003\n","Epoch 3531/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3116 - accuracy: 0.9011\n","Epoch 3531: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3146 - accuracy: 0.9006\n","Epoch 3532/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3080 - accuracy: 0.9028\n","Epoch 3532: loss improved from 0.31266 to 0.31201, saving model to best_model_3.hdf5\n","8/8 [==============================] - 1s 106ms/step - loss: 0.3120 - accuracy: 0.9014\n","Epoch 3533/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3156 - accuracy: 0.9019\n","Epoch 3533: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 49ms/step - loss: 0.3168 - accuracy: 0.9014\n","Epoch 3534/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3205 - accuracy: 0.8970\n","Epoch 3534: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3178 - accuracy: 0.8980\n","Epoch 3535/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3132 - accuracy: 0.9015\n","Epoch 3535: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3191 - accuracy: 0.8992\n","Epoch 3536/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3126 - accuracy: 0.9014\n","Epoch 3536: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3167 - accuracy: 0.9002\n","Epoch 3537/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3199 - accuracy: 0.9018\n","Epoch 3537: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3198 - accuracy: 0.9018\n","Epoch 3538/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3154 - accuracy: 0.9030\n","Epoch 3538: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3199 - accuracy: 0.9014\n","Epoch 3539/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3065 - accuracy: 0.9042\n","Epoch 3539: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3164 - accuracy: 0.9006\n","Epoch 3540/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3191 - accuracy: 0.8986\n","Epoch 3540: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3156 - accuracy: 0.9001\n","Epoch 3541/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3231 - accuracy: 0.8998\n","Epoch 3541: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3211 - accuracy: 0.8997\n","Epoch 3542/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3135 - accuracy: 0.9022\n","Epoch 3542: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3191 - accuracy: 0.9002\n","Epoch 3543/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3168 - accuracy: 0.9007\n","Epoch 3543: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3195 - accuracy: 0.8989\n","Epoch 3544/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3151 - accuracy: 0.9005\n","Epoch 3544: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3182 - accuracy: 0.8990\n","Epoch 3545/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3157 - accuracy: 0.9016\n","Epoch 3545: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3180 - accuracy: 0.9005\n","Epoch 3546/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3135 - accuracy: 0.9032\n","Epoch 3546: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3175 - accuracy: 0.9014\n","Epoch 3547/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3157 - accuracy: 0.9011\n","Epoch 3547: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3187 - accuracy: 0.9005\n","Epoch 3548/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3148 - accuracy: 0.9016\n","Epoch 3548: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3148 - accuracy: 0.9016\n","Epoch 3549/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3150 - accuracy: 0.9003\n","Epoch 3549: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3147 - accuracy: 0.8997\n","Epoch 3550/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3172 - accuracy: 0.9028\n","Epoch 3550: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3190 - accuracy: 0.9023\n","Epoch 3551/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3191 - accuracy: 0.8983\n","Epoch 3551: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3179 - accuracy: 0.8987\n","Epoch 3552/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3130 - accuracy: 0.9028\n","Epoch 3552: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3165 - accuracy: 0.9014\n","Epoch 3553/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3154 - accuracy: 0.9003\n","Epoch 3553: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3174 - accuracy: 0.8993\n","Epoch 3554/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3170 - accuracy: 0.8990\n","Epoch 3554: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3168 - accuracy: 0.8993\n","Epoch 3555/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3139 - accuracy: 0.8993\n","Epoch 3555: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3158 - accuracy: 0.8985\n","Epoch 3556/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3182 - accuracy: 0.8998\n","Epoch 3556: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3190 - accuracy: 0.8993\n","Epoch 3557/4000\n","8/8 [==============================] - ETA: 0s - loss: 0.3182 - accuracy: 0.9014\n","Epoch 3557: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 56ms/step - loss: 0.3182 - accuracy: 0.9014\n","Epoch 3558/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3162 - accuracy: 0.9028\n","Epoch 3558: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 49ms/step - loss: 0.3195 - accuracy: 0.9021\n","Epoch 3559/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3215 - accuracy: 0.8991\n","Epoch 3559: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3222 - accuracy: 0.8988\n","Epoch 3560/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3179 - accuracy: 0.9021\n","Epoch 3560: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3219 - accuracy: 0.9007\n","Epoch 3561/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3195 - accuracy: 0.9019\n","Epoch 3561: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3210 - accuracy: 0.9012\n","Epoch 3562/4000\n","8/8 [==============================] - ETA: 0s - loss: 0.3201 - accuracy: 0.9010\n","Epoch 3562: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3201 - accuracy: 0.9010\n","Epoch 3563/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3169 - accuracy: 0.9019\n","Epoch 3563: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3206 - accuracy: 0.9007\n","Epoch 3564/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3193 - accuracy: 0.9012\n","Epoch 3564: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3211 - accuracy: 0.8998\n","Epoch 3565/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3186 - accuracy: 0.9008\n","Epoch 3565: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3170 - accuracy: 0.9003\n","Epoch 3566/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3181 - accuracy: 0.8993\n","Epoch 3566: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3169 - accuracy: 0.9003\n","Epoch 3567/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3168 - accuracy: 0.9007\n","Epoch 3567: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3195 - accuracy: 0.9006\n","Epoch 3568/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3179 - accuracy: 0.9001\n","Epoch 3568: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3173 - accuracy: 0.8998\n","Epoch 3569/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3183 - accuracy: 0.9033\n","Epoch 3569: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3231 - accuracy: 0.9011\n","Epoch 3570/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3234 - accuracy: 0.9004\n","Epoch 3570: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3237 - accuracy: 0.9005\n","Epoch 3571/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3321 - accuracy: 0.8993\n","Epoch 3571: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3314 - accuracy: 0.8999\n","Epoch 3572/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3329 - accuracy: 0.8987\n","Epoch 3572: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3336 - accuracy: 0.8977\n","Epoch 3573/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3377 - accuracy: 0.8989\n","Epoch 3573: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3376 - accuracy: 0.8985\n","Epoch 3574/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3434 - accuracy: 0.8980\n","Epoch 3574: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3405 - accuracy: 0.8983\n","Epoch 3575/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3459 - accuracy: 0.8979\n","Epoch 3575: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3486 - accuracy: 0.8968\n","Epoch 3576/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3553 - accuracy: 0.8997\n","Epoch 3576: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3615 - accuracy: 0.8970\n","Epoch 3577/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3744 - accuracy: 0.8936\n","Epoch 3577: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3764 - accuracy: 0.8922\n","Epoch 3578/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3787 - accuracy: 0.8933\n","Epoch 3578: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3856 - accuracy: 0.8917\n","Epoch 3579/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.4429 - accuracy: 0.8747\n","Epoch 3579: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 51ms/step - loss: 0.4445 - accuracy: 0.8744\n","Epoch 3580/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.4960 - accuracy: 0.8664\n","Epoch 3580: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 51ms/step - loss: 0.4931 - accuracy: 0.8675\n","Epoch 3581/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.5359 - accuracy: 0.8595\n","Epoch 3581: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 52ms/step - loss: 0.5458 - accuracy: 0.8576\n","Epoch 3582/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.5578 - accuracy: 0.8562\n","Epoch 3582: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 52ms/step - loss: 0.5632 - accuracy: 0.8548\n","Epoch 3583/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.5860 - accuracy: 0.8599\n","Epoch 3583: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 53ms/step - loss: 0.5945 - accuracy: 0.8579\n","Epoch 3584/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.6629 - accuracy: 0.8422\n","Epoch 3584: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 54ms/step - loss: 0.6648 - accuracy: 0.8413\n","Epoch 3585/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.6771 - accuracy: 0.8384\n","Epoch 3585: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 53ms/step - loss: 0.6842 - accuracy: 0.8368\n","Epoch 3586/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.6678 - accuracy: 0.8415\n","Epoch 3586: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 50ms/step - loss: 0.6777 - accuracy: 0.8391\n","Epoch 3587/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.6799 - accuracy: 0.8422\n","Epoch 3587: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 52ms/step - loss: 0.6851 - accuracy: 0.8398\n","Epoch 3588/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.6364 - accuracy: 0.8524\n","Epoch 3588: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 51ms/step - loss: 0.6365 - accuracy: 0.8527\n","Epoch 3589/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.6173 - accuracy: 0.8629\n","Epoch 3589: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 51ms/step - loss: 0.6177 - accuracy: 0.8625\n","Epoch 3590/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.5733 - accuracy: 0.8726\n","Epoch 3590: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 49ms/step - loss: 0.5800 - accuracy: 0.8702\n","Epoch 3591/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.5346 - accuracy: 0.8768\n","Epoch 3591: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 53ms/step - loss: 0.5326 - accuracy: 0.8782\n","Epoch 3592/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.4984 - accuracy: 0.8830\n","Epoch 3592: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 51ms/step - loss: 0.5011 - accuracy: 0.8830\n","Epoch 3593/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.4843 - accuracy: 0.8873\n","Epoch 3593: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 55ms/step - loss: 0.4890 - accuracy: 0.8851\n","Epoch 3594/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.4426 - accuracy: 0.8944\n","Epoch 3594: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 53ms/step - loss: 0.4457 - accuracy: 0.8930\n","Epoch 3595/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.4260 - accuracy: 0.8944\n","Epoch 3595: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 53ms/step - loss: 0.4252 - accuracy: 0.8944\n","Epoch 3596/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.4108 - accuracy: 0.8949\n","Epoch 3596: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 53ms/step - loss: 0.4129 - accuracy: 0.8936\n","Epoch 3597/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3912 - accuracy: 0.8975\n","Epoch 3597: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3968 - accuracy: 0.8957\n","Epoch 3598/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3831 - accuracy: 0.8983\n","Epoch 3598: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3849 - accuracy: 0.8983\n","Epoch 3599/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3697 - accuracy: 0.9001\n","Epoch 3599: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3703 - accuracy: 0.8997\n","Epoch 3600/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3587 - accuracy: 0.9012\n","Epoch 3600: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3624 - accuracy: 0.8997\n","Epoch 3601/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3504 - accuracy: 0.9012\n","Epoch 3601: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3522 - accuracy: 0.9006\n","Epoch 3602/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3442 - accuracy: 0.9021\n","Epoch 3602: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3490 - accuracy: 0.8994\n","Epoch 3603/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3358 - accuracy: 0.9049\n","Epoch 3603: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3419 - accuracy: 0.9021\n","Epoch 3604/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3326 - accuracy: 0.9023\n","Epoch 3604: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3404 - accuracy: 0.8998\n","Epoch 3605/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3280 - accuracy: 0.9051\n","Epoch 3605: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3334 - accuracy: 0.9025\n","Epoch 3606/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3331 - accuracy: 0.8993\n","Epoch 3606: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3326 - accuracy: 0.8998\n","Epoch 3607/4000\n","8/8 [==============================] - ETA: 0s - loss: 0.3272 - accuracy: 0.9012\n","Epoch 3607: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 56ms/step - loss: 0.3272 - accuracy: 0.9012\n","Epoch 3608/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3253 - accuracy: 0.8998\n","Epoch 3608: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3251 - accuracy: 0.8994\n","Epoch 3609/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3216 - accuracy: 0.9044\n","Epoch 3609: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3227 - accuracy: 0.9027\n","Epoch 3610/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3156 - accuracy: 0.9039\n","Epoch 3610: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3221 - accuracy: 0.9015\n","Epoch 3611/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3174 - accuracy: 0.9040\n","Epoch 3611: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3199 - accuracy: 0.9023\n","Epoch 3612/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3172 - accuracy: 0.9023\n","Epoch 3612: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3183 - accuracy: 0.9020\n","Epoch 3613/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3125 - accuracy: 0.9040\n","Epoch 3613: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3168 - accuracy: 0.9023\n","Epoch 3614/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3203 - accuracy: 0.9000\n","Epoch 3614: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3167 - accuracy: 0.9007\n","Epoch 3615/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3164 - accuracy: 0.9008\n","Epoch 3615: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3168 - accuracy: 0.9010\n","Epoch 3616/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3124 - accuracy: 0.9022\n","Epoch 3616: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3136 - accuracy: 0.9019\n","Epoch 3617/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3103 - accuracy: 0.9023\n","Epoch 3617: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3151 - accuracy: 0.9010\n","Epoch 3618/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3101 - accuracy: 0.9028\n","Epoch 3618: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 48ms/step - loss: 0.3131 - accuracy: 0.9014\n","Epoch 3619/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3135 - accuracy: 0.9004\n","Epoch 3619: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3138 - accuracy: 0.9005\n","Epoch 3620/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3140 - accuracy: 0.8993\n","Epoch 3620: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3167 - accuracy: 0.8990\n","Epoch 3621/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3158 - accuracy: 0.9018\n","Epoch 3621: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3163 - accuracy: 0.9019\n","Epoch 3622/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3160 - accuracy: 0.9012\n","Epoch 3622: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 56ms/step - loss: 0.3141 - accuracy: 0.9019\n","Epoch 3623/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3192 - accuracy: 0.9015\n","Epoch 3623: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3168 - accuracy: 0.9023\n","Epoch 3624/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3126 - accuracy: 0.9026\n","Epoch 3624: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3175 - accuracy: 0.9011\n","Epoch 3625/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3140 - accuracy: 0.9033\n","Epoch 3625: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3160 - accuracy: 0.9024\n","Epoch 3626/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3124 - accuracy: 0.9018\n","Epoch 3626: loss improved from 0.31201 to 0.31160, saving model to best_model_3.hdf5\n","8/8 [==============================] - 1s 106ms/step - loss: 0.3116 - accuracy: 0.9011\n","Epoch 3627/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3148 - accuracy: 0.9009\n","Epoch 3627: loss did not improve from 0.31160\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3164 - accuracy: 0.9003\n","Epoch 3628/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3112 - accuracy: 0.9029\n","Epoch 3628: loss did not improve from 0.31160\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3174 - accuracy: 0.9002\n","Epoch 3629/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3187 - accuracy: 0.9012\n","Epoch 3629: loss did not improve from 0.31160\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3179 - accuracy: 0.9014\n","Epoch 3630/4000\n","8/8 [==============================] - ETA: 0s - loss: 0.3161 - accuracy: 0.9024\n","Epoch 3630: loss did not improve from 0.31160\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3161 - accuracy: 0.9024\n","Epoch 3631/4000\n","8/8 [==============================] - ETA: 0s - loss: 0.3156 - accuracy: 0.9021\n","Epoch 3631: loss did not improve from 0.31160\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3156 - accuracy: 0.9021\n","Epoch 3632/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3152 - accuracy: 0.9014\n","Epoch 3632: loss did not improve from 0.31160\n","8/8 [==============================] - 0s 48ms/step - loss: 0.3172 - accuracy: 0.9006\n","Epoch 3633/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3097 - accuracy: 0.9050\n","Epoch 3633: loss did not improve from 0.31160\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3146 - accuracy: 0.9032\n","Epoch 3634/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3091 - accuracy: 0.9018\n","Epoch 3634: loss did not improve from 0.31160\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3151 - accuracy: 0.9002\n","Epoch 3635/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3175 - accuracy: 0.9025\n","Epoch 3635: loss did not improve from 0.31160\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3170 - accuracy: 0.9020\n","Epoch 3636/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3190 - accuracy: 0.8984\n","Epoch 3636: loss did not improve from 0.31160\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3176 - accuracy: 0.8984\n","Epoch 3637/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3090 - accuracy: 0.9025\n","Epoch 3637: loss did not improve from 0.31160\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3136 - accuracy: 0.9012\n","Epoch 3638/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3117 - accuracy: 0.9001\n","Epoch 3638: loss did not improve from 0.31160\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3123 - accuracy: 0.8993\n","Epoch 3639/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3135 - accuracy: 0.9011\n","Epoch 3639: loss did not improve from 0.31160\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3140 - accuracy: 0.9005\n","Epoch 3640/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3095 - accuracy: 0.9004\n","Epoch 3640: loss did not improve from 0.31160\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3119 - accuracy: 0.8997\n","Epoch 3641/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3086 - accuracy: 0.9009\n","Epoch 3641: loss did not improve from 0.31160\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3130 - accuracy: 0.9001\n","Epoch 3642/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3127 - accuracy: 0.9003\n","Epoch 3642: loss did not improve from 0.31160\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3161 - accuracy: 0.8987\n","Epoch 3643/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3141 - accuracy: 0.9004\n","Epoch 3643: loss did not improve from 0.31160\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3139 - accuracy: 0.9002\n","Epoch 3644/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3121 - accuracy: 0.9018\n","Epoch 3644: loss did not improve from 0.31160\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3119 - accuracy: 0.9018\n","Epoch 3645/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3080 - accuracy: 0.9032\n","Epoch 3645: loss did not improve from 0.31160\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3130 - accuracy: 0.9010\n","Epoch 3646/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3148 - accuracy: 0.9018\n","Epoch 3646: loss did not improve from 0.31160\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3121 - accuracy: 0.9032\n","Epoch 3647/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3095 - accuracy: 0.9036\n","Epoch 3647: loss improved from 0.31160 to 0.31074, saving model to best_model_3.hdf5\n","8/8 [==============================] - 1s 105ms/step - loss: 0.3107 - accuracy: 0.9028\n","Epoch 3648/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3114 - accuracy: 0.9030\n","Epoch 3648: loss did not improve from 0.31074\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3168 - accuracy: 0.9016\n","Epoch 3649/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3122 - accuracy: 0.9003\n","Epoch 3649: loss did not improve from 0.31074\n","8/8 [==============================] - 0s 49ms/step - loss: 0.3127 - accuracy: 0.8996\n","Epoch 3650/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3109 - accuracy: 0.9022\n","Epoch 3650: loss did not improve from 0.31074\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3108 - accuracy: 0.9024\n","Epoch 3651/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3122 - accuracy: 0.9012\n","Epoch 3651: loss improved from 0.31074 to 0.30983, saving model to best_model_3.hdf5\n","8/8 [==============================] - 1s 114ms/step - loss: 0.3098 - accuracy: 0.9020\n","Epoch 3652/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3066 - accuracy: 0.9026\n","Epoch 3652: loss did not improve from 0.30983\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3112 - accuracy: 0.9005\n","Epoch 3653/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3088 - accuracy: 0.9019\n","Epoch 3653: loss did not improve from 0.30983\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3128 - accuracy: 0.9009\n","Epoch 3654/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3109 - accuracy: 0.9026\n","Epoch 3654: loss did not improve from 0.30983\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3123 - accuracy: 0.9019\n","Epoch 3655/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3115 - accuracy: 0.9008\n","Epoch 3655: loss improved from 0.30983 to 0.30893, saving model to best_model_3.hdf5\n","8/8 [==============================] - 1s 106ms/step - loss: 0.3089 - accuracy: 0.9014\n","Epoch 3656/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.2979 - accuracy: 0.9056\n","Epoch 3656: loss did not improve from 0.30893\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3094 - accuracy: 0.9024\n","Epoch 3657/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3137 - accuracy: 0.9018\n","Epoch 3657: loss did not improve from 0.30893\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3118 - accuracy: 0.9025\n","Epoch 3658/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3071 - accuracy: 0.9026\n","Epoch 3658: loss did not improve from 0.30893\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3160 - accuracy: 0.8994\n","Epoch 3659/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3144 - accuracy: 0.9023\n","Epoch 3659: loss did not improve from 0.30893\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3174 - accuracy: 0.9010\n","Epoch 3660/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3095 - accuracy: 0.9015\n","Epoch 3660: loss did not improve from 0.30893\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3134 - accuracy: 0.9002\n","Epoch 3661/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3121 - accuracy: 0.9014\n","Epoch 3661: loss did not improve from 0.30893\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3132 - accuracy: 0.9009\n","Epoch 3662/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3098 - accuracy: 0.9025\n","Epoch 3662: loss did not improve from 0.30893\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3134 - accuracy: 0.9012\n","Epoch 3663/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3152 - accuracy: 0.9019\n","Epoch 3663: loss did not improve from 0.30893\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3121 - accuracy: 0.9027\n","Epoch 3664/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3101 - accuracy: 0.9023\n","Epoch 3664: loss did not improve from 0.30893\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3120 - accuracy: 0.9014\n","Epoch 3665/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3129 - accuracy: 0.8984\n","Epoch 3665: loss did not improve from 0.30893\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3132 - accuracy: 0.8981\n","Epoch 3666/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3110 - accuracy: 0.8994\n","Epoch 3666: loss did not improve from 0.30893\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3099 - accuracy: 0.8989\n","Epoch 3667/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3107 - accuracy: 0.8989\n","Epoch 3667: loss did not improve from 0.30893\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3117 - accuracy: 0.8992\n","Epoch 3668/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3035 - accuracy: 0.9036\n","Epoch 3668: loss improved from 0.30893 to 0.30800, saving model to best_model_3.hdf5\n","8/8 [==============================] - 1s 100ms/step - loss: 0.3080 - accuracy: 0.9021\n","Epoch 3669/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3104 - accuracy: 0.8973\n","Epoch 3669: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3119 - accuracy: 0.8967\n","Epoch 3670/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3092 - accuracy: 0.9011\n","Epoch 3670: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3106 - accuracy: 0.9009\n","Epoch 3671/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3089 - accuracy: 0.9028\n","Epoch 3671: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3087 - accuracy: 0.9024\n","Epoch 3672/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3151 - accuracy: 0.8996\n","Epoch 3672: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 56ms/step - loss: 0.3136 - accuracy: 0.8999\n","Epoch 3673/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3091 - accuracy: 0.9021\n","Epoch 3673: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 49ms/step - loss: 0.3120 - accuracy: 0.9014\n","Epoch 3674/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3105 - accuracy: 0.9001\n","Epoch 3674: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3131 - accuracy: 0.8993\n","Epoch 3675/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3098 - accuracy: 0.9032\n","Epoch 3675: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3111 - accuracy: 0.9023\n","Epoch 3676/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3106 - accuracy: 0.9012\n","Epoch 3676: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3129 - accuracy: 0.9005\n","Epoch 3677/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3104 - accuracy: 0.9016\n","Epoch 3677: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3113 - accuracy: 0.9011\n","Epoch 3678/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3044 - accuracy: 0.9026\n","Epoch 3678: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3125 - accuracy: 0.8998\n","Epoch 3679/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3105 - accuracy: 0.9015\n","Epoch 3679: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3134 - accuracy: 0.9005\n","Epoch 3680/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3137 - accuracy: 0.8983\n","Epoch 3680: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3120 - accuracy: 0.8987\n","Epoch 3681/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3121 - accuracy: 0.9016\n","Epoch 3681: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3141 - accuracy: 0.9012\n","Epoch 3682/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3050 - accuracy: 0.9028\n","Epoch 3682: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3084 - accuracy: 0.9020\n","Epoch 3683/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3110 - accuracy: 0.8997\n","Epoch 3683: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3107 - accuracy: 0.8998\n","Epoch 3684/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3131 - accuracy: 0.9009\n","Epoch 3684: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3136 - accuracy: 0.9007\n","Epoch 3685/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3043 - accuracy: 0.9025\n","Epoch 3685: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3112 - accuracy: 0.8996\n","Epoch 3686/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3133 - accuracy: 0.9016\n","Epoch 3686: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3145 - accuracy: 0.9012\n","Epoch 3687/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3150 - accuracy: 0.9016\n","Epoch 3687: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3154 - accuracy: 0.9011\n","Epoch 3688/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3073 - accuracy: 0.9053\n","Epoch 3688: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3113 - accuracy: 0.9034\n","Epoch 3689/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3088 - accuracy: 0.9021\n","Epoch 3689: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3142 - accuracy: 0.8996\n","Epoch 3690/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3133 - accuracy: 0.9007\n","Epoch 3690: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3146 - accuracy: 0.9003\n","Epoch 3691/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3053 - accuracy: 0.9035\n","Epoch 3691: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3131 - accuracy: 0.9015\n","Epoch 3692/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3067 - accuracy: 0.9018\n","Epoch 3692: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3120 - accuracy: 0.8998\n","Epoch 3693/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3093 - accuracy: 0.9036\n","Epoch 3693: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3125 - accuracy: 0.9016\n","Epoch 3694/4000\n","8/8 [==============================] - ETA: 0s - loss: 0.3130 - accuracy: 0.8979\n","Epoch 3694: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3130 - accuracy: 0.8979\n","Epoch 3695/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3113 - accuracy: 0.9015\n","Epoch 3695: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3156 - accuracy: 0.8998\n","Epoch 3696/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3162 - accuracy: 0.9008\n","Epoch 3696: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3147 - accuracy: 0.9007\n","Epoch 3697/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3066 - accuracy: 0.9009\n","Epoch 3697: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3098 - accuracy: 0.9001\n","Epoch 3698/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3063 - accuracy: 0.9030\n","Epoch 3698: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3118 - accuracy: 0.9009\n","Epoch 3699/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3064 - accuracy: 0.9039\n","Epoch 3699: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3100 - accuracy: 0.9023\n","Epoch 3700/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3071 - accuracy: 0.9016\n","Epoch 3700: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3087 - accuracy: 0.9015\n","Epoch 3701/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3133 - accuracy: 0.8982\n","Epoch 3701: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3107 - accuracy: 0.8994\n","Epoch 3702/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3094 - accuracy: 0.9009\n","Epoch 3702: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3108 - accuracy: 0.9001\n","Epoch 3703/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3080 - accuracy: 0.9012\n","Epoch 3703: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3084 - accuracy: 0.9006\n","Epoch 3704/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3093 - accuracy: 0.8997\n","Epoch 3704: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3106 - accuracy: 0.8996\n","Epoch 3705/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3101 - accuracy: 0.9011\n","Epoch 3705: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3127 - accuracy: 0.8998\n","Epoch 3706/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3042 - accuracy: 0.9036\n","Epoch 3706: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3092 - accuracy: 0.9016\n","Epoch 3707/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3098 - accuracy: 0.8996\n","Epoch 3707: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3106 - accuracy: 0.8990\n","Epoch 3708/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3111 - accuracy: 0.9028\n","Epoch 3708: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3116 - accuracy: 0.9023\n","Epoch 3709/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3049 - accuracy: 0.9026\n","Epoch 3709: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 56ms/step - loss: 0.3112 - accuracy: 0.9012\n","Epoch 3710/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3100 - accuracy: 0.8991\n","Epoch 3710: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3131 - accuracy: 0.8981\n","Epoch 3711/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3114 - accuracy: 0.9005\n","Epoch 3711: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 56ms/step - loss: 0.3131 - accuracy: 0.8993\n","Epoch 3712/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3087 - accuracy: 0.9021\n","Epoch 3712: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 49ms/step - loss: 0.3134 - accuracy: 0.8994\n","Epoch 3713/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3135 - accuracy: 0.9018\n","Epoch 3713: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3139 - accuracy: 0.9014\n","Epoch 3714/4000\n","8/8 [==============================] - ETA: 0s - loss: 0.3147 - accuracy: 0.8994\n","Epoch 3714: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3147 - accuracy: 0.8994\n","Epoch 3715/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3168 - accuracy: 0.8972\n","Epoch 3715: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3153 - accuracy: 0.8974\n","Epoch 3716/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3104 - accuracy: 0.9011\n","Epoch 3716: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3118 - accuracy: 0.8998\n","Epoch 3717/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3142 - accuracy: 0.8996\n","Epoch 3717: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3150 - accuracy: 0.8998\n","Epoch 3718/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3077 - accuracy: 0.9035\n","Epoch 3718: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3133 - accuracy: 0.9016\n","Epoch 3719/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3053 - accuracy: 0.9009\n","Epoch 3719: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3115 - accuracy: 0.8998\n","Epoch 3720/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3092 - accuracy: 0.9021\n","Epoch 3720: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3134 - accuracy: 0.8997\n","Epoch 3721/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3038 - accuracy: 0.9058\n","Epoch 3721: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3144 - accuracy: 0.9012\n","Epoch 3722/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3096 - accuracy: 0.9018\n","Epoch 3722: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 57ms/step - loss: 0.3131 - accuracy: 0.9007\n","Epoch 3723/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3138 - accuracy: 0.9026\n","Epoch 3723: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3137 - accuracy: 0.9021\n","Epoch 3724/4000\n","8/8 [==============================] - ETA: 0s - loss: 0.3152 - accuracy: 0.8997\n","Epoch 3724: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 57ms/step - loss: 0.3152 - accuracy: 0.8997\n","Epoch 3725/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3132 - accuracy: 0.9019\n","Epoch 3725: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 48ms/step - loss: 0.3124 - accuracy: 0.9021\n","Epoch 3726/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3142 - accuracy: 0.8991\n","Epoch 3726: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3149 - accuracy: 0.8992\n","Epoch 3727/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3150 - accuracy: 0.9003\n","Epoch 3727: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3139 - accuracy: 0.9010\n","Epoch 3728/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3080 - accuracy: 0.9011\n","Epoch 3728: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3118 - accuracy: 0.8996\n","Epoch 3729/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3097 - accuracy: 0.9001\n","Epoch 3729: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3092 - accuracy: 0.8999\n","Epoch 3730/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3123 - accuracy: 0.8998\n","Epoch 3730: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3107 - accuracy: 0.8996\n","Epoch 3731/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3056 - accuracy: 0.9018\n","Epoch 3731: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3085 - accuracy: 0.9007\n","Epoch 3732/4000\n","8/8 [==============================] - ETA: 0s - loss: 0.3116 - accuracy: 0.9002\n","Epoch 3732: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3116 - accuracy: 0.9002\n","Epoch 3733/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3123 - accuracy: 0.9035\n","Epoch 3733: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3134 - accuracy: 0.9024\n","Epoch 3734/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3091 - accuracy: 0.9037\n","Epoch 3734: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3098 - accuracy: 0.9034\n","Epoch 3735/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3064 - accuracy: 0.9026\n","Epoch 3735: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3107 - accuracy: 0.9012\n","Epoch 3736/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3089 - accuracy: 0.9005\n","Epoch 3736: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3116 - accuracy: 0.8999\n","Epoch 3737/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3079 - accuracy: 0.9032\n","Epoch 3737: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3125 - accuracy: 0.9019\n","Epoch 3738/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3174 - accuracy: 0.8996\n","Epoch 3738: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3125 - accuracy: 0.9011\n","Epoch 3739/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3118 - accuracy: 0.9015\n","Epoch 3739: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3139 - accuracy: 0.9011\n","Epoch 3740/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3047 - accuracy: 0.9009\n","Epoch 3740: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3137 - accuracy: 0.8987\n","Epoch 3741/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3122 - accuracy: 0.9011\n","Epoch 3741: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3119 - accuracy: 0.9006\n","Epoch 3742/4000\n","8/8 [==============================] - ETA: 0s - loss: 0.3117 - accuracy: 0.9023\n","Epoch 3742: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3117 - accuracy: 0.9023\n","Epoch 3743/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3115 - accuracy: 0.9003\n","Epoch 3743: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3119 - accuracy: 0.9002\n","Epoch 3744/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3158 - accuracy: 0.9014\n","Epoch 3744: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3169 - accuracy: 0.9010\n","Epoch 3745/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3141 - accuracy: 0.9001\n","Epoch 3745: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3142 - accuracy: 0.9001\n","Epoch 3746/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3150 - accuracy: 0.8997\n","Epoch 3746: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3169 - accuracy: 0.8985\n","Epoch 3747/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3107 - accuracy: 0.9012\n","Epoch 3747: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3116 - accuracy: 0.9009\n","Epoch 3748/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3134 - accuracy: 0.9009\n","Epoch 3748: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3116 - accuracy: 0.9016\n","Epoch 3749/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3131 - accuracy: 0.8989\n","Epoch 3749: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3132 - accuracy: 0.8984\n","Epoch 3750/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3075 - accuracy: 0.9008\n","Epoch 3750: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3119 - accuracy: 0.8990\n","Epoch 3751/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3097 - accuracy: 0.9018\n","Epoch 3751: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3147 - accuracy: 0.9005\n","Epoch 3752/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3099 - accuracy: 0.9016\n","Epoch 3752: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3148 - accuracy: 0.8994\n","Epoch 3753/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3089 - accuracy: 0.9007\n","Epoch 3753: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3100 - accuracy: 0.9015\n","Epoch 3754/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3161 - accuracy: 0.8989\n","Epoch 3754: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3165 - accuracy: 0.8979\n","Epoch 3755/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3110 - accuracy: 0.9012\n","Epoch 3755: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3129 - accuracy: 0.9002\n","Epoch 3756/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3091 - accuracy: 0.9022\n","Epoch 3756: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3125 - accuracy: 0.9009\n","Epoch 3757/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3170 - accuracy: 0.8990\n","Epoch 3757: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3124 - accuracy: 0.9002\n","Epoch 3758/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3141 - accuracy: 0.9023\n","Epoch 3758: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 48ms/step - loss: 0.3130 - accuracy: 0.9015\n","Epoch 3759/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3102 - accuracy: 0.9022\n","Epoch 3759: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3125 - accuracy: 0.9009\n","Epoch 3760/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3104 - accuracy: 0.9019\n","Epoch 3760: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3126 - accuracy: 0.9005\n","Epoch 3761/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3100 - accuracy: 0.9029\n","Epoch 3761: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3134 - accuracy: 0.9016\n","Epoch 3762/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3090 - accuracy: 0.9016\n","Epoch 3762: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3125 - accuracy: 0.8998\n","Epoch 3763/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3064 - accuracy: 0.9012\n","Epoch 3763: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3112 - accuracy: 0.8998\n","Epoch 3764/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3121 - accuracy: 0.9023\n","Epoch 3764: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3127 - accuracy: 0.9015\n","Epoch 3765/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3109 - accuracy: 0.9037\n","Epoch 3765: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 56ms/step - loss: 0.3135 - accuracy: 0.9024\n","Epoch 3766/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3064 - accuracy: 0.9029\n","Epoch 3766: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3169 - accuracy: 0.8983\n","Epoch 3767/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3136 - accuracy: 0.9018\n","Epoch 3767: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3199 - accuracy: 0.9003\n","Epoch 3768/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3180 - accuracy: 0.9001\n","Epoch 3768: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3179 - accuracy: 0.8999\n","Epoch 3769/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3139 - accuracy: 0.9008\n","Epoch 3769: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3180 - accuracy: 0.8988\n","Epoch 3770/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3202 - accuracy: 0.8987\n","Epoch 3770: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3182 - accuracy: 0.8996\n","Epoch 3771/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3125 - accuracy: 0.9018\n","Epoch 3771: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3140 - accuracy: 0.9001\n","Epoch 3772/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3061 - accuracy: 0.9049\n","Epoch 3772: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3120 - accuracy: 0.9025\n","Epoch 3773/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3103 - accuracy: 0.9032\n","Epoch 3773: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3122 - accuracy: 0.9014\n","Epoch 3774/4000\n","8/8 [==============================] - ETA: 0s - loss: 0.3126 - accuracy: 0.8989\n","Epoch 3774: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3126 - accuracy: 0.8989\n","Epoch 3775/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3134 - accuracy: 0.9001\n","Epoch 3775: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3168 - accuracy: 0.8985\n","Epoch 3776/4000\n","8/8 [==============================] - ETA: 0s - loss: 0.3158 - accuracy: 0.8996\n","Epoch 3776: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3158 - accuracy: 0.8996\n","Epoch 3777/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3154 - accuracy: 0.8977\n","Epoch 3777: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3133 - accuracy: 0.8988\n","Epoch 3778/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3122 - accuracy: 0.9007\n","Epoch 3778: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3135 - accuracy: 0.8996\n","Epoch 3779/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3100 - accuracy: 0.9037\n","Epoch 3779: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3129 - accuracy: 0.9021\n","Epoch 3780/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3103 - accuracy: 0.9015\n","Epoch 3780: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3121 - accuracy: 0.9005\n","Epoch 3781/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3132 - accuracy: 0.8986\n","Epoch 3781: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 57ms/step - loss: 0.3141 - accuracy: 0.8980\n","Epoch 3782/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3070 - accuracy: 0.9021\n","Epoch 3782: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3127 - accuracy: 0.9001\n","Epoch 3783/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3135 - accuracy: 0.9009\n","Epoch 3783: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3119 - accuracy: 0.9010\n","Epoch 3784/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3078 - accuracy: 0.9018\n","Epoch 3784: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3122 - accuracy: 0.8998\n","Epoch 3785/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3111 - accuracy: 0.9003\n","Epoch 3785: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3124 - accuracy: 0.9001\n","Epoch 3786/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3146 - accuracy: 0.9001\n","Epoch 3786: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3139 - accuracy: 0.9006\n","Epoch 3787/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3099 - accuracy: 0.9022\n","Epoch 3787: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3132 - accuracy: 0.9003\n","Epoch 3788/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3124 - accuracy: 0.9000\n","Epoch 3788: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3140 - accuracy: 0.8987\n","Epoch 3789/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3138 - accuracy: 0.8991\n","Epoch 3789: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3112 - accuracy: 0.8996\n","Epoch 3790/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3105 - accuracy: 0.8997\n","Epoch 3790: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3132 - accuracy: 0.8996\n","Epoch 3791/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3109 - accuracy: 0.9042\n","Epoch 3791: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3146 - accuracy: 0.9027\n","Epoch 3792/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3093 - accuracy: 0.8987\n","Epoch 3792: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3105 - accuracy: 0.8992\n","Epoch 3793/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3140 - accuracy: 0.8983\n","Epoch 3793: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3133 - accuracy: 0.8990\n","Epoch 3794/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3118 - accuracy: 0.8996\n","Epoch 3794: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3108 - accuracy: 0.8998\n","Epoch 3795/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3100 - accuracy: 0.9014\n","Epoch 3795: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3106 - accuracy: 0.9007\n","Epoch 3796/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3071 - accuracy: 0.9001\n","Epoch 3796: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3110 - accuracy: 0.8989\n","Epoch 3797/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3093 - accuracy: 0.8997\n","Epoch 3797: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3094 - accuracy: 0.8992\n","Epoch 3798/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3072 - accuracy: 0.9023\n","Epoch 3798: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 56ms/step - loss: 0.3114 - accuracy: 0.9010\n","Epoch 3799/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3090 - accuracy: 0.9035\n","Epoch 3799: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3102 - accuracy: 0.9029\n","Epoch 3800/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3115 - accuracy: 0.9022\n","Epoch 3800: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3120 - accuracy: 0.9014\n","Epoch 3801/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3062 - accuracy: 0.9015\n","Epoch 3801: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3111 - accuracy: 0.8996\n","Epoch 3802/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3090 - accuracy: 0.9007\n","Epoch 3802: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3138 - accuracy: 0.8996\n","Epoch 3803/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3089 - accuracy: 0.9030\n","Epoch 3803: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3145 - accuracy: 0.9003\n","Epoch 3804/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3122 - accuracy: 0.9042\n","Epoch 3804: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3135 - accuracy: 0.9034\n","Epoch 3805/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3135 - accuracy: 0.8972\n","Epoch 3805: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3201 - accuracy: 0.8954\n","Epoch 3806/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3135 - accuracy: 0.9023\n","Epoch 3806: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3192 - accuracy: 0.8999\n","Epoch 3807/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3164 - accuracy: 0.9008\n","Epoch 3807: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3191 - accuracy: 0.8996\n","Epoch 3808/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3086 - accuracy: 0.9026\n","Epoch 3808: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3142 - accuracy: 0.8996\n","Epoch 3809/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3125 - accuracy: 0.8980\n","Epoch 3809: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3134 - accuracy: 0.8976\n","Epoch 3810/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3111 - accuracy: 0.9040\n","Epoch 3810: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3148 - accuracy: 0.9020\n","Epoch 3811/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3152 - accuracy: 0.9015\n","Epoch 3811: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3150 - accuracy: 0.9009\n","Epoch 3812/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3072 - accuracy: 0.9035\n","Epoch 3812: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3146 - accuracy: 0.9011\n","Epoch 3813/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3073 - accuracy: 0.9008\n","Epoch 3813: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3145 - accuracy: 0.8992\n","Epoch 3814/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3136 - accuracy: 0.9011\n","Epoch 3814: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 49ms/step - loss: 0.3131 - accuracy: 0.9016\n","Epoch 3815/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3172 - accuracy: 0.8997\n","Epoch 3815: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3152 - accuracy: 0.9005\n","Epoch 3816/4000\n","8/8 [==============================] - ETA: 0s - loss: 0.3196 - accuracy: 0.8993\n","Epoch 3816: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3196 - accuracy: 0.8993\n","Epoch 3817/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3118 - accuracy: 0.9005\n","Epoch 3817: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3144 - accuracy: 0.8994\n","Epoch 3818/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3143 - accuracy: 0.8994\n","Epoch 3818: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3126 - accuracy: 0.9003\n","Epoch 3819/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3059 - accuracy: 0.9021\n","Epoch 3819: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3100 - accuracy: 0.9006\n","Epoch 3820/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3115 - accuracy: 0.8991\n","Epoch 3820: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 49ms/step - loss: 0.3134 - accuracy: 0.8977\n","Epoch 3821/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3074 - accuracy: 0.9016\n","Epoch 3821: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3107 - accuracy: 0.9001\n","Epoch 3822/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3110 - accuracy: 0.9011\n","Epoch 3822: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3120 - accuracy: 0.9010\n","Epoch 3823/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3173 - accuracy: 0.8965\n","Epoch 3823: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3155 - accuracy: 0.8971\n","Epoch 3824/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3092 - accuracy: 0.9023\n","Epoch 3824: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3159 - accuracy: 0.8994\n","Epoch 3825/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3160 - accuracy: 0.8997\n","Epoch 3825: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 56ms/step - loss: 0.3140 - accuracy: 0.9006\n","Epoch 3826/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3153 - accuracy: 0.9012\n","Epoch 3826: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3146 - accuracy: 0.9014\n","Epoch 3827/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3090 - accuracy: 0.9008\n","Epoch 3827: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3112 - accuracy: 0.8994\n","Epoch 3828/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3087 - accuracy: 0.9022\n","Epoch 3828: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3109 - accuracy: 0.9014\n","Epoch 3829/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3129 - accuracy: 0.8996\n","Epoch 3829: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3127 - accuracy: 0.8988\n","Epoch 3830/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3106 - accuracy: 0.9014\n","Epoch 3830: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3120 - accuracy: 0.9009\n","Epoch 3831/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3132 - accuracy: 0.8982\n","Epoch 3831: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3132 - accuracy: 0.8985\n","Epoch 3832/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3081 - accuracy: 0.9012\n","Epoch 3832: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3118 - accuracy: 0.8994\n","Epoch 3833/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3088 - accuracy: 0.9008\n","Epoch 3833: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3161 - accuracy: 0.8990\n","Epoch 3834/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3142 - accuracy: 0.9005\n","Epoch 3834: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3149 - accuracy: 0.8999\n","Epoch 3835/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3098 - accuracy: 0.8993\n","Epoch 3835: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 57ms/step - loss: 0.3127 - accuracy: 0.8981\n","Epoch 3836/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3045 - accuracy: 0.9022\n","Epoch 3836: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 49ms/step - loss: 0.3126 - accuracy: 0.9001\n","Epoch 3837/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3131 - accuracy: 0.9003\n","Epoch 3837: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 49ms/step - loss: 0.3176 - accuracy: 0.8983\n","Epoch 3838/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3122 - accuracy: 0.9011\n","Epoch 3838: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 56ms/step - loss: 0.3156 - accuracy: 0.9001\n","Epoch 3839/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3132 - accuracy: 0.9012\n","Epoch 3839: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3170 - accuracy: 0.9002\n","Epoch 3840/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3064 - accuracy: 0.9008\n","Epoch 3840: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3126 - accuracy: 0.8984\n","Epoch 3841/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3088 - accuracy: 0.9018\n","Epoch 3841: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3105 - accuracy: 0.9009\n","Epoch 3842/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3091 - accuracy: 0.9030\n","Epoch 3842: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 56ms/step - loss: 0.3127 - accuracy: 0.9010\n","Epoch 3843/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3121 - accuracy: 0.9000\n","Epoch 3843: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3141 - accuracy: 0.9002\n","Epoch 3844/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3057 - accuracy: 0.9033\n","Epoch 3844: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3113 - accuracy: 0.9006\n","Epoch 3845/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3069 - accuracy: 0.9018\n","Epoch 3845: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3107 - accuracy: 0.9002\n","Epoch 3846/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3077 - accuracy: 0.9008\n","Epoch 3846: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3139 - accuracy: 0.8990\n","Epoch 3847/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3069 - accuracy: 0.9033\n","Epoch 3847: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3128 - accuracy: 0.9015\n","Epoch 3848/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3118 - accuracy: 0.9004\n","Epoch 3848: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3104 - accuracy: 0.9002\n","Epoch 3849/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3131 - accuracy: 0.9007\n","Epoch 3849: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3126 - accuracy: 0.9014\n","Epoch 3850/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3101 - accuracy: 0.9009\n","Epoch 3850: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3110 - accuracy: 0.9006\n","Epoch 3851/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3147 - accuracy: 0.8986\n","Epoch 3851: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3141 - accuracy: 0.8992\n","Epoch 3852/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3089 - accuracy: 0.9009\n","Epoch 3852: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3112 - accuracy: 0.9003\n","Epoch 3853/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3086 - accuracy: 0.8998\n","Epoch 3853: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3098 - accuracy: 0.8989\n","Epoch 3854/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3073 - accuracy: 0.9022\n","Epoch 3854: loss improved from 0.30800 to 0.30766, saving model to best_model_3.hdf5\n","8/8 [==============================] - 1s 103ms/step - loss: 0.3077 - accuracy: 0.9018\n","Epoch 3855/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3044 - accuracy: 0.9015\n","Epoch 3855: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3104 - accuracy: 0.8998\n","Epoch 3856/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3086 - accuracy: 0.9015\n","Epoch 3856: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3104 - accuracy: 0.9006\n","Epoch 3857/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3082 - accuracy: 0.9019\n","Epoch 3857: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3108 - accuracy: 0.9009\n","Epoch 3858/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3119 - accuracy: 0.9009\n","Epoch 3858: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3123 - accuracy: 0.9011\n","Epoch 3859/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3107 - accuracy: 0.9008\n","Epoch 3859: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 49ms/step - loss: 0.3119 - accuracy: 0.9006\n","Epoch 3860/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3088 - accuracy: 0.9007\n","Epoch 3860: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3112 - accuracy: 0.8997\n","Epoch 3861/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3100 - accuracy: 0.9015\n","Epoch 3861: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3083 - accuracy: 0.9025\n","Epoch 3862/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3079 - accuracy: 0.8996\n","Epoch 3862: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3102 - accuracy: 0.8994\n","Epoch 3863/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3157 - accuracy: 0.9003\n","Epoch 3863: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3153 - accuracy: 0.8999\n","Epoch 3864/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3090 - accuracy: 0.9008\n","Epoch 3864: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3139 - accuracy: 0.8993\n","Epoch 3865/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3079 - accuracy: 0.9021\n","Epoch 3865: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3118 - accuracy: 0.9014\n","Epoch 3866/4000\n","8/8 [==============================] - ETA: 0s - loss: 0.3142 - accuracy: 0.9010\n","Epoch 3866: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 57ms/step - loss: 0.3142 - accuracy: 0.9010\n","Epoch 3867/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3106 - accuracy: 0.8997\n","Epoch 3867: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3149 - accuracy: 0.8983\n","Epoch 3868/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3171 - accuracy: 0.9008\n","Epoch 3868: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3170 - accuracy: 0.9006\n","Epoch 3869/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3134 - accuracy: 0.9012\n","Epoch 3869: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3157 - accuracy: 0.9003\n","Epoch 3870/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3209 - accuracy: 0.9008\n","Epoch 3870: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3201 - accuracy: 0.9010\n","Epoch 3871/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3166 - accuracy: 0.9001\n","Epoch 3871: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3186 - accuracy: 0.8993\n","Epoch 3872/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3149 - accuracy: 0.8997\n","Epoch 3872: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3154 - accuracy: 0.8992\n","Epoch 3873/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3113 - accuracy: 0.9026\n","Epoch 3873: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3174 - accuracy: 0.9003\n","Epoch 3874/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3137 - accuracy: 0.8983\n","Epoch 3874: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3147 - accuracy: 0.8981\n","Epoch 3875/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3163 - accuracy: 0.9009\n","Epoch 3875: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3184 - accuracy: 0.8994\n","Epoch 3876/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3150 - accuracy: 0.9007\n","Epoch 3876: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3165 - accuracy: 0.9003\n","Epoch 3877/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3208 - accuracy: 0.9005\n","Epoch 3877: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3192 - accuracy: 0.9009\n","Epoch 3878/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3154 - accuracy: 0.9029\n","Epoch 3878: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3177 - accuracy: 0.9010\n","Epoch 3879/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3198 - accuracy: 0.8990\n","Epoch 3879: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3186 - accuracy: 0.8990\n","Epoch 3880/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3145 - accuracy: 0.9009\n","Epoch 3880: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3170 - accuracy: 0.9007\n","Epoch 3881/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3239 - accuracy: 0.8984\n","Epoch 3881: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3223 - accuracy: 0.8988\n","Epoch 3882/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3277 - accuracy: 0.8991\n","Epoch 3882: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3279 - accuracy: 0.8984\n","Epoch 3883/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3330 - accuracy: 0.8975\n","Epoch 3883: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3357 - accuracy: 0.8965\n","Epoch 3884/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3433 - accuracy: 0.8996\n","Epoch 3884: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3451 - accuracy: 0.8989\n","Epoch 3885/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3563 - accuracy: 0.8915\n","Epoch 3885: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3541 - accuracy: 0.8926\n","Epoch 3886/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3655 - accuracy: 0.8947\n","Epoch 3886: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3671 - accuracy: 0.8946\n","Epoch 3887/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3809 - accuracy: 0.8923\n","Epoch 3887: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3899 - accuracy: 0.8895\n","Epoch 3888/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.4068 - accuracy: 0.8841\n","Epoch 3888: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 54ms/step - loss: 0.4110 - accuracy: 0.8827\n","Epoch 3889/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.4631 - accuracy: 0.8736\n","Epoch 3889: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 54ms/step - loss: 0.4605 - accuracy: 0.8752\n","Epoch 3890/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.5645 - accuracy: 0.8510\n","Epoch 3890: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 55ms/step - loss: 0.5737 - accuracy: 0.8491\n","Epoch 3891/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.6499 - accuracy: 0.8354\n","Epoch 3891: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 55ms/step - loss: 0.6652 - accuracy: 0.8333\n","Epoch 3892/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.7582 - accuracy: 0.8100\n","Epoch 3892: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 52ms/step - loss: 0.7625 - accuracy: 0.8086\n","Epoch 3893/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.8074 - accuracy: 0.8076\n","Epoch 3893: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 51ms/step - loss: 0.8247 - accuracy: 0.8027\n","Epoch 3894/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.8081 - accuracy: 0.8188\n","Epoch 3894: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 55ms/step - loss: 0.8154 - accuracy: 0.8161\n","Epoch 3895/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.7536 - accuracy: 0.8357\n","Epoch 3895: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 52ms/step - loss: 0.7659 - accuracy: 0.8345\n","Epoch 3896/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.7178 - accuracy: 0.8450\n","Epoch 3896: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 51ms/step - loss: 0.7188 - accuracy: 0.8443\n","Epoch 3897/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.6784 - accuracy: 0.8560\n","Epoch 3897: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 54ms/step - loss: 0.6864 - accuracy: 0.8539\n","Epoch 3898/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.6296 - accuracy: 0.8623\n","Epoch 3898: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 53ms/step - loss: 0.6319 - accuracy: 0.8616\n","Epoch 3899/4000\n","8/8 [==============================] - ETA: 0s - loss: 0.5865 - accuracy: 0.8672\n","Epoch 3899: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 52ms/step - loss: 0.5865 - accuracy: 0.8672\n","Epoch 3900/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.5343 - accuracy: 0.8799\n","Epoch 3900: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 53ms/step - loss: 0.5370 - accuracy: 0.8790\n","Epoch 3901/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.5065 - accuracy: 0.8842\n","Epoch 3901: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 49ms/step - loss: 0.5072 - accuracy: 0.8844\n","Epoch 3902/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.4701 - accuracy: 0.8903\n","Epoch 3902: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 52ms/step - loss: 0.4717 - accuracy: 0.8893\n","Epoch 3903/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.4425 - accuracy: 0.8929\n","Epoch 3903: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 55ms/step - loss: 0.4471 - accuracy: 0.8908\n","Epoch 3904/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.4237 - accuracy: 0.8962\n","Epoch 3904: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 54ms/step - loss: 0.4234 - accuracy: 0.8958\n","Epoch 3905/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.4042 - accuracy: 0.8959\n","Epoch 3905: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 54ms/step - loss: 0.4006 - accuracy: 0.8965\n","Epoch 3906/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3824 - accuracy: 0.9003\n","Epoch 3906: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3858 - accuracy: 0.8993\n","Epoch 3907/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3745 - accuracy: 0.8984\n","Epoch 3907: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3728 - accuracy: 0.8985\n","Epoch 3908/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3551 - accuracy: 0.9007\n","Epoch 3908: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3569 - accuracy: 0.8990\n","Epoch 3909/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3470 - accuracy: 0.9035\n","Epoch 3909: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3482 - accuracy: 0.9021\n","Epoch 3910/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3356 - accuracy: 0.9030\n","Epoch 3910: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3382 - accuracy: 0.9012\n","Epoch 3911/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3297 - accuracy: 0.9021\n","Epoch 3911: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3333 - accuracy: 0.9009\n","Epoch 3912/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3269 - accuracy: 0.9011\n","Epoch 3912: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3275 - accuracy: 0.9011\n","Epoch 3913/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3247 - accuracy: 0.9015\n","Epoch 3913: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3254 - accuracy: 0.9007\n","Epoch 3914/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3175 - accuracy: 0.9008\n","Epoch 3914: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3205 - accuracy: 0.9006\n","Epoch 3915/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3196 - accuracy: 0.9019\n","Epoch 3915: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3180 - accuracy: 0.9023\n","Epoch 3916/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3172 - accuracy: 0.9008\n","Epoch 3916: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3151 - accuracy: 0.9016\n","Epoch 3917/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3151 - accuracy: 0.9028\n","Epoch 3917: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3156 - accuracy: 0.9018\n","Epoch 3918/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3100 - accuracy: 0.9025\n","Epoch 3918: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3144 - accuracy: 0.9010\n","Epoch 3919/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3089 - accuracy: 0.9022\n","Epoch 3919: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3133 - accuracy: 0.9012\n","Epoch 3920/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3114 - accuracy: 0.9011\n","Epoch 3920: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3144 - accuracy: 0.9007\n","Epoch 3921/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3085 - accuracy: 0.9025\n","Epoch 3921: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3108 - accuracy: 0.9010\n","Epoch 3922/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3088 - accuracy: 0.9025\n","Epoch 3922: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3118 - accuracy: 0.9015\n","Epoch 3923/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3088 - accuracy: 0.9040\n","Epoch 3923: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3111 - accuracy: 0.9023\n","Epoch 3924/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3107 - accuracy: 0.8975\n","Epoch 3924: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3117 - accuracy: 0.8970\n","Epoch 3925/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3098 - accuracy: 0.9011\n","Epoch 3925: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3115 - accuracy: 0.9005\n","Epoch 3926/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3103 - accuracy: 0.9008\n","Epoch 3926: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3084 - accuracy: 0.9015\n","Epoch 3927/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3115 - accuracy: 0.8997\n","Epoch 3927: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3108 - accuracy: 0.9010\n","Epoch 3928/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3077 - accuracy: 0.9014\n","Epoch 3928: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3090 - accuracy: 0.9003\n","Epoch 3929/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3099 - accuracy: 0.9016\n","Epoch 3929: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3091 - accuracy: 0.9021\n","Epoch 3930/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3001 - accuracy: 0.9033\n","Epoch 3930: loss improved from 0.30766 to 0.30766, saving model to best_model_3.hdf5\n","8/8 [==============================] - 1s 108ms/step - loss: 0.3077 - accuracy: 0.9005\n","Epoch 3931/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3108 - accuracy: 0.9019\n","Epoch 3931: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3093 - accuracy: 0.9016\n","Epoch 3932/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3108 - accuracy: 0.9001\n","Epoch 3932: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3130 - accuracy: 0.8994\n","Epoch 3933/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3107 - accuracy: 0.9005\n","Epoch 3933: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3115 - accuracy: 0.9007\n","Epoch 3934/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3118 - accuracy: 0.9026\n","Epoch 3934: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3144 - accuracy: 0.9012\n","Epoch 3935/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3081 - accuracy: 0.9003\n","Epoch 3935: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3091 - accuracy: 0.8996\n","Epoch 3936/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3060 - accuracy: 0.9026\n","Epoch 3936: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 56ms/step - loss: 0.3130 - accuracy: 0.8996\n","Epoch 3937/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3065 - accuracy: 0.9015\n","Epoch 3937: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3097 - accuracy: 0.8997\n","Epoch 3938/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3070 - accuracy: 0.8991\n","Epoch 3938: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3094 - accuracy: 0.8983\n","Epoch 3939/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3068 - accuracy: 0.9004\n","Epoch 3939: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3118 - accuracy: 0.8993\n","Epoch 3940/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3060 - accuracy: 0.9032\n","Epoch 3940: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3094 - accuracy: 0.9021\n","Epoch 3941/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3058 - accuracy: 0.9001\n","Epoch 3941: loss improved from 0.30766 to 0.30741, saving model to best_model_3.hdf5\n","8/8 [==============================] - 1s 109ms/step - loss: 0.3074 - accuracy: 0.8999\n","Epoch 3942/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3080 - accuracy: 0.9012\n","Epoch 3942: loss did not improve from 0.30741\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3094 - accuracy: 0.9006\n","Epoch 3943/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3029 - accuracy: 0.9051\n","Epoch 3943: loss improved from 0.30741 to 0.30673, saving model to best_model_3.hdf5\n","8/8 [==============================] - 1s 108ms/step - loss: 0.3067 - accuracy: 0.9038\n","Epoch 3944/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3041 - accuracy: 0.9049\n","Epoch 3944: loss did not improve from 0.30673\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3081 - accuracy: 0.9021\n","Epoch 3945/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3065 - accuracy: 0.9004\n","Epoch 3945: loss did not improve from 0.30673\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3117 - accuracy: 0.8996\n","Epoch 3946/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3099 - accuracy: 0.9001\n","Epoch 3946: loss did not improve from 0.30673\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3083 - accuracy: 0.9009\n","Epoch 3947/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3064 - accuracy: 0.9026\n","Epoch 3947: loss did not improve from 0.30673\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3101 - accuracy: 0.9016\n","Epoch 3948/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3060 - accuracy: 0.9028\n","Epoch 3948: loss did not improve from 0.30673\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3104 - accuracy: 0.9009\n","Epoch 3949/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3079 - accuracy: 0.9009\n","Epoch 3949: loss did not improve from 0.30673\n","8/8 [==============================] - 0s 57ms/step - loss: 0.3072 - accuracy: 0.9010\n","Epoch 3950/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3033 - accuracy: 0.9040\n","Epoch 3950: loss did not improve from 0.30673\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3088 - accuracy: 0.9021\n","Epoch 3951/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3067 - accuracy: 0.9004\n","Epoch 3951: loss did not improve from 0.30673\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3076 - accuracy: 0.9002\n","Epoch 3952/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3095 - accuracy: 0.8987\n","Epoch 3952: loss did not improve from 0.30673\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3105 - accuracy: 0.8985\n","Epoch 3953/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3086 - accuracy: 0.9016\n","Epoch 3953: loss did not improve from 0.30673\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3081 - accuracy: 0.9011\n","Epoch 3954/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3020 - accuracy: 0.9029\n","Epoch 3954: loss did not improve from 0.30673\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3093 - accuracy: 0.8998\n","Epoch 3955/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3028 - accuracy: 0.9022\n","Epoch 3955: loss did not improve from 0.30673\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3068 - accuracy: 0.9010\n","Epoch 3956/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3058 - accuracy: 0.9032\n","Epoch 3956: loss did not improve from 0.30673\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3080 - accuracy: 0.9027\n","Epoch 3957/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3062 - accuracy: 0.9021\n","Epoch 3957: loss did not improve from 0.30673\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3092 - accuracy: 0.9006\n","Epoch 3958/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3019 - accuracy: 0.9028\n","Epoch 3958: loss improved from 0.30673 to 0.30523, saving model to best_model_3.hdf5\n","8/8 [==============================] - 1s 105ms/step - loss: 0.3052 - accuracy: 0.9016\n","Epoch 3959/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3020 - accuracy: 0.9003\n","Epoch 3959: loss did not improve from 0.30523\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3058 - accuracy: 0.8985\n","Epoch 3960/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3070 - accuracy: 0.9023\n","Epoch 3960: loss did not improve from 0.30523\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3067 - accuracy: 0.9020\n","Epoch 3961/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3108 - accuracy: 0.9011\n","Epoch 3961: loss did not improve from 0.30523\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3090 - accuracy: 0.9016\n","Epoch 3962/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3068 - accuracy: 0.9005\n","Epoch 3962: loss did not improve from 0.30523\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3077 - accuracy: 0.9001\n","Epoch 3963/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3038 - accuracy: 0.9018\n","Epoch 3963: loss improved from 0.30523 to 0.30493, saving model to best_model_3.hdf5\n","8/8 [==============================] - 1s 103ms/step - loss: 0.3049 - accuracy: 0.9015\n","Epoch 3964/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3017 - accuracy: 0.9001\n","Epoch 3964: loss did not improve from 0.30493\n","8/8 [==============================] - 0s 56ms/step - loss: 0.3065 - accuracy: 0.8980\n","Epoch 3965/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3111 - accuracy: 0.8982\n","Epoch 3965: loss did not improve from 0.30493\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3080 - accuracy: 0.8993\n","Epoch 3966/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3100 - accuracy: 0.9033\n","Epoch 3966: loss did not improve from 0.30493\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3100 - accuracy: 0.9029\n","Epoch 3967/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3105 - accuracy: 0.8990\n","Epoch 3967: loss did not improve from 0.30493\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3103 - accuracy: 0.8990\n","Epoch 3968/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3031 - accuracy: 0.9040\n","Epoch 3968: loss did not improve from 0.30493\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3058 - accuracy: 0.9027\n","Epoch 3969/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3042 - accuracy: 0.9019\n","Epoch 3969: loss did not improve from 0.30493\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3079 - accuracy: 0.9007\n","Epoch 3970/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3059 - accuracy: 0.8996\n","Epoch 3970: loss did not improve from 0.30493\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3086 - accuracy: 0.8985\n","Epoch 3971/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3105 - accuracy: 0.9023\n","Epoch 3971: loss did not improve from 0.30493\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3094 - accuracy: 0.9019\n","Epoch 3972/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3018 - accuracy: 0.9057\n","Epoch 3972: loss did not improve from 0.30493\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3057 - accuracy: 0.9041\n","Epoch 3973/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3079 - accuracy: 0.9019\n","Epoch 3973: loss did not improve from 0.30493\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3097 - accuracy: 0.9002\n","Epoch 3974/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3060 - accuracy: 0.9021\n","Epoch 3974: loss did not improve from 0.30493\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3073 - accuracy: 0.9019\n","Epoch 3975/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3077 - accuracy: 0.8998\n","Epoch 3975: loss did not improve from 0.30493\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3073 - accuracy: 0.8993\n","Epoch 3976/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3065 - accuracy: 0.8986\n","Epoch 3976: loss did not improve from 0.30493\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3080 - accuracy: 0.8976\n","Epoch 3977/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3027 - accuracy: 0.9018\n","Epoch 3977: loss did not improve from 0.30493\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3049 - accuracy: 0.9007\n","Epoch 3978/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3036 - accuracy: 0.9015\n","Epoch 3978: loss did not improve from 0.30493\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3063 - accuracy: 0.9011\n","Epoch 3979/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3031 - accuracy: 0.9018\n","Epoch 3979: loss did not improve from 0.30493\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3067 - accuracy: 0.9001\n","Epoch 3980/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3026 - accuracy: 0.9014\n","Epoch 3980: loss did not improve from 0.30493\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3054 - accuracy: 0.9009\n","Epoch 3981/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3088 - accuracy: 0.8997\n","Epoch 3981: loss did not improve from 0.30493\n","8/8 [==============================] - 0s 56ms/step - loss: 0.3054 - accuracy: 0.8999\n","Epoch 3982/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3063 - accuracy: 0.8996\n","Epoch 3982: loss did not improve from 0.30493\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3070 - accuracy: 0.8988\n","Epoch 3983/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3055 - accuracy: 0.9012\n","Epoch 3983: loss did not improve from 0.30493\n","8/8 [==============================] - 0s 58ms/step - loss: 0.3059 - accuracy: 0.9009\n","Epoch 3984/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3016 - accuracy: 0.9021\n","Epoch 3984: loss did not improve from 0.30493\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3056 - accuracy: 0.9002\n","Epoch 3985/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.2990 - accuracy: 0.9043\n","Epoch 3985: loss did not improve from 0.30493\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3052 - accuracy: 0.9019\n","Epoch 3986/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.2998 - accuracy: 0.9046\n","Epoch 3986: loss improved from 0.30493 to 0.30386, saving model to best_model_3.hdf5\n","8/8 [==============================] - 1s 103ms/step - loss: 0.3039 - accuracy: 0.9021\n","Epoch 3987/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.2983 - accuracy: 0.9019\n","Epoch 3987: loss did not improve from 0.30386\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3046 - accuracy: 0.8998\n","Epoch 3988/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3006 - accuracy: 0.9030\n","Epoch 3988: loss did not improve from 0.30386\n","8/8 [==============================] - 0s 56ms/step - loss: 0.3068 - accuracy: 0.9011\n","Epoch 3989/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3026 - accuracy: 0.9030\n","Epoch 3989: loss did not improve from 0.30386\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3085 - accuracy: 0.9005\n","Epoch 3990/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3074 - accuracy: 0.9026\n","Epoch 3990: loss did not improve from 0.30386\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3097 - accuracy: 0.9011\n","Epoch 3991/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3040 - accuracy: 0.9028\n","Epoch 3991: loss did not improve from 0.30386\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3065 - accuracy: 0.9011\n","Epoch 3992/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3082 - accuracy: 0.8996\n","Epoch 3992: loss did not improve from 0.30386\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3069 - accuracy: 0.9005\n","Epoch 3993/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3005 - accuracy: 0.9008\n","Epoch 3993: loss did not improve from 0.30386\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3055 - accuracy: 0.8994\n","Epoch 3994/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3067 - accuracy: 0.8994\n","Epoch 3994: loss did not improve from 0.30386\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3065 - accuracy: 0.8998\n","Epoch 3995/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3014 - accuracy: 0.9025\n","Epoch 3995: loss did not improve from 0.30386\n","8/8 [==============================] - 0s 56ms/step - loss: 0.3049 - accuracy: 0.9006\n","Epoch 3996/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3083 - accuracy: 0.9005\n","Epoch 3996: loss did not improve from 0.30386\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3074 - accuracy: 0.9003\n","Epoch 3997/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.2973 - accuracy: 0.9044\n","Epoch 3997: loss did not improve from 0.30386\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3056 - accuracy: 0.9021\n","Epoch 3998/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3060 - accuracy: 0.9025\n","Epoch 3998: loss did not improve from 0.30386\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3065 - accuracy: 0.9027\n","Epoch 3999/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3059 - accuracy: 0.9026\n","Epoch 3999: loss did not improve from 0.30386\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3072 - accuracy: 0.9027\n","Epoch 4000/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3040 - accuracy: 0.9014\n","Epoch 4000: loss did not improve from 0.30386\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3074 - accuracy: 0.8996\n"]}]},{"cell_type":"markdown","metadata":{"id":"FWJR7YxwYNs8"},"source":["# Plotting the training graphs "]},{"cell_type":"code","metadata":{"id":"rcXreH5urHwX","colab":{"base_uri":"https://localhost:8080/","height":545},"executionInfo":{"status":"ok","timestamp":1645399101977,"user_tz":-360,"elapsed":1284,"user":{"displayName":"Mimsadi Islam","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07228862094531790502"}},"outputId":"fcf538ce-26c9-44b7-b92e-2117582828c4"},"source":["import matplotlib.pyplot as plt\n","accuracy = history.history['accuracy']\n","loss = history.history['loss']\n","\n","epochs = range(len(accuracy))\n","\n","plt.plot(epochs, accuracy, 'b', label='Training accuracy')\n","plt.title('Training accuracy')\n","\n","plt.figure()\n","\n","plt.plot(epochs, loss, 'b', label='Training Loss')\n","plt.title('Training loss')\n","plt.legend()\n","\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAXAAAAEICAYAAABGaK+TAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxU9b3/8dcniwFZZIuILAJXBSkialDBVnGpV0VLW/X3wKoVbYtbxV1cauV3r7TUtle0rQtal7qgUpWqrdZd7MWKIKIgm7IZVIggYZE1+d4/vmecyUIyme3MSd7PxyOP+Z6TM+d8cpK85zvfs4w55xARkegpCLsAERFJjQJcRCSiFOAiIhGlABcRiSgFuIhIRCnARUQiSgEukWZmL5jZuZletok1DDez8kyvV6QxRWEXIC2PmW1KmNwd2AZUBdMXOOceTXZdzrmTsrGsSBQowCXnnHNtY20zWw781Dn3Su3lzKzIObczl7WJRImGUCRvxIYizGycmX0BPGBmHc3seTOrMLOvgnaPhOe8YWY/DdqjzexfZva7YNllZnZSisv2MbPpZrbRzF4xsz+Z2SNJ/hwHBNtab2bzzex7Cd872cw+Cta7ysyuDuZ3CX629Wa2zszeMjP9f0qD9Aci+WYvoBOwDzAG/zf6QDDdC9gC/LGB5x8OLAK6ALcCfzYzS2HZx4CZQGdgPHBOMsWbWTHwHPASsCdwKfComfULFvkzfpioHTAQeC2YfxVQDpQCXYEbAN3nQhqkAJd8Uw3c7Jzb5pzb4pxb65x7yjn3tXNuIzABOLqB569wzt3rnKsCHgK64QMx6WXNrBcwBPilc267c+5fwLNJ1n8E0BaYGDz3NeB54Mzg+zuAAWbW3jn3lXPuvYT53YB9nHM7nHNvOd2oSBqhAJd8U+Gc2xqbMLPdzeweM1thZhuA6UAHMyvcxfO/iDWcc18HzbZNXHZvYF3CPIBPk6x/b+BT51x1wrwVQPegfRpwMrDCzN40s6HB/N8CHwMvmdlSM7suye1JC6YAl3xTu9d5FdAPONw51x44Kpi/q2GRTPgc6GRmuyfM65nkcz8DetYav+4FrAJwzr3rnBuJH16ZBjwZzN/onLvKOdcX+B5wpZkdl+bPIc2cAlzyXTv8uPd6M+sE3JztDTrnVgCzgPFmtlvQSz41yae/A3wNXGtmxWY2PHju48G6zjKzPZxzO4AN+CEjzOwUM9s3GIOvxJ9WWV3/JkQ8Bbjku0lAa+BL4N/Aizna7lnAUGAtcAvwBP589QY557bjA/skfM13Aj92zi0MFjkHWB4MB10YbAdgP+AVYBPwNnCnc+71jP000iyZjpOINM7MngAWOuey/g5AJFnqgYvUw8yGmNl/mFmBmZ0IjMSPWYvkDV2JKVK/vYCn8eeBlwMXOefmhFuSSE0aQhERiSgNoYiIRFROh1C6dOnievfunctNiohE3uzZs790zpXWnp/TAO/duzezZs3K5SZFRCLPzFbUN19DKCIiEaUAFxGJKAW4iEhE6TxwkRZsx44dlJeXs3Xr1sYXlqxr1aoVPXr0oLi4OKnlFeAiLVh5eTnt2rWjd+/e7PpzLyQXnHOsXbuW8vJy+vTpk9RzNIQi0oJt3bqVzp07K7zzgJnRuXPnJr0bUoCLtHAK7/zR1N9FJAL84YfhnnvCrkJEJL9EIsCnTIH77gu7ChHJtLVr1zJ48GAGDx7MXnvtRffu3b+Z3r59e4PPnTVrFmPHjm10G8OGDctIrW+88QannHJKRtaVKZE4iGkGuueWSPPTuXNn3n//fQDGjx9P27Ztufrqq7/5/s6dOykqqj+mysrKKCsra3QbM2bMyEyxeSgSPXAFuEjLMXr0aC688EIOP/xwrr32WmbOnMnQoUM5+OCDGTZsGIsWLQJq9ojHjx/P+eefz/Dhw+nbty933HHHN+tr27btN8sPHz6c008/nf79+3PWWWcRuxvrP/7xD/r378+hhx7K2LFjm9TTnjJlCgceeCADBw5k3LhxAFRVVTF69GgGDhzIgQceyG233QbAHXfcwYABAxg0aBCjRo1Ke19FogdeUKAAF8m2yy+HoDOcMYMHw6RJTX9eeXk5M2bMoLCwkA0bNvDWW29RVFTEK6+8wg033MBTTz1V5zkLFy7k9ddfZ+PGjfTr14+LLrqozvnUc+bMYf78+ey9994ceeSR/O///i9lZWVccMEFTJ8+nT59+nDmmWcmXednn33GuHHjmD17Nh07duSEE05g2rRp9OzZk1WrVjFv3jwA1q9fD8DEiRNZtmwZJSUl38xLh3rgIpJ3zjjjDAoLCwGorKzkjDPOYODAgVxxxRXMnz+/3ueMGDGCkpISunTpwp577snq1avrLHPYYYfRo0cPCgoKGDx4MMuXL2fhwoX07dv3m3OvmxLg7777LsOHD6e0tJSioiLOOusspk+fTt++fVm6dCmXXnopL774Iu3btwdg0KBBnHXWWTzyyCO7HBpqikbXYGb3A6cAa5xzA4N5nfAf8tobWA78P+fcV2lXs8saoFqfzy2SVan0lLOlTZs237RvuukmjjnmGJ555hmWL1/O8OHD631OSUnJN+3CwkJ27tyZ0jKZ0LFjR+bOncs///lP7r77bp588knuv/9+/v73vzN9+nSee+45JkyYwIcffphWkCfTA38QOLHWvOuAV51z+wGvBtNZox64SMtVWVlJ9+7dAXjwwQczvv5+/fqxdOlSli9fDsATTzyR9HMPO+ww3nzzTb788kuqqqqYMmUKRx99NF9++SXV1dWcdtpp3HLLLbz33ntUV1fz6aefcswxx/Cb3/yGyspKNm3alFbtjUa/c266mfWuNXskMDxoPwS8AYxLq5IGKMBFWq5rr72Wc889l1tuuYURI0ZkfP2tW7fmzjvv5MQTT6RNmzYMGTJkl8u++uqr9OjR45vpqVOnMnHiRI455hicc4wYMYKRI0cyd+5czjvvPKqDoYNf//rXVFVVcfbZZ1NZWYlzjrFjx9KhQ4e0ak/qMzGDAH8+YQhlvXOuQ9A24KvYdD3PHQOMAejVq9ehK1bUe1/yBp12GixaBMHxABHJkAULFnDAAQeEXUboNm3aRNu2bXHOcckll7DffvtxxRVXhFJLfb8TM5vtnKtzzmTaBzGdfwXY5auAc26yc67MOVdWWlrnE4GSoh64iGTTvffey+DBg/nWt75FZWUlF1xwQdglJSXV0fPVZtbNOfe5mXUD1mSyqNoU4CKSTVdccUVoPe50pNoDfxY4N2ifC/wtM+XUT+eBi2RPMsOokhtN/V00GuBmNgV4G+hnZuVm9hNgIvBdM1sCHB9MZ4164CLZ0apVK9auXasQzwOx+4G3atUq6eckcxbKrs5qPy7praRJAS6SHT169KC8vJyKioqwSxHin8iTrEhcSq8AF8mO4uLipD/9RfJPZC6l15WYIiI1RSbA1QMXEalJAS4iElEKcBGRiFKAi4hEVCQCXBfyiIjUFYkAVw9cRKQuBbiISEQpwEVEIkoBLiISUZEJcF2JKSJSU2QCXD1wEZGaFOAiIhEViQDXeeAiInVFIsDVAxcRqUsBLiISUQpwEZGIUoCLiESUAlxEJKIiE+C6kEdEpKbIBLh64CIiNUUiwHUeuIhIXZEIcPXARUTqUoCLiESUAlxEJKIU4CIiEaUAFxGJKAW4iEhEKcBFRCIqrQA3syvMbL6ZzTOzKWbWKlOF1dyOrsQUEakt5QA3s+7AWKDMOTcQKARGZaqwRLqQR0SkrnSHUIqA1mZWBOwOfJZ+SXVpCEVEpK6UA9w5twr4HbAS+ByodM69VHs5MxtjZrPMbFZFRUVK21KAi4jUlc4QSkdgJNAH2BtoY2Zn117OOTfZOVfmnCsrLS1NcVupViki0nylM4RyPLDMOVfhnNsBPA0My0xZNcUCXL1wEZG4dAJ8JXCEme1uZgYcByzITFk1KcBFROpKZwz8HeCvwHvAh8G6JmeorhoU4CIidRWl82Tn3M3AzRmqZZcU4CIidUXiSszCQv9YVRVuHSIi+SQSAV5c7B937Ai3DhGRfBKJAC8KBnp27gy3DhGRfBKJAFcPXESkLgW4iEhERSLAY0MoCnARkbhIBHisB64xcBGRuEgEuHrgIiJ1RSLANQYuIlJXpAJcQygiInGRCHANoYiI1BWJANcQiohIXZEK8O3bw61DRCSfRCLA27b1j5s3h1uHiEg+iUSAt2/vHzdsCLcOEZF8EokAb9fOP27cGG4dIiL5JBIBrh64iEhdkQjwNm38p/KoBy4iEheJADeDDh1g7dqwKxERyR+RCHCA7t1h1aqwqxARyR+RCfCePeHTT8OuQkQkf0QmwHv0UICLiCSKTID37QsVFVBZGXYlIiL5ITIB3q2bf5w0Kdw6RETyRWQC/NRT/eOECeHWISKSLyIT4J06+UfdkVBExItMgCfS+eAiIhEL8J49/ePUqeHWISKSDyIV4B9+6B91JoqISMQCfI89/ON114Vbh4hIPkgrwM2sg5n91cwWmtkCMxuaqcJERKRh6fbAbwdedM71Bw4CFqRfUsPGj/ePuipTRFq6olSfaGZ7AEcBowGcc9uBrH9q5YAB/rFXL3Au21sTEclf6fTA+wAVwANmNsfM7jOzNhmqa5cGDYq39QEPItKSpRPgRcAhwF3OuYOBzUCdw4tmNsbMZpnZrIqKijQ25/XrF2/ffHPaqxMRiax0ArwcKHfOvRNM/xUf6DU45yY758qcc2WlpaVpbC5uQTDS/uWXGVmdiEgkpRzgzrkvgE/NLNYnPg74KCNVNaJ/f//4yCPw8su52KKISP5J9yyUS4FHzewDYDDwq/RLapoTToDLL1dvXERanpTPQgFwzr0PlGWolibZuROKgupvvx3WrIHHHgujEhGRcETqSsxEhYU1p/WJ9SLS0kQ2wAFmzIi3t24Nrw4RkTBEOsCHJly4/8or4dUhIhKGSAc4wJgxYVcgIhKOyAf4PffE26+9Fl4dIiK5FvkAT/S3v4VdgYhI7jSLAH/0Uf94xx3h1iEikkvNIsDPPDPeXrcuvDpERHKpWQS4Wbx9//3h1SEikkvNIsABjjvOP15zDWTgpociInmv2QT4c8/F29Onh1eHiEiuNJsAb9063t68Obw6RERyJa2bWeWrf//bPw4aBIMHh1uLiEi2NKsAX7cOOnWCu+7yX6DPzRSR5qvZDKEAdOwYdgUiIrnTrAIc/KfVi4i0BM0uwKdMCbsCEZHcaHYBPmxY2BWIiORGswtwgCFDwq5ARCT7mmWAjx4db993X2hliIhkVbMM8AsvjLd/9rPw6hARyaZmGeAFBbqplYg0f80ywAHOOy/eXrw4vDpERLKl2QZ4on799GEPItL8NOsA/+KLePuyy+Cdd8KrRUQk05p1gHftWnP6iCPCqUNEJBuadYADrF4ddgUiItnR7AN8zz1r9sR/8YvwahERyaRmH+AATz4Zb0+YoFvMikjz0CIC/Kijaob4kiXh1SIikilpB7iZFZrZHDN7PhMFZcvpp8fb/frB+efDBx+EV4+ISLoy0QO/DFiQgfVklRncemt8+oEH4KCDwqtHRCRdaQW4mfUARgCRuGXUUUeFXYGISOak2wOfBFwLVGeglqw7/HB4882a86qqwqlFRCRdKQe4mZ0CrHHOzW5kuTFmNsvMZlVUVKS6uYyp3Qv/+c/DqUNEJF3p9MCPBL5nZsuBx4FjzeyR2gs55yY758qcc2WlpaVpbC5z3n8/3r777vDqEBFJR8oB7py73jnXwznXGxgFvOacOztjlWXRQQfBqafGp7dtC68WEZFUtYjzwOtzzjnx9rp14dUhIpKqjAS4c+4N59wpmVhXrvzwh/H2Cy+EV4eISKpabA+8sBCGDvXtn/yk7tkpIiL5rsUGOMATT8Tbw4eHVoaISEpadID37FlzujoSZ7OLiHgtOsABHn443i4s9Jfci4hEQYsP8LMjceKjiEhdLT7AAcrLa07rfuEiEgUKcKB795rT27eHU4eISFMowANLl8bbX3zhx8ITz1IREck3CvBAnz7x9k03+ccJE8KpRUQkGQrwBOed5x8Tz0wREclXCvAEf/pT2BWIiCRPAZ6gdeua0zobRUTymQK8lssvj7d37gyvDhGRxijAa/n97+PthQvDq0NEpDEK8FoKau0R3R9FRPKVArweM2bE29ddF14dIiINUYDXY+hQOPlk3/7tb8OtRURkVxTguzBxYrw9YEB4dYiI7IoCfBcOPDDeXrAgvDpERHZFAd6AuXPj7VdfDa8OEZH6KMAbkNgLP/54+PnPw6tFRKQ2BXgDzODoo+PTutReRPKJArwRkyfXnP7kk3DqEBGpTQHeiP33h3ffjU/vu294tYiIJFKAJ6GsDG68MT59yCG6QlNEwqcAT9L48fH2nDnQtm1opYiIAArwpBUVwfTp8ektW8KrRUQEFOBN8p3v1JzW7WZFJEwK8DQUF8O2bWFXISItlQK8ibZvrzndqlU4dYiIKMCbqLgY1qwJuwoRkTQC3Mx6mtnrZvaRmc03s8syWVg+Ky2tOT1qlA5qikjupdMD3wlc5ZwbABwBXGJmLebGq4m98CeegBdf9Gep6MCmiORKygHunPvcOfde0N4ILAC6Z6qwfFdaCvfdF59+8UV/35SbbgqvJhFpWcw5l/5KzHoD04GBzrkNtb43BhgD0KtXr0NXrFiR9vbyxZYtsPvuNecVFEBVVTj1iEjzZGaznXNlteenfRDTzNoCTwGX1w5vAOfcZOdcmXOurLT24HHEtW4NlZU15+kSexHJlbQC3MyK8eH9qHPu6cyUFC3t28O4cTXnVVXBRx/V/EAIEZFMS3kIxcwMeAhY55y7PJnnlJWVuVmzZqW0vXy2bduuzwfPwAiViLRw2RhCORI4BzjWzN4Pvk5OY32RVVIC5eX67EwRya2iVJ/onPsXYBmsJdK6d6+/tz1/PvTs6YdaREQySVdiZpDV83I2cCAcdljuaxGR5k8BnmHV1TBlSs15ixaFU4uING8K8Awzg+9/v+78hQtzX4uING8K8Cxo1aruePgBB8Bee8GOHeHUJCLNjwI8i2oPpaxeDffcE04tItL8KMCzaNQo3xPff//4vEsv9cMsuumViKRLAZ4D771Xd95tt9W9DF9EpCkU4DnQpo3viSeeTnjttTBkSHg1iUj0KcBz6O23Yd68+PSSJf4+KjqwKSKpUIDnUEEBDKj1kRe33gq77RZOPSISbQrwHDPzwynTptWcf++9uvGViDSNAjwkI0f6wB471k+PGeN76P/4h5/+/e/h5ZfDq09E8l9GPpEnWc31drLpqu8eKjHqlYtI1j6RR9KX2BOv7auvcluLiESHAjxP3H67vxFW7c/Y7NTJ99AvvRSuuQbuuiuc+kQk/yjA84gZbN4Ma9fCs8/W/N4f/wi/+x1cfDFs3BhOfalYudKP72/bFnYlEiV33w2vvhp2FflPAZ6HOnWCU0/1n635i1/U/X779v4TgIYNg8su8+1EFRX58+HKl17qz7B5/fWwK8mNdevgBz/w971JlXNw+eUwe3bm6oqaiy6C448Pu4rkPPYYFBbC1q2537YCPI8VFMB//7f/wzjmmJoh2LOnvzDojjt8O+Zf/4I99/R/ULfc0vRt/uhH8LOfpV97TOyzQteuTW75igpYsya9bc6dm/rB35NOgr59U9/2Aw/4U0R/9avU17FunR9SGz489XUkqqqCgw7K7PDbo49m7xbJUXu3Nm6c7zB9+mnut60Aj4CSEnjtNf8PvaurNs3813e+E593001N74lPmQL33Qfbt9f//T/8wW8n2X+y0lL/+OWXyS1/4IHQtWtyy9ZnxgwYPNjXmYoXX4Rly1J/AWjd2j9+/XVqz4f4i92mTamvI9GaNfDBB374LRO2b4ezz/a3SM6GdPbdrrz9Nixfnvn1ArRr5x/TedeVKgV4xBQV+XCprPT/mF980fDy550Hn3wCGzbEQ96s/rfniaH15JP1ry92tsxLLyVXb9u2/vGzzxpfdseO+D9BqkNAH33kH2Pn0zdF4ovS+vWpbT9Wdzrhm+yLXbJWrcrs+taty+z6asv0UIRzfrixT5/Mrjcm9jeuAJektW/ve7ddu/pTDd9+2wfzo4/6P9jYx7j95S+w776wxx41n19W5pdPDNbE0Ksv4Jcti7dnzEiuzlhPPpm3l+++G28vXZrc+mtbvNg/fv5505+7YUO8nfizNkXstM90DjRnOsBrHyNJV2KAJzs01hRbtsTbmbjtcqovxsmKBXhjnalsUIA3Ax06wBFH+N7fj37k5+2/P7zwQt1lH3645nT37vFe+SmnxOdPmuRDcNq0+FWjiWPTEyc23kuurobJk307mUC88sp4O9UhkFgPfN68pveCE8Mo3QBP5585Wz3w4uLMrC8T+6khiQGeiReIior019GQ2LCZeuCSUSee6IM38evss32wbt4cH59OdMYZ/l7lAHvv7c+oePZZf0D1iCP8/N6944/Llvl/srlzYf58/8/32Wfw0EP+AObmzX7Zd99tvFfavn28/fzzqf3MCxb49VRXw8yZTXtuYhilGkyxwFm6NPVx9MTQSgyzVMUCfMeOzIwvJwZiqu+UGpI4hJKJ8E3seGTjFNxYvWEEeFHuNylhM/MXDDV0tkd1NVx1Vf3fW7DA9zo+/bTxMzaKimDqVP9CEAvoiy7yz+vQwf+D7rOP73W+/DKcf75fbtIk35vt2DFeT+ydAsCf/ww//Smcey48+KCft3Sp/7r4YrjzTj/Mc+yxSe+Wb3rvAM88A1dfnfxzY1au9I9ffeX3byoHZBMPti1a5A/KpiNxDPyDD+IvxKlKHJLJdg98xQoYODC99SW+CMyfn/7PX1usk5LpYw3JUIBLva68suaQhnP+dLSi4C+mutoP0Uyd6oMyNvYMcMIJ/ha5J53kw7SqyvfgY0MuDZ3ONnq0D+lJk/z58I156CH/NWBAPIB//GP/ruGmm/wwyqZN8Z7nkCG+3aGDPy7Qpo0PoUWL/IHbQw7x464zZvjho/79/YtVSYn/OTp08D/bxo2+zg0bfGivXg2DBsGHH/oXpBUr4J//hHPOafheN7Xt2AFvvOHHVTdt8u9c0g3wlSv9UNmqVf7TodINsJUr/burNm2y0wNPHPqaOxdGjEhvfdkO8NjxlrlzM7veZOhmVpIza9fCU0/5MOzYEebMgcMP9+etb93qQ+GQQ/yy48f7oB882Pf4YwdBu3aNv1W94QYfcIl3bbz+en8O9jPPwA9/2LT6evTwF2UUFfmzFlL14IO+hsWL/QvX/vv78F+yBA4+2I9Fb9zof66ePeM/W+/e8d73H/7gPwB75Ur49rd9WG7f7vdVSYkP+tiwWHV1/B1KUZG/BmDLFv8uYMYMH2DXXAOPP+7rGTHCv0D06OHD0syvP3ag++uv/TrM/DanTfP7srDQ/w6vv95/ulRxsa99wgT/jq6oyK931Sr/++3Qwf9eYy92u+/un1NZ6UMv9qK7227QrZvfbteufnv/8z++1oMO8vuhTRu//Vhvt2dPv87qav+Cu3Wr33ZxsX9eVZWvdccO+OUv/Qv6Hnv4F+QpU/ypf61a+ZoLCvzPWVAQ358lJfFbP1dXxzswX38dH6LbscP//P37x19wFy/2Jw005UU7Gbu6mZUCXJqtbdv8P/eWLf4ff8GC+Pj95s0+EL7+Ot7T33ff+DuMFSt8UG3f7gPou9/1//CVlf5c8YMOgi5dfFDNnOl74sOG+d73mWf6F5n/+i8foP36+cBatswfV2jXzgdEZSV8/LFf9vDDfUC0b+/P5b/5Zl/v+PH+gpmKCh8iZr7mkhIfOAUFfl5VlQ+vnTt9sGze7EOtdWt/xtG0afDWW/5nWrAg/X37xht+3/zgB/FQzaSjjvJDZD/+cWbWN3q073lffPGuD77H9p9z/m+jqir59U+d6muNDf+0a+dfmAoL/Xq3bPHvfvbZJ7X6FeAiAvhgWrfOB3BRkQ+Ybdv8C0pRke/txoKsoMAHdHW172Xu3OlDqCA4/WHrVv+CEBuqatXKh9Vuu8XfIcQOlm/eHF9vq1a+hmnT/MVb3bpBr17+uMEee8CRR/rwW7LED3usX+/rXLzYv0sZMiRe31df+W3EwrO62v88Xbr4dt++/iK44mIfoi+95Ot47TU49FD/zqCqys/bbbf4wfdY7zz2AllU5IfI+vf3L6DFxf5rv/38GVwzZ8LTT/tTcPfdN/4CUFXl13vjjf5dTyoU4CIiEaX7gYuINDNpBbiZnWhmi8zsYzO7LlNFiYhI41IOcDMrBP4EnAQMAM40swENP0tERDIlnR74YcDHzrmlzrntwOPAyMyUJSIijUknwLsDibcoKg/m1WBmY8xslpnNqsj2TQlERFqQrB/EdM5Nds6VOefKSuu7+YaIiKQknQBfBSR8Fgw9gnkiIpID6QT4u8B+ZtbHzHYDRgHPNvIcERHJkLQu5DGzk4FJQCFwv3NuQiPLVwArUtxcFyDDd0rOCNXVNKqraVRX0zTXuvZxztUZg87plZjpMLNZ9V2JFDbV1TSqq2lUV9O0tLp0JaaISEQpwEVEIipKAT457AJ2QXU1jepqGtXVNC2qrsiMgYuISE1R6oGLiEgCBbiISERFIsDDvG2tmS03sw/N7H0zmxXM62RmL5vZkuCxYzDfzOyOoM4PzOyQDNdyv5mtMbN5CfOaXIuZnRssv8TMzs1SXePNbFWw394PrhmIfe/6oK5FZvafCfMz9ns2s55m9rqZfWRm883ssmB+qPurgbpC3V/B+lqZ2UwzmxvU9v+D+X3M7J1gO08EF+5hZiXB9MfB93s3VnOG63rQzJYl7LPBwfxc/u0XmtkcM3s+mM7tvnLO5fUX/iKhT4C+wG7AXGBADre/HOhSa96twHVB+zrgN0H7ZOAFwIAjgHcyXMtRwCHAvFRrAToBS4PHjkG7YxbqGg9cXc+yA4LfYQnQJ/jdFmb69wx0Aw4J2u2AxcG2Q91fDdQV6v4KtmVA26BdDLwT7IsngVHB/LuBi4L2xcDdQXsU8ERDNWehrgeB0+tZPpd/+1cCjwHPB9M53VdR6IHn421rRwIPBe2HgKOIjukAAANRSURBVO8nzP+L8/4NdDCzbpnaqHNuOrAuzVr+E3jZObfOOfcV8DJwYhbq2pWRwOPOuW3OuWXAx/jfcUZ/z865z51z7wXtjcAC/N0yQ91fDdS1KznZX0E9zjm3KZgsDr4ccCzw12B+7X0W25d/BY4zM2ug5kzXtSs5+V2aWQ9gBHBfMG3keF9FIcCTum1tFjngJTObbWZjgnldnXOfB+0vgK5BO4xam1pLLmv8efAW9v7YUEUYdQVvVw/G99zyZn/VqgvyYH8FQwLvA2vwAfcJsN45t7Oe7XxTQ/D9SqBzNmqrXZdzLrbPJgT77DYzK6ldV63tZ7quScC1QOxz7juT430VhQAP27edc4fgP3noEjM7KvGbzr8PyotzMfOpFuAu4D+AwcDnwO/DKMLM2gJPAZc75zYkfi/M/VVPXXmxv5xzVc65wfi7ix4G9A+jjtpq12VmA4Hr8fUNwQ+LjMtVPWZ2CrDGOTc7V9usTxQCPNTb1jrnVgWPa4Bn8H/Uq2NDI8HjmhBrbWotOanRObc6+KerBu4l/rYwZ3WZWTE+JB91zj0dzA59f9VXVz7sr0TOufXA68BQ/BBEUT3b+aaG4Pt7AGuzWVtCXScGw1HOObcNeIDc7rMjge+Z2XL88NWxwO3kel+lM4Cfiy+gCH+woQ/xgzXfytG22wDtEtoz8GNmv6XmgbBbg/YIah48mZmFmnpT82Bhk2rB91SW4Q/idAzanbJQV7eE9hX4cT6Ab1HzoM1S/AG5jP6eg5/7L8CkWvND3V8N1BXq/gq2VQp0CNqtgbeAU4Cp1Dwwd3HQvoSaB+aebKjmLNTVLWGfTgImhvS3P5z4Qcyc7quMhku2vvBHlRfjx+NuzOF2+wY7dy4wP7Zt/NjVq8AS4JXYH0HwB/OnoM4PgbIM1zMF//Z6B36s7Cep1AKcjz9Y8jFwXpbqejjY7gf4+8QnBtSNQV2LgJOy8XsGvo0fHvkAeD/4Ojns/dVAXaHur2B9g4A5QQ3zgF8m/B/MDH7+qUBJML9VMP1x8P2+jdWc4bpeC/bZPOAR4meq5OxvP1jncOIBntN9pUvpRUQiKgpj4CIiUg8FuIhIRCnARUQiSgEuIhJRCnARkYhSgIuIRJQCXEQkov4POfR3PP2zJtkAAAAASUVORK5CYII=\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"U_vp2gIKBPll"},"source":["# Output the Lyrics "]},{"cell_type":"code","metadata":{"id":"FJk29hBMsIiw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1645399138813,"user_tz":-360,"elapsed":11910,"user":{"displayName":"Mimsadi Islam","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07228862094531790502"}},"outputId":"1f24abcb-cfd2-41a4-d2d3-434f23655b4f"},"source":["#model_3.load_weights('/content/drive/My Drive/Colab Notebooks/R_T/best_model_3.hdf5')\n","model_3.load_weights('/content/best_model_3.hdf5')\n","model2.load_weights('/content/best_next_line_model.hdf5')\n","#model2.load_weights('/content/drive/My Drive/Colab Notebooks/R_T/best_next_line_model.hdf5')\n","seed_text = \"   \"\n","#count=0\n","\n","#prv_last=\"\"\n","first_word_seed_text=\"\"\n","lines = 10\n","i=0\n","prediction_probabilities = []\n","while i < lines :\n","    if first_word_seed_text == \"\":\n","\n","        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n","        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n","        predicted = model_3.predict(token_list, verbose=0)\n","    else:\n","        token_list = tokenizer.texts_to_sequences([first_word_seed_text])[0]\n","        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n","        predicted = model_3.predict(token_list, verbose=0)\n","        first_word_seed_text = \"\"\n","    predicted_class = np.argmax(predicted)\n","    prediction_probabilities.append(predicted[0][predicted_class])\n","    output_word = \"\"\n","    for word, index in tokenizer.word_index.items():\n","        if index == predicted_class:\n","            output_word = word\n","            break\n","\n","    if seed_text.find(output_word) == -1:\n","        seed_text += output_word + \" \"\n","    else:\n","        predicted_class = np.argsort(predicted)[0][-2]\n","    \n","        for word, index in tokenizer.word_index.items():\n","            if index == predicted_class:         \n","                output_word = word\n","                break\n","        \n","\n","        seed_text +=  output_word + \" \"\n","\n","    next_line_seed_text = seed_text.split('\\n')[-1]\n","    if next_line_seed_text == \"\":\n","        next_line_seed_text = seed_text\n","    char_token_list = char_tokenizer.texts_to_sequences([next_line_seed_text])\n","    char_token_list = np.array(pad_sequences(char_token_list, maxlen=max_seq_length, padding='post'))\n","    predicted_next_line = model2.predict(char_token_list, verbose=0)[0][0]\n","    if predicted_next_line >= 0.5:\n","        seed_text += \"\\n\"\n","        i += 1\n","        first_word_seed_text = next_line_seed_text\n","    \n","\n","    \n","\n","\t\t\n","print(seed_text)\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["      \n","           \n","      \n","            \n","        \n","        \n","        \n","       \n","       \n","                 \n","\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","col_list = [\"Starting\", \"Self -BLEU(GPT-2)\",\"SELF_BLEU(LSTM)\"]\n","df = pd.read_csv(\"/content/drive/MyDrive/ML Project/result - Sheet1.csv\", usecols=col_list)\n","\n","print(df[\"Starting\"][1])\n","print(len(df[\"Starting\"]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cXSum7AJdGsu","executionInfo":{"status":"ok","timestamp":1645399609092,"user_tz":-360,"elapsed":401,"user":{"displayName":"Mimsadi Islam","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07228862094531790502"}},"outputId":"9939c912-be7a-44e3-daec-a2f9d507e9bd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":[" \n","50\n"]}]},{"cell_type":"code","metadata":{"id":"-fkzEN-KydlM"},"source":["#####all songs together#####\n","#model_3.load_weights('/content/drive/My Drive/Colab Notebooks/R_T/best_model_3.hdf5')\n","model_3.load_weights('/content/best_model_3.hdf5')\n","model2.load_weights('/content/best_next_line_model.hdf5')\n","#model2.load_weights('/content/drive/My Drive/Colab Notebooks/R_T/best_next_line_model.hdf5')\n","col_list = [\"Starting\", \"Self -BLEU(GPT-2)\",\"SELF_BLEU(LSTM)\"]\n","df = pd.read_csv(\"/content/drive/MyDrive/ML Project/result - Sheet1.csv\", usecols=col_list)\n","\n","#print(df[\"Starting\"])\n","for j in range(len(df[\"Starting\"])):\n","    seed_text = df[\"Starting\"][j]\n","#count=0\n","\n","#prv_last=\"\"\n","    first_word_seed_text=\"\"\n","    lines = 10\n","    i=0\n","    prediction_probabilities = []\n","    while i < lines :\n","        if first_word_seed_text == \"\":\n","\n","            token_list = tokenizer.texts_to_sequences([seed_text])[0]\n","            token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n","            predicted = model_3.predict(token_list, verbose=0)\n","        else:\n","            token_list = tokenizer.texts_to_sequences([first_word_seed_text])[0]\n","            token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n","            predicted = model_3.predict(token_list, verbose=0)\n","            first_word_seed_text = \"\"\n","        predicted_class = np.argmax(predicted)\n","        prediction_probabilities.append(predicted[0][predicted_class])\n","        output_word = \"\"\n","        for word, index in tokenizer.word_index.items():\n","            if index == predicted_class:\n","                output_word = word\n","                break\n","\n","        if seed_text.find(output_word) == -1:\n","            seed_text += output_word + \" \"\n","        else:\n","            predicted_class = np.argsort(predicted)[0][-2]\n","           \n","            for word, index in tokenizer.word_index.items():\n","                if index == predicted_class:         \n","                    output_word = word\n","                    break\n","        \n","\n","            seed_text +=  output_word + \" \"\n","\n","        next_line_seed_text = seed_text.split('\\n')[-1]\n","        if next_line_seed_text == \"\":\n","            next_line_seed_text = seed_text\n","        char_token_list = char_tokenizer.texts_to_sequences([next_line_seed_text])\n","        char_token_list = np.array(pad_sequences(char_token_list, maxlen=max_seq_length, padding='post'))\n","        predicted_next_line = model2.predict(char_token_list, verbose=0)[0][0]\n","        if predicted_next_line >= 0.5:\n","            seed_text += \"\\n\"\n","            i += 1\n","            first_word_seed_text = next_line_seed_text\n","    \n","\n","    \n","\n","    path = \"/content/drive/MyDrive/ML Project/LSTM_outputs/song\" + str(j) + \".txt\"\n","    f = open(path, \"w\")\n","    f.writelines(seed_text)\n","    f.close()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"CtX1aYcBfRGQ"},"execution_count":null,"outputs":[]}]}