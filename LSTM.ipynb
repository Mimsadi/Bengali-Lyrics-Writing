{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"LSTM.ipynb","provenance":[{"file_id":"18P1aaNBYg4UQcsENLbc2tI1xOFWH2nPa","timestamp":1643541938481},{"file_id":"https://github.com/saif14/MyProject/blob/master/artcellSongCreate.ipynb","timestamp":1592280166701}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"wYJd1ELv1jzB"},"source":["# Mounting the drive"]},{"cell_type":"code","metadata":{"id":"_fQmHDDKNLC1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1645394016186,"user_tz":-360,"elapsed":17056,"user":{"displayName":"Mimsadi Islam","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07228862094531790502"}},"outputId":"9d7161c2-00bc-4a0b-d502-c33845a9fb9a"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","metadata":{"id":"kRkcw_7uGxnM"},"source":["# Reading the data for Rabindra sangeet"]},{"cell_type":"code","metadata":{"id":"HU-TtHLnVD3t"},"source":["with open('/content/drive/MyDrive/ML Project/Bengali Lyrics/R_T_lyrics.txt') as f:\n","    data=f.read()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pDzp5j1K11Y_"},"source":["# Fetching the weight file from Drive"]},{"cell_type":"code","metadata":{"id":"OMrbz9zfk-9-","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1645394030118,"user_tz":-360,"elapsed":384,"user":{"displayName":"Mimsadi Islam","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07228862094531790502"}},"outputId":"c0a2a577-0295-4cf0-fb1f-7b28fea45b59"},"source":["import shutil\n","\n","shutil.copyfile('/content/drive/MyDrive/ML Project/LSTM_weights/best_86.hdf5' , 'best.hdf5')"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'best.hdf5'"]},"metadata":{},"execution_count":3}]},{"cell_type":"markdown","metadata":{"id":"tvA0f_OU18UI"},"source":["# Importing necessary Libraries"]},{"cell_type":"code","metadata":{"id":"57mJSXENntXN"},"source":["from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional,Conv1D, GlobalMaxPooling1D , MaxPooling1D ,BatchNormalization\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.models import Sequential\n","#from keras.layers import BatchNormalization\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras import regularizers\n","import tensorflow.keras.utils as ku \n","import numpy as np \n","import tensorflow as tf\n","#from imblearn.keras import balanced_batch_generator\n","#from imblearn.keras import BalancedBatchGenerator\n","from imblearn.under_sampling import NearMiss\n","#from balanced_batch_generator import balanced_batch_generator\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","import tensorflow.keras.backend as K\n","#from sklearn.utils import class_weight\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DI04P6X52AK_"},"source":["# Defining the DATA"]},{"cell_type":"code","metadata":{"id":"CjTbOMgJpJLs"},"source":["print(data)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hcqJoNjG2Gp4"},"source":["# Creating the word index using Tokenizer"]},{"cell_type":"code","metadata":{"id":"afAhI_Caqj1l","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1645394155759,"user_tz":-360,"elapsed":386,"user":{"displayName":"Mimsadi Islam","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07228862094531790502"}},"outputId":"a804c4ab-a672-4f77-f1ab-e13733c68003"},"source":["l_end = []\n","l_start = []\n","tokenizer = Tokenizer()\n","corpus = data.split(\"\\n\")\n","tokenizer.fit_on_texts(corpus) \n","total_words = len(tokenizer.word_index) + 1\n","\n","\n","input_sequences = []\n","for line in corpus:\n","\tword=line.split()\n","\tif len(word)!= 0 :\n","  \t\tl_end.append(word[-1])\n","  \t\tl_start.append(word[0])\n","\n","\ttoken_list = tokenizer.texts_to_sequences([line])[0] \n","\n","\tfor i in range(1, len(token_list)):\n","\t\tn_gram_sequence = token_list[:i+1]\n","\n","\t\tinput_sequences.append(n_gram_sequence)\n","max_sequence_len = max([len(x) for x in input_sequences])\n","\n","input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre')) \n","\n","predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n","print(predictors.shape)\n","\n","classes_instance= np.bincount(label)\n","num_classes = len(classes_instance)\n","\n","\n","\n","label = ku.to_categorical(label, num_classes=num_classes)\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(7726, 12)\n"]}]},{"cell_type":"code","metadata":{"id":"NyCWjyFAyXls"},"source":["word_index = tokenizer.word_index\n","word_index\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LVd3hxPt2zFu"},"source":["# Modifying the Tokenizer to reduce number of calsses and pre-process the data to fit in Model"]},{"cell_type":"markdown","metadata":{"id":"eUF5OA1qX2pT"},"source":["#Comute class weights for next line model"]},{"cell_type":"code","metadata":{"id":"RLt1EritX2xS"},"source":["def compute_weight(Y, classes):\n","    Y = np.asarray(Y)\n","    num_samples = len(Y)\n","    n_classes = len(classes)\n","    Y = Y.astype(int)\n","    Y = np.expand_dims(Y, axis=1)\n","    num_bin = np.bincount(Y[:, 0])\n","    class_weights={}\n","    for i in range(n_classes):\n","        if num_bin[i]!=0:\n","            class_weights[i]=(num_samples / (n_classes * num_bin[i]))\n","        else:\n","            class_weights[i]=1 \n","    return class_weights"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KG_zIF-P7Rsm"},"source":["# Preparing data for the next line model"]},{"cell_type":"code","metadata":{"id":"n16j9anr7Vz-"},"source":["text=[]\n","\n","for each_line in data.split('\\n'):\n","    each_line = each_line+'\\n'\n","    text.append(each_line)\n","\n","while True:\n","    try:\n","        text.remove('\\n')\n","    except:\n","        break\n","\n","\n","char_tokenizer = Tokenizer(char_level=True,oov_token=\"UNK\")\n","char_tokenizer.fit_on_texts(text)\n","\n","next_line_token = char_tokenizer.word_index['\\n']\n","total_character = len(char_tokenizer.word_index.keys())\n","\n","sequences = char_tokenizer.texts_to_sequences(text)\n","\n","X=[]\n","Y=[]\n","for each_sequence in sequences:\n","    for i in range(1,len(each_sequence)):\n","        if each_sequence[i]!=next_line_token and each_sequence[i+1]!=next_line_token:\n","            X.append(each_sequence[:i+1])\n","            Y.append(0)\n","        else:\n","            X.append(each_sequence[:i+1])\n","            Y.append(1)\n","            break\n","max_seq_length = max([len(i) for i in X])\n","\n","X = np.array(pad_sequences(X, maxlen=max_seq_length, padding='post'))\n","\n","Y = np.asarray(Y)\n","class_weight = compute_weight(Y, [0,1])\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SBUbYwEYP3Y8"},"source":["# Next Word Model"]},{"cell_type":"code","metadata":{"id":"TfOrUFYVGccX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1645394181743,"user_tz":-360,"elapsed":5138,"user":{"displayName":"Mimsadi Islam","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07228862094531790502"}},"outputId":"791ade4a-0e1d-4014-a82d-eb7792b0bbf9"},"source":["\n","tf.random.set_seed(10)\n","\n","model_3 = Sequential()\n","model_3.add(Embedding(total_words, 120, input_length=max_sequence_len-1))\n","model_3.add(Bidirectional(LSTM(170, return_sequences = True)))\n","\n","model_3.add(Conv1D(filters=64, kernel_size=3,padding='valid'))\n","model_3.add(BatchNormalization())\n","model_3.add(MaxPooling1D(pool_size=2))\n","model_3.add(Dropout(0.2))\n","model_3.add(LSTM(150,return_sequences=True))\n","model_3.add(LSTM(150))\n","\n","model_3.add(Dense(total_words/2, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n","model_3.add(Dense(num_classes, activation='softmax'))\n","adam = Adam(learning_rate=0.001)\n","\n","model_3.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n","print(model_3.summary())"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding (Embedding)       (None, 12, 120)           404880    \n","                                                                 \n"," bidirectional (Bidirectiona  (None, 12, 340)          395760    \n"," l)                                                              \n","                                                                 \n"," conv1d (Conv1D)             (None, 10, 64)            65344     \n","                                                                 \n"," batch_normalization (BatchN  (None, 10, 64)           256       \n"," ormalization)                                                   \n","                                                                 \n"," max_pooling1d (MaxPooling1D  (None, 5, 64)            0         \n"," )                                                               \n","                                                                 \n"," dropout (Dropout)           (None, 5, 64)             0         \n","                                                                 \n"," lstm_1 (LSTM)               (None, 5, 150)            129000    \n","                                                                 \n"," lstm_2 (LSTM)               (None, 150)               180600    \n","                                                                 \n"," dense (Dense)               (None, 1687)              254737    \n","                                                                 \n"," dense_1 (Dense)             (None, 3374)              5695312   \n","                                                                 \n","=================================================================\n","Total params: 7,125,889\n","Trainable params: 7,125,761\n","Non-trainable params: 128\n","_________________________________________________________________\n","None\n"]}]},{"cell_type":"markdown","metadata":{"id":"MNVGZdv25bub"},"source":["# 2nd model to predict next line in the lyrics"]},{"cell_type":"code","metadata":{"id":"MZ_NgfvG4YCQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1645394191366,"user_tz":-360,"elapsed":529,"user":{"displayName":"Mimsadi Islam","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07228862094531790502"}},"outputId":"c2b46e61-8598-4f35-ab5a-30cd198f1aac"},"source":["model2 = Sequential()\n","model2.add(Embedding(total_character+1, 120, input_length=max_seq_length))\n","model2.add(Conv1D(filters=64, kernel_size=3,padding='valid'))\n","model2.add(GlobalMaxPooling1D())\n","model2.add(Dense(10, activation='relu'))\n","model2.add(Dense(1, activation='sigmoid'))\n","model2.compile(optimizer='adam',\n","              loss='binary_crossentropy',\n","              metrics=['accuracy'])\n","print(model2.summary())"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding_1 (Embedding)     (None, 64, 120)           9480      \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 62, 64)            23104     \n","                                                                 \n"," global_max_pooling1d (Globa  (None, 64)               0         \n"," lMaxPooling1D)                                                  \n","                                                                 \n"," dense_2 (Dense)             (None, 10)                650       \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 11        \n","                                                                 \n","=================================================================\n","Total params: 33,245\n","Trainable params: 33,245\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n"]}]},{"cell_type":"markdown","metadata":{"id":"OxBO8xsejYug"},"source":["# Training Next line model"]},{"cell_type":"code","metadata":{"id":"W8FveZb4Abu7","colab":{"base_uri":"https://localhost:8080/"},"outputId":"d4db6444-4836-4752-b637-4f5ec39139e9","executionInfo":{"status":"ok","timestamp":1645397067445,"user_tz":-360,"elapsed":2871279,"user":{"displayName":"Mimsadi Islam","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07228862094531790502"}}},"source":["\n","K.set_value(model2.optimizer.learning_rate, 0.001)\n","\n","\n","\n","\n","filepath = \"best_next_line_model.hdf5\"\n","model_checkpoint = ModelCheckpoint(filepath, monitor=\"accuracy\", save_best_only=True, verbose=1)\n","history = model2.fit(X, Y, batch_size=128, epochs=1000 , verbose=1, callbacks=[model_checkpoint], class_weight=class_weight)\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.4255 - accuracy: 0.7726\n","Epoch 1: accuracy improved from -inf to 0.77261, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 13s 6ms/step - loss: 0.4255 - accuracy: 0.7726\n","Epoch 2/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.2879 - accuracy: 0.8776\n","Epoch 2: accuracy improved from 0.77261 to 0.87813, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 2s 6ms/step - loss: 0.2876 - accuracy: 0.8781\n","Epoch 3/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.2543 - accuracy: 0.8871\n","Epoch 3: accuracy improved from 0.87813 to 0.88710, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 2s 6ms/step - loss: 0.2543 - accuracy: 0.8871\n","Epoch 4/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.2349 - accuracy: 0.8998\n","Epoch 4: accuracy improved from 0.88710 to 0.89947, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 2s 6ms/step - loss: 0.2361 - accuracy: 0.8995\n","Epoch 5/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.2209 - accuracy: 0.9039\n","Epoch 5: accuracy improved from 0.89947 to 0.90412, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 2s 6ms/step - loss: 0.2213 - accuracy: 0.9041\n","Epoch 6/1000\n","379/387 [============================>.] - ETA: 0s - loss: 0.2085 - accuracy: 0.9064\n","Epoch 6: accuracy improved from 0.90412 to 0.90602, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 2s 6ms/step - loss: 0.2095 - accuracy: 0.9060\n","Epoch 7/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.1966 - accuracy: 0.9109\n","Epoch 7: accuracy improved from 0.90602 to 0.91085, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 2s 6ms/step - loss: 0.1966 - accuracy: 0.9109\n","Epoch 8/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.1879 - accuracy: 0.9131\n","Epoch 8: accuracy improved from 0.91085 to 0.91306, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 2s 6ms/step - loss: 0.1878 - accuracy: 0.9131\n","Epoch 9/1000\n","379/387 [============================>.] - ETA: 0s - loss: 0.1769 - accuracy: 0.9195\n","Epoch 9: accuracy improved from 0.91306 to 0.91932, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 2s 6ms/step - loss: 0.1778 - accuracy: 0.9193\n","Epoch 10/1000\n","379/387 [============================>.] - ETA: 0s - loss: 0.1695 - accuracy: 0.9215\n","Epoch 10: accuracy improved from 0.91932 to 0.92128, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 2s 6ms/step - loss: 0.1703 - accuracy: 0.9213\n","Epoch 11/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.1540 - accuracy: 0.9292\n","Epoch 11: accuracy improved from 0.92128 to 0.92862, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 2s 6ms/step - loss: 0.1545 - accuracy: 0.9286\n","Epoch 12/1000\n","379/387 [============================>.] - ETA: 0s - loss: 0.1488 - accuracy: 0.9290\n","Epoch 12: accuracy improved from 0.92862 to 0.92905, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 2s 6ms/step - loss: 0.1481 - accuracy: 0.9290\n","Epoch 13/1000\n","380/387 [============================>.] - ETA: 0s - loss: 0.1371 - accuracy: 0.9344\n","Epoch 13: accuracy improved from 0.92905 to 0.93440, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 2s 6ms/step - loss: 0.1373 - accuracy: 0.9344\n","Epoch 14/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.1301 - accuracy: 0.9386\n","Epoch 14: accuracy improved from 0.93440 to 0.93832, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 2s 6ms/step - loss: 0.1311 - accuracy: 0.9383\n","Epoch 15/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.1213 - accuracy: 0.9416\n","Epoch 15: accuracy improved from 0.93832 to 0.94160, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 2s 6ms/step - loss: 0.1212 - accuracy: 0.9416\n","Epoch 16/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.1150 - accuracy: 0.9454\n","Epoch 16: accuracy improved from 0.94160 to 0.94532, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 2s 6ms/step - loss: 0.1159 - accuracy: 0.9453\n","Epoch 17/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.1120 - accuracy: 0.9456\n","Epoch 17: accuracy improved from 0.94532 to 0.94568, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 2s 6ms/step - loss: 0.1119 - accuracy: 0.9457\n","Epoch 18/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.1020 - accuracy: 0.9516\n","Epoch 18: accuracy improved from 0.94568 to 0.95151, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 2s 6ms/step - loss: 0.1026 - accuracy: 0.9515\n","Epoch 19/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.1041 - accuracy: 0.9508\n","Epoch 19: accuracy did not improve from 0.95151\n","387/387 [==============================] - 2s 6ms/step - loss: 0.1042 - accuracy: 0.9508\n","Epoch 20/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0971 - accuracy: 0.9533\n","Epoch 20: accuracy improved from 0.95151 to 0.95332, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0970 - accuracy: 0.9533\n","Epoch 21/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0901 - accuracy: 0.9574\n","Epoch 21: accuracy improved from 0.95332 to 0.95735, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0901 - accuracy: 0.9573\n","Epoch 22/1000\n","380/387 [============================>.] - ETA: 0s - loss: 0.0877 - accuracy: 0.9587\n","Epoch 22: accuracy improved from 0.95735 to 0.95852, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0876 - accuracy: 0.9585\n","Epoch 23/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0901 - accuracy: 0.9581\n","Epoch 23: accuracy did not improve from 0.95852\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0905 - accuracy: 0.9575\n","Epoch 24/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0842 - accuracy: 0.9604\n","Epoch 24: accuracy improved from 0.95852 to 0.96042, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0842 - accuracy: 0.9604\n","Epoch 25/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0781 - accuracy: 0.9629\n","Epoch 25: accuracy improved from 0.96042 to 0.96278, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0782 - accuracy: 0.9628\n","Epoch 26/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0739 - accuracy: 0.9652\n","Epoch 26: accuracy improved from 0.96278 to 0.96519, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0741 - accuracy: 0.9652\n","Epoch 27/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0762 - accuracy: 0.9645\n","Epoch 27: accuracy did not improve from 0.96519\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0764 - accuracy: 0.9643\n","Epoch 28/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0712 - accuracy: 0.9667\n","Epoch 28: accuracy improved from 0.96519 to 0.96667, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0712 - accuracy: 0.9667\n","Epoch 29/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0743 - accuracy: 0.9648\n","Epoch 29: accuracy did not improve from 0.96667\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0743 - accuracy: 0.9648\n","Epoch 30/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0705 - accuracy: 0.9665\n","Epoch 30: accuracy did not improve from 0.96667\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0706 - accuracy: 0.9664\n","Epoch 31/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0698 - accuracy: 0.9675\n","Epoch 31: accuracy improved from 0.96667 to 0.96751, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0698 - accuracy: 0.9675\n","Epoch 32/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0626 - accuracy: 0.9703\n","Epoch 32: accuracy improved from 0.96751 to 0.97035, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0626 - accuracy: 0.9703\n","Epoch 33/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0643 - accuracy: 0.9696\n","Epoch 33: accuracy did not improve from 0.97035\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0645 - accuracy: 0.9698\n","Epoch 34/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0770 - accuracy: 0.9640\n","Epoch 34: accuracy did not improve from 0.97035\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0779 - accuracy: 0.9642\n","Epoch 35/1000\n","379/387 [============================>.] - ETA: 0s - loss: 0.0651 - accuracy: 0.9701\n","Epoch 35: accuracy did not improve from 0.97035\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0651 - accuracy: 0.9700\n","Epoch 36/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0705 - accuracy: 0.9680\n","Epoch 36: accuracy did not improve from 0.97035\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0705 - accuracy: 0.9680\n","Epoch 37/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0541 - accuracy: 0.9749\n","Epoch 37: accuracy improved from 0.97035 to 0.97487, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0540 - accuracy: 0.9749\n","Epoch 38/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0522 - accuracy: 0.9757\n","Epoch 38: accuracy improved from 0.97487 to 0.97562, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0525 - accuracy: 0.9756\n","Epoch 39/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0518 - accuracy: 0.9760\n","Epoch 39: accuracy improved from 0.97562 to 0.97601, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0519 - accuracy: 0.9760\n","Epoch 40/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0634 - accuracy: 0.9713\n","Epoch 40: accuracy did not improve from 0.97601\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0636 - accuracy: 0.9714\n","Epoch 41/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0625 - accuracy: 0.9722\n","Epoch 41: accuracy did not improve from 0.97601\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0622 - accuracy: 0.9722\n","Epoch 42/1000\n","380/387 [============================>.] - ETA: 0s - loss: 0.0611 - accuracy: 0.9723\n","Epoch 42: accuracy did not improve from 0.97601\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0609 - accuracy: 0.9724\n","Epoch 43/1000\n","379/387 [============================>.] - ETA: 0s - loss: 0.0536 - accuracy: 0.9757\n","Epoch 43: accuracy did not improve from 0.97601\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0536 - accuracy: 0.9755\n","Epoch 44/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0592 - accuracy: 0.9734\n","Epoch 44: accuracy did not improve from 0.97601\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0593 - accuracy: 0.9735\n","Epoch 45/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0494 - accuracy: 0.9780\n","Epoch 45: accuracy improved from 0.97601 to 0.97813, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0492 - accuracy: 0.9781\n","Epoch 46/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0460 - accuracy: 0.9792\n","Epoch 46: accuracy improved from 0.97813 to 0.97926, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0461 - accuracy: 0.9793\n","Epoch 47/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0646 - accuracy: 0.9714\n","Epoch 47: accuracy did not improve from 0.97926\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0644 - accuracy: 0.9713\n","Epoch 48/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0511 - accuracy: 0.9770\n","Epoch 48: accuracy did not improve from 0.97926\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0517 - accuracy: 0.9770\n","Epoch 49/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0656 - accuracy: 0.9701\n","Epoch 49: accuracy did not improve from 0.97926\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0654 - accuracy: 0.9702\n","Epoch 50/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0582 - accuracy: 0.9746\n","Epoch 50: accuracy did not improve from 0.97926\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0582 - accuracy: 0.9746\n","Epoch 51/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0543 - accuracy: 0.9755\n","Epoch 51: accuracy did not improve from 0.97926\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0548 - accuracy: 0.9751\n","Epoch 52/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0466 - accuracy: 0.9793\n","Epoch 52: accuracy did not improve from 0.97926\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0467 - accuracy: 0.9793\n","Epoch 53/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0502 - accuracy: 0.9777\n","Epoch 53: accuracy did not improve from 0.97926\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0503 - accuracy: 0.9777\n","Epoch 54/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0468 - accuracy: 0.9786\n","Epoch 54: accuracy did not improve from 0.97926\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0468 - accuracy: 0.9786\n","Epoch 55/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0465 - accuracy: 0.9795\n","Epoch 55: accuracy improved from 0.97926 to 0.97938, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0472 - accuracy: 0.9794\n","Epoch 56/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0538 - accuracy: 0.9763\n","Epoch 56: accuracy did not improve from 0.97938\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0538 - accuracy: 0.9763\n","Epoch 57/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0577 - accuracy: 0.9746\n","Epoch 57: accuracy did not improve from 0.97938\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0581 - accuracy: 0.9747\n","Epoch 58/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0471 - accuracy: 0.9785\n","Epoch 58: accuracy did not improve from 0.97938\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0471 - accuracy: 0.9785\n","Epoch 59/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0485 - accuracy: 0.9785\n","Epoch 59: accuracy did not improve from 0.97938\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0484 - accuracy: 0.9785\n","Epoch 60/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0439 - accuracy: 0.9793\n","Epoch 60: accuracy improved from 0.97938 to 0.97944, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0437 - accuracy: 0.9794\n","Epoch 61/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0457 - accuracy: 0.9792\n","Epoch 61: accuracy did not improve from 0.97944\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0458 - accuracy: 0.9791\n","Epoch 62/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0450 - accuracy: 0.9809\n","Epoch 62: accuracy improved from 0.97944 to 0.98063, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0454 - accuracy: 0.9806\n","Epoch 63/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0537 - accuracy: 0.9767\n","Epoch 63: accuracy did not improve from 0.98063\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0537 - accuracy: 0.9767\n","Epoch 64/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0534 - accuracy: 0.9760\n","Epoch 64: accuracy did not improve from 0.98063\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0534 - accuracy: 0.9760\n","Epoch 65/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0405 - accuracy: 0.9818\n","Epoch 65: accuracy improved from 0.98063 to 0.98183, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0407 - accuracy: 0.9818\n","Epoch 66/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0380 - accuracy: 0.9829\n","Epoch 66: accuracy improved from 0.98183 to 0.98284, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0380 - accuracy: 0.9828\n","Epoch 67/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0306 - accuracy: 0.9858\n","Epoch 67: accuracy improved from 0.98284 to 0.98581, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0307 - accuracy: 0.9858\n","Epoch 68/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0425 - accuracy: 0.9804\n","Epoch 68: accuracy did not improve from 0.98581\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0425 - accuracy: 0.9804\n","Epoch 69/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0445 - accuracy: 0.9804\n","Epoch 69: accuracy did not improve from 0.98581\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0454 - accuracy: 0.9804\n","Epoch 70/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0527 - accuracy: 0.9776\n","Epoch 70: accuracy did not improve from 0.98581\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0527 - accuracy: 0.9776\n","Epoch 71/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0441 - accuracy: 0.9805\n","Epoch 71: accuracy did not improve from 0.98581\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0448 - accuracy: 0.9804\n","Epoch 72/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0508 - accuracy: 0.9783\n","Epoch 72: accuracy did not improve from 0.98581\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0508 - accuracy: 0.9782\n","Epoch 73/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0355 - accuracy: 0.9836\n","Epoch 73: accuracy did not improve from 0.98581\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0354 - accuracy: 0.9836\n","Epoch 74/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0460 - accuracy: 0.9809\n","Epoch 74: accuracy did not improve from 0.98581\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0461 - accuracy: 0.9808\n","Epoch 75/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0448 - accuracy: 0.9804\n","Epoch 75: accuracy did not improve from 0.98581\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0449 - accuracy: 0.9804\n","Epoch 76/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0481 - accuracy: 0.9791\n","Epoch 76: accuracy did not improve from 0.98581\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0481 - accuracy: 0.9791\n","Epoch 77/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0407 - accuracy: 0.9819\n","Epoch 77: accuracy did not improve from 0.98581\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0406 - accuracy: 0.9819\n","Epoch 78/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0313 - accuracy: 0.9862\n","Epoch 78: accuracy improved from 0.98581 to 0.98623, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0313 - accuracy: 0.9862\n","Epoch 79/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0414 - accuracy: 0.9823\n","Epoch 79: accuracy did not improve from 0.98623\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0415 - accuracy: 0.9823\n","Epoch 80/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0419 - accuracy: 0.9821\n","Epoch 80: accuracy did not improve from 0.98623\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0417 - accuracy: 0.9822\n","Epoch 81/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0439 - accuracy: 0.9808\n","Epoch 81: accuracy did not improve from 0.98623\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0439 - accuracy: 0.9808\n","Epoch 82/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0425 - accuracy: 0.9810\n","Epoch 82: accuracy did not improve from 0.98623\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0423 - accuracy: 0.9811\n","Epoch 83/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0428 - accuracy: 0.9819\n","Epoch 83: accuracy did not improve from 0.98623\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0426 - accuracy: 0.9819\n","Epoch 84/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0468 - accuracy: 0.9802\n","Epoch 84: accuracy did not improve from 0.98623\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0478 - accuracy: 0.9803\n","Epoch 85/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0399 - accuracy: 0.9819\n","Epoch 85: accuracy did not improve from 0.98623\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0400 - accuracy: 0.9819\n","Epoch 86/1000\n","380/387 [============================>.] - ETA: 0s - loss: 0.0315 - accuracy: 0.9862\n","Epoch 86: accuracy did not improve from 0.98623\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0317 - accuracy: 0.9860\n","Epoch 87/1000\n","379/387 [============================>.] - ETA: 0s - loss: 0.0405 - accuracy: 0.9814\n","Epoch 87: accuracy did not improve from 0.98623\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0403 - accuracy: 0.9816\n","Epoch 88/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0513 - accuracy: 0.9785\n","Epoch 88: accuracy did not improve from 0.98623\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0516 - accuracy: 0.9781\n","Epoch 89/1000\n","379/387 [============================>.] - ETA: 0s - loss: 0.0426 - accuracy: 0.9817\n","Epoch 89: accuracy did not improve from 0.98623\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0427 - accuracy: 0.9817\n","Epoch 90/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0393 - accuracy: 0.9829\n","Epoch 90: accuracy did not improve from 0.98623\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0394 - accuracy: 0.9829\n","Epoch 91/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0317 - accuracy: 0.9857\n","Epoch 91: accuracy did not improve from 0.98623\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0316 - accuracy: 0.9857\n","Epoch 92/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0246 - accuracy: 0.9893\n","Epoch 92: accuracy improved from 0.98623 to 0.98927, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0246 - accuracy: 0.9893\n","Epoch 93/1000\n","380/387 [============================>.] - ETA: 0s - loss: 0.0291 - accuracy: 0.9868\n","Epoch 93: accuracy did not improve from 0.98927\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0295 - accuracy: 0.9869\n","Epoch 94/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0482 - accuracy: 0.9802\n","Epoch 94: accuracy did not improve from 0.98927\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0478 - accuracy: 0.9803\n","Epoch 95/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0398 - accuracy: 0.9828\n","Epoch 95: accuracy did not improve from 0.98927\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0398 - accuracy: 0.9828\n","Epoch 96/1000\n","380/387 [============================>.] - ETA: 0s - loss: 0.0430 - accuracy: 0.9818\n","Epoch 96: accuracy did not improve from 0.98927\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0430 - accuracy: 0.9818\n","Epoch 97/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0336 - accuracy: 0.9856\n","Epoch 97: accuracy did not improve from 0.98927\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0336 - accuracy: 0.9855\n","Epoch 98/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0277 - accuracy: 0.9880\n","Epoch 98: accuracy did not improve from 0.98927\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0275 - accuracy: 0.9881\n","Epoch 99/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0337 - accuracy: 0.9856\n","Epoch 99: accuracy did not improve from 0.98927\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0339 - accuracy: 0.9856\n","Epoch 100/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0402 - accuracy: 0.9831\n","Epoch 100: accuracy did not improve from 0.98927\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0401 - accuracy: 0.9831\n","Epoch 101/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0338 - accuracy: 0.9852\n","Epoch 101: accuracy did not improve from 0.98927\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0338 - accuracy: 0.9852\n","Epoch 102/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0383 - accuracy: 0.9842\n","Epoch 102: accuracy did not improve from 0.98927\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0384 - accuracy: 0.9843\n","Epoch 103/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0284 - accuracy: 0.9875\n","Epoch 103: accuracy did not improve from 0.98927\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0282 - accuracy: 0.9876\n","Epoch 104/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0400 - accuracy: 0.9836\n","Epoch 104: accuracy did not improve from 0.98927\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0401 - accuracy: 0.9836\n","Epoch 105/1000\n","379/387 [============================>.] - ETA: 0s - loss: 0.0469 - accuracy: 0.9812\n","Epoch 105: accuracy did not improve from 0.98927\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0470 - accuracy: 0.9809\n","Epoch 106/1000\n","380/387 [============================>.] - ETA: 0s - loss: 0.0327 - accuracy: 0.9857\n","Epoch 106: accuracy did not improve from 0.98927\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0328 - accuracy: 0.9856\n","Epoch 107/1000\n","380/387 [============================>.] - ETA: 0s - loss: 0.0252 - accuracy: 0.9892\n","Epoch 107: accuracy did not improve from 0.98927\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0255 - accuracy: 0.9892\n","Epoch 108/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0277 - accuracy: 0.9874\n","Epoch 108: accuracy did not improve from 0.98927\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0278 - accuracy: 0.9873\n","Epoch 109/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0509 - accuracy: 0.9797\n","Epoch 109: accuracy did not improve from 0.98927\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0509 - accuracy: 0.9797\n","Epoch 110/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0351 - accuracy: 0.9847\n","Epoch 110: accuracy did not improve from 0.98927\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0351 - accuracy: 0.9847\n","Epoch 111/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0371 - accuracy: 0.9842\n","Epoch 111: accuracy did not improve from 0.98927\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0370 - accuracy: 0.9842\n","Epoch 112/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0375 - accuracy: 0.9843\n","Epoch 112: accuracy did not improve from 0.98927\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0375 - accuracy: 0.9844\n","Epoch 113/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0349 - accuracy: 0.9850\n","Epoch 113: accuracy did not improve from 0.98927\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0355 - accuracy: 0.9851\n","Epoch 114/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0373 - accuracy: 0.9839\n","Epoch 114: accuracy did not improve from 0.98927\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0374 - accuracy: 0.9839\n","Epoch 115/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0323 - accuracy: 0.9860\n","Epoch 115: accuracy did not improve from 0.98927\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0323 - accuracy: 0.9859\n","Epoch 116/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0386 - accuracy: 0.9841\n","Epoch 116: accuracy did not improve from 0.98927\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0386 - accuracy: 0.9841\n","Epoch 117/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0400 - accuracy: 0.9834\n","Epoch 117: accuracy did not improve from 0.98927\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0402 - accuracy: 0.9836\n","Epoch 118/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0447 - accuracy: 0.9820\n","Epoch 118: accuracy did not improve from 0.98927\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0447 - accuracy: 0.9820\n","Epoch 119/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0274 - accuracy: 0.9880\n","Epoch 119: accuracy did not improve from 0.98927\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0273 - accuracy: 0.9880\n","Epoch 120/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0190 - accuracy: 0.9915\n","Epoch 120: accuracy improved from 0.98927 to 0.99145, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0191 - accuracy: 0.9914\n","Epoch 121/1000\n","379/387 [============================>.] - ETA: 0s - loss: 0.0340 - accuracy: 0.9856\n","Epoch 121: accuracy did not improve from 0.99145\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0342 - accuracy: 0.9855\n","Epoch 122/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0382 - accuracy: 0.9841\n","Epoch 122: accuracy did not improve from 0.99145\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0382 - accuracy: 0.9841\n","Epoch 123/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0300 - accuracy: 0.9865\n","Epoch 123: accuracy did not improve from 0.99145\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0300 - accuracy: 0.9866\n","Epoch 124/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0219 - accuracy: 0.9906\n","Epoch 124: accuracy did not improve from 0.99145\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0219 - accuracy: 0.9906\n","Epoch 125/1000\n","379/387 [============================>.] - ETA: 0s - loss: 0.0254 - accuracy: 0.9891\n","Epoch 125: accuracy did not improve from 0.99145\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0254 - accuracy: 0.9891\n","Epoch 126/1000\n","380/387 [============================>.] - ETA: 0s - loss: 0.0244 - accuracy: 0.9896\n","Epoch 126: accuracy did not improve from 0.99145\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0241 - accuracy: 0.9897\n","Epoch 127/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0293 - accuracy: 0.9872\n","Epoch 127: accuracy did not improve from 0.99145\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0300 - accuracy: 0.9870\n","Epoch 128/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0432 - accuracy: 0.9825\n","Epoch 128: accuracy did not improve from 0.99145\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0430 - accuracy: 0.9825\n","Epoch 129/1000\n","379/387 [============================>.] - ETA: 0s - loss: 0.0309 - accuracy: 0.9860\n","Epoch 129: accuracy did not improve from 0.99145\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0306 - accuracy: 0.9861\n","Epoch 130/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0406 - accuracy: 0.9832\n","Epoch 130: accuracy did not improve from 0.99145\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0406 - accuracy: 0.9832\n","Epoch 131/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0306 - accuracy: 0.9866\n","Epoch 131: accuracy did not improve from 0.99145\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0305 - accuracy: 0.9867\n","Epoch 132/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0322 - accuracy: 0.9862\n","Epoch 132: accuracy did not improve from 0.99145\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0323 - accuracy: 0.9863\n","Epoch 133/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0353 - accuracy: 0.9853\n","Epoch 133: accuracy did not improve from 0.99145\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0351 - accuracy: 0.9854\n","Epoch 134/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0308 - accuracy: 0.9868\n","Epoch 134: accuracy did not improve from 0.99145\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0307 - accuracy: 0.9869\n","Epoch 135/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0359 - accuracy: 0.9846\n","Epoch 135: accuracy did not improve from 0.99145\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0360 - accuracy: 0.9847\n","Epoch 136/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0380 - accuracy: 0.9833\n","Epoch 136: accuracy did not improve from 0.99145\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0379 - accuracy: 0.9833\n","Epoch 137/1000\n","379/387 [============================>.] - ETA: 0s - loss: 0.0284 - accuracy: 0.9882\n","Epoch 137: accuracy did not improve from 0.99145\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0281 - accuracy: 0.9883\n","Epoch 138/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0191 - accuracy: 0.9914\n","Epoch 138: accuracy did not improve from 0.99145\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0191 - accuracy: 0.9914\n","Epoch 139/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0171 - accuracy: 0.9925\n","Epoch 139: accuracy improved from 0.99145 to 0.99248, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0172 - accuracy: 0.9925\n","Epoch 140/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0258 - accuracy: 0.9893\n","Epoch 140: accuracy did not improve from 0.99248\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0261 - accuracy: 0.9892\n","Epoch 141/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0273 - accuracy: 0.9882\n","Epoch 141: accuracy did not improve from 0.99248\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0272 - accuracy: 0.9883\n","Epoch 142/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0405 - accuracy: 0.9844\n","Epoch 142: accuracy did not improve from 0.99248\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0405 - accuracy: 0.9843\n","Epoch 143/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0475 - accuracy: 0.9806\n","Epoch 143: accuracy did not improve from 0.99248\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0475 - accuracy: 0.9806\n","Epoch 144/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0297 - accuracy: 0.9869\n","Epoch 144: accuracy did not improve from 0.99248\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0296 - accuracy: 0.9869\n","Epoch 145/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0286 - accuracy: 0.9881\n","Epoch 145: accuracy did not improve from 0.99248\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0285 - accuracy: 0.9882\n","Epoch 146/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0238 - accuracy: 0.9901\n","Epoch 146: accuracy did not improve from 0.99248\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0238 - accuracy: 0.9901\n","Epoch 147/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0168 - accuracy: 0.9926\n","Epoch 147: accuracy improved from 0.99248 to 0.99260, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0168 - accuracy: 0.9926\n","Epoch 148/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0162 - accuracy: 0.9936\n","Epoch 148: accuracy improved from 0.99260 to 0.99349, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0165 - accuracy: 0.9935\n","Epoch 149/1000\n","379/387 [============================>.] - ETA: 0s - loss: 0.0167 - accuracy: 0.9936\n","Epoch 149: accuracy improved from 0.99349 to 0.99357, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0169 - accuracy: 0.9936\n","Epoch 150/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0329 - accuracy: 0.9860\n","Epoch 150: accuracy did not improve from 0.99357\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0328 - accuracy: 0.9861\n","Epoch 151/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0303 - accuracy: 0.9872\n","Epoch 151: accuracy did not improve from 0.99357\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0303 - accuracy: 0.9872\n","Epoch 152/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0215 - accuracy: 0.9910\n","Epoch 152: accuracy did not improve from 0.99357\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0214 - accuracy: 0.9911\n","Epoch 153/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0315 - accuracy: 0.9876\n","Epoch 153: accuracy did not improve from 0.99357\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0316 - accuracy: 0.9875\n","Epoch 154/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0359 - accuracy: 0.9858\n","Epoch 154: accuracy did not improve from 0.99357\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0359 - accuracy: 0.9857\n","Epoch 155/1000\n","380/387 [============================>.] - ETA: 0s - loss: 0.0312 - accuracy: 0.9869\n","Epoch 155: accuracy did not improve from 0.99357\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0314 - accuracy: 0.9867\n","Epoch 156/1000\n","380/387 [============================>.] - ETA: 0s - loss: 0.0310 - accuracy: 0.9873\n","Epoch 156: accuracy did not improve from 0.99357\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0313 - accuracy: 0.9874\n","Epoch 157/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0170 - accuracy: 0.9926\n","Epoch 157: accuracy did not improve from 0.99357\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0170 - accuracy: 0.9926\n","Epoch 158/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0138 - accuracy: 0.9942\n","Epoch 158: accuracy improved from 0.99357 to 0.99412, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0139 - accuracy: 0.9941\n","Epoch 159/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0212 - accuracy: 0.9911\n","Epoch 159: accuracy did not improve from 0.99412\n","387/387 [==============================] - 3s 6ms/step - loss: 0.0212 - accuracy: 0.9911\n","Epoch 160/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0230 - accuracy: 0.9906\n","Epoch 160: accuracy did not improve from 0.99412\n","387/387 [==============================] - 3s 6ms/step - loss: 0.0230 - accuracy: 0.9906\n","Epoch 161/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0314 - accuracy: 0.9871\n","Epoch 161: accuracy did not improve from 0.99412\n","387/387 [==============================] - 3s 6ms/step - loss: 0.0313 - accuracy: 0.9871\n","Epoch 162/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0327 - accuracy: 0.9865\n","Epoch 162: accuracy did not improve from 0.99412\n","387/387 [==============================] - 3s 6ms/step - loss: 0.0327 - accuracy: 0.9865\n","Epoch 163/1000\n","379/387 [============================>.] - ETA: 0s - loss: 0.0241 - accuracy: 0.9896\n","Epoch 163: accuracy did not improve from 0.99412\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0240 - accuracy: 0.9896\n","Epoch 164/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0215 - accuracy: 0.9912\n","Epoch 164: accuracy did not improve from 0.99412\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0215 - accuracy: 0.9912\n","Epoch 165/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0219 - accuracy: 0.9913\n","Epoch 165: accuracy did not improve from 0.99412\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0231 - accuracy: 0.9910\n","Epoch 166/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0408 - accuracy: 0.9835\n","Epoch 166: accuracy did not improve from 0.99412\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0409 - accuracy: 0.9834\n","Epoch 167/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0278 - accuracy: 0.9890\n","Epoch 167: accuracy did not improve from 0.99412\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0278 - accuracy: 0.9890\n","Epoch 168/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0193 - accuracy: 0.9926\n","Epoch 168: accuracy did not improve from 0.99412\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0193 - accuracy: 0.9926\n","Epoch 169/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0277 - accuracy: 0.9893\n","Epoch 169: accuracy did not improve from 0.99412\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0276 - accuracy: 0.9894\n","Epoch 170/1000\n","380/387 [============================>.] - ETA: 0s - loss: 0.0315 - accuracy: 0.9872\n","Epoch 170: accuracy did not improve from 0.99412\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0313 - accuracy: 0.9873\n","Epoch 171/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0238 - accuracy: 0.9900\n","Epoch 171: accuracy did not improve from 0.99412\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0238 - accuracy: 0.9900\n","Epoch 172/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0175 - accuracy: 0.9924\n","Epoch 172: accuracy did not improve from 0.99412\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0174 - accuracy: 0.9924\n","Epoch 173/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0161 - accuracy: 0.9934\n","Epoch 173: accuracy did not improve from 0.99412\n","387/387 [==============================] - 3s 6ms/step - loss: 0.0162 - accuracy: 0.9933\n","Epoch 174/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0147 - accuracy: 0.9940\n","Epoch 174: accuracy did not improve from 0.99412\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0147 - accuracy: 0.9940\n","Epoch 175/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0288 - accuracy: 0.9885\n","Epoch 175: accuracy did not improve from 0.99412\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0288 - accuracy: 0.9885\n","Epoch 176/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0322 - accuracy: 0.9867\n","Epoch 176: accuracy did not improve from 0.99412\n","387/387 [==============================] - 3s 6ms/step - loss: 0.0321 - accuracy: 0.9867\n","Epoch 177/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0319 - accuracy: 0.9878\n","Epoch 177: accuracy did not improve from 0.99412\n","387/387 [==============================] - 3s 6ms/step - loss: 0.0317 - accuracy: 0.9878\n","Epoch 178/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0278 - accuracy: 0.9888\n","Epoch 178: accuracy did not improve from 0.99412\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0275 - accuracy: 0.9889\n","Epoch 179/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0272 - accuracy: 0.9891\n","Epoch 179: accuracy did not improve from 0.99412\n","387/387 [==============================] - 3s 6ms/step - loss: 0.0272 - accuracy: 0.9891\n","Epoch 180/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0255 - accuracy: 0.9900\n","Epoch 180: accuracy did not improve from 0.99412\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0257 - accuracy: 0.9899\n","Epoch 181/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0208 - accuracy: 0.9912\n","Epoch 181: accuracy did not improve from 0.99412\n","387/387 [==============================] - 3s 6ms/step - loss: 0.0208 - accuracy: 0.9912\n","Epoch 182/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0158 - accuracy: 0.9933\n","Epoch 182: accuracy did not improve from 0.99412\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0158 - accuracy: 0.9933\n","Epoch 183/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0112 - accuracy: 0.9953\n","Epoch 183: accuracy improved from 0.99412 to 0.99535, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0111 - accuracy: 0.9954\n","Epoch 184/1000\n","380/387 [============================>.] - ETA: 0s - loss: 0.0116 - accuracy: 0.9954\n","Epoch 184: accuracy did not improve from 0.99535\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0126 - accuracy: 0.9952\n","Epoch 185/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0285 - accuracy: 0.9887\n","Epoch 185: accuracy did not improve from 0.99535\n","387/387 [==============================] - 3s 6ms/step - loss: 0.0284 - accuracy: 0.9887\n","Epoch 186/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0276 - accuracy: 0.9893\n","Epoch 186: accuracy did not improve from 0.99535\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0275 - accuracy: 0.9894\n","Epoch 187/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0272 - accuracy: 0.9895\n","Epoch 187: accuracy did not improve from 0.99535\n","387/387 [==============================] - 3s 6ms/step - loss: 0.0272 - accuracy: 0.9895\n","Epoch 188/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0330 - accuracy: 0.9870\n","Epoch 188: accuracy did not improve from 0.99535\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0330 - accuracy: 0.9870\n","Epoch 189/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0280 - accuracy: 0.9885\n","Epoch 189: accuracy did not improve from 0.99535\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0279 - accuracy: 0.9885\n","Epoch 190/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0181 - accuracy: 0.9925\n","Epoch 190: accuracy did not improve from 0.99535\n","387/387 [==============================] - 3s 6ms/step - loss: 0.0181 - accuracy: 0.9925\n","Epoch 191/1000\n","380/387 [============================>.] - ETA: 0s - loss: 0.0157 - accuracy: 0.9932\n","Epoch 191: accuracy did not improve from 0.99535\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0156 - accuracy: 0.9932\n","Epoch 192/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0291 - accuracy: 0.9887\n","Epoch 192: accuracy did not improve from 0.99535\n","387/387 [==============================] - 3s 6ms/step - loss: 0.0291 - accuracy: 0.9887\n","Epoch 193/1000\n","380/387 [============================>.] - ETA: 0s - loss: 0.0202 - accuracy: 0.9917\n","Epoch 193: accuracy did not improve from 0.99535\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0202 - accuracy: 0.9917\n","Epoch 194/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0114 - accuracy: 0.9953\n","Epoch 194: accuracy did not improve from 0.99535\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0118 - accuracy: 0.9952\n","Epoch 195/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0221 - accuracy: 0.9911\n","Epoch 195: accuracy did not improve from 0.99535\n","387/387 [==============================] - 3s 6ms/step - loss: 0.0228 - accuracy: 0.9910\n","Epoch 196/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0392 - accuracy: 0.9840\n","Epoch 196: accuracy did not improve from 0.99535\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0391 - accuracy: 0.9842\n","Epoch 197/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0223 - accuracy: 0.9913\n","Epoch 197: accuracy did not improve from 0.99535\n","387/387 [==============================] - 3s 6ms/step - loss: 0.0222 - accuracy: 0.9913\n","Epoch 198/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0243 - accuracy: 0.9900\n","Epoch 198: accuracy did not improve from 0.99535\n","387/387 [==============================] - 3s 6ms/step - loss: 0.0242 - accuracy: 0.9900\n","Epoch 199/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0169 - accuracy: 0.9931\n","Epoch 199: accuracy did not improve from 0.99535\n","387/387 [==============================] - 3s 6ms/step - loss: 0.0169 - accuracy: 0.9930\n","Epoch 200/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0109 - accuracy: 0.9955\n","Epoch 200: accuracy improved from 0.99535 to 0.99547, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0109 - accuracy: 0.9955\n","Epoch 201/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0077 - accuracy: 0.9969\n","Epoch 201: accuracy improved from 0.99547 to 0.99687, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0077 - accuracy: 0.9969\n","Epoch 202/1000\n","379/387 [============================>.] - ETA: 0s - loss: 0.0225 - accuracy: 0.9907\n","Epoch 202: accuracy did not improve from 0.99687\n","387/387 [==============================] - 2s 6ms/step - loss: 0.0228 - accuracy: 0.9906\n","Epoch 203/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0367 - accuracy: 0.9859\n","Epoch 203: accuracy did not improve from 0.99687\n","387/387 [==============================] - 3s 6ms/step - loss: 0.0367 - accuracy: 0.9859\n","Epoch 204/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0314 - accuracy: 0.9883\n","Epoch 204: accuracy did not improve from 0.99687\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0314 - accuracy: 0.9883\n","Epoch 205/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0284 - accuracy: 0.9895\n","Epoch 205: accuracy did not improve from 0.99687\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0288 - accuracy: 0.9893\n","Epoch 206/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0327 - accuracy: 0.9866\n","Epoch 206: accuracy did not improve from 0.99687\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0329 - accuracy: 0.9865\n","Epoch 207/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0263 - accuracy: 0.9893\n","Epoch 207: accuracy did not improve from 0.99687\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0263 - accuracy: 0.9893\n","Epoch 208/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0135 - accuracy: 0.9943\n","Epoch 208: accuracy did not improve from 0.99687\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0134 - accuracy: 0.9944\n","Epoch 209/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0258 - accuracy: 0.9903\n","Epoch 209: accuracy did not improve from 0.99687\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0265 - accuracy: 0.9899\n","Epoch 210/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0310 - accuracy: 0.9882\n","Epoch 210: accuracy did not improve from 0.99687\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0310 - accuracy: 0.9882\n","Epoch 211/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0136 - accuracy: 0.9942\n","Epoch 211: accuracy did not improve from 0.99687\n","387/387 [==============================] - 3s 6ms/step - loss: 0.0137 - accuracy: 0.9941\n","Epoch 212/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0133 - accuracy: 0.9945\n","Epoch 212: accuracy did not improve from 0.99687\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0135 - accuracy: 0.9942\n","Epoch 213/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0274 - accuracy: 0.9890\n","Epoch 213: accuracy did not improve from 0.99687\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0274 - accuracy: 0.9890\n","Epoch 214/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0180 - accuracy: 0.9925\n","Epoch 214: accuracy did not improve from 0.99687\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0181 - accuracy: 0.9925\n","Epoch 215/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0113 - accuracy: 0.9951\n","Epoch 215: accuracy did not improve from 0.99687\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0113 - accuracy: 0.9951\n","Epoch 216/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0221 - accuracy: 0.9916\n","Epoch 216: accuracy did not improve from 0.99687\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0221 - accuracy: 0.9916\n","Epoch 217/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0171 - accuracy: 0.9929\n","Epoch 217: accuracy did not improve from 0.99687\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0172 - accuracy: 0.9929\n","Epoch 218/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0307 - accuracy: 0.9887\n","Epoch 218: accuracy did not improve from 0.99687\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0308 - accuracy: 0.9885\n","Epoch 219/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0332 - accuracy: 0.9874\n","Epoch 219: accuracy did not improve from 0.99687\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0332 - accuracy: 0.9874\n","Epoch 220/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0262 - accuracy: 0.9888\n","Epoch 220: accuracy did not improve from 0.99687\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0262 - accuracy: 0.9888\n","Epoch 221/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0132 - accuracy: 0.9944\n","Epoch 221: accuracy did not improve from 0.99687\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0132 - accuracy: 0.9944\n","Epoch 222/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0094 - accuracy: 0.9961\n","Epoch 222: accuracy did not improve from 0.99687\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0094 - accuracy: 0.9961\n","Epoch 223/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0080 - accuracy: 0.9967\n","Epoch 223: accuracy did not improve from 0.99687\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0080 - accuracy: 0.9967\n","Epoch 224/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0054 - accuracy: 0.9979\n","Epoch 224: accuracy improved from 0.99687 to 0.99790, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0054 - accuracy: 0.9979\n","Epoch 225/1000\n","380/387 [============================>.] - ETA: 0s - loss: 0.0060 - accuracy: 0.9974\n","Epoch 225: accuracy did not improve from 0.99790\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0060 - accuracy: 0.9975\n","Epoch 226/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0235 - accuracy: 0.9922\n","Epoch 226: accuracy did not improve from 0.99790\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0237 - accuracy: 0.9921\n","Epoch 227/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0663 - accuracy: 0.9749\n","Epoch 227: accuracy did not improve from 0.99790\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0664 - accuracy: 0.9749\n","Epoch 228/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0247 - accuracy: 0.9897\n","Epoch 228: accuracy did not improve from 0.99790\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0247 - accuracy: 0.9897\n","Epoch 229/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0177 - accuracy: 0.9924\n","Epoch 229: accuracy did not improve from 0.99790\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0176 - accuracy: 0.9925\n","Epoch 230/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0111 - accuracy: 0.9955\n","Epoch 230: accuracy did not improve from 0.99790\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0111 - accuracy: 0.9955\n","Epoch 231/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0085 - accuracy: 0.9965\n","Epoch 231: accuracy did not improve from 0.99790\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0085 - accuracy: 0.9965\n","Epoch 232/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0074 - accuracy: 0.9971\n","Epoch 232: accuracy did not improve from 0.99790\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0074 - accuracy: 0.9971\n","Epoch 233/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0075 - accuracy: 0.9972\n","Epoch 233: accuracy did not improve from 0.99790\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0076 - accuracy: 0.9971\n","Epoch 234/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0654 - accuracy: 0.9776\n","Epoch 234: accuracy did not improve from 0.99790\n","387/387 [==============================] - 3s 6ms/step - loss: 0.0651 - accuracy: 0.9776\n","Epoch 235/1000\n","380/387 [============================>.] - ETA: 0s - loss: 0.0264 - accuracy: 0.9891\n","Epoch 235: accuracy did not improve from 0.99790\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0267 - accuracy: 0.9891\n","Epoch 236/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0256 - accuracy: 0.9893\n","Epoch 236: accuracy did not improve from 0.99790\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0254 - accuracy: 0.9893\n","Epoch 237/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0121 - accuracy: 0.9948\n","Epoch 237: accuracy did not improve from 0.99790\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0121 - accuracy: 0.9947\n","Epoch 238/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0079 - accuracy: 0.9968\n","Epoch 238: accuracy did not improve from 0.99790\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0079 - accuracy: 0.9968\n","Epoch 239/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0056 - accuracy: 0.9978\n","Epoch 239: accuracy did not improve from 0.99790\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0056 - accuracy: 0.9978\n","Epoch 240/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0048 - accuracy: 0.9983\n","Epoch 240: accuracy improved from 0.99790 to 0.99832, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0048 - accuracy: 0.9983\n","Epoch 241/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0045 - accuracy: 0.9983\n","Epoch 241: accuracy did not improve from 0.99832\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0045 - accuracy: 0.9982\n","Epoch 242/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0215 - accuracy: 0.9921\n","Epoch 242: accuracy did not improve from 0.99832\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0219 - accuracy: 0.9922\n","Epoch 243/1000\n","380/387 [============================>.] - ETA: 0s - loss: 0.0640 - accuracy: 0.9775\n","Epoch 243: accuracy did not improve from 0.99832\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0638 - accuracy: 0.9776\n","Epoch 244/1000\n","380/387 [============================>.] - ETA: 0s - loss: 0.0286 - accuracy: 0.9874\n","Epoch 244: accuracy did not improve from 0.99832\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0289 - accuracy: 0.9874\n","Epoch 245/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0202 - accuracy: 0.9917\n","Epoch 245: accuracy did not improve from 0.99832\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0202 - accuracy: 0.9918\n","Epoch 246/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0159 - accuracy: 0.9935\n","Epoch 246: accuracy did not improve from 0.99832\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0160 - accuracy: 0.9935\n","Epoch 247/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0106 - accuracy: 0.9954\n","Epoch 247: accuracy did not improve from 0.99832\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0105 - accuracy: 0.9955\n","Epoch 248/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0205 - accuracy: 0.9911\n","Epoch 248: accuracy did not improve from 0.99832\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0207 - accuracy: 0.9909\n","Epoch 249/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0147 - accuracy: 0.9935\n","Epoch 249: accuracy did not improve from 0.99832\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0148 - accuracy: 0.9936\n","Epoch 250/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0084 - accuracy: 0.9963\n","Epoch 250: accuracy did not improve from 0.99832\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0084 - accuracy: 0.9963\n","Epoch 251/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0134 - accuracy: 0.9947\n","Epoch 251: accuracy did not improve from 0.99832\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0135 - accuracy: 0.9947\n","Epoch 252/1000\n","380/387 [============================>.] - ETA: 0s - loss: 0.0154 - accuracy: 0.9936\n","Epoch 252: accuracy did not improve from 0.99832\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0152 - accuracy: 0.9937\n","Epoch 253/1000\n","379/387 [============================>.] - ETA: 0s - loss: 0.0375 - accuracy: 0.9864\n","Epoch 253: accuracy did not improve from 0.99832\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0373 - accuracy: 0.9864\n","Epoch 254/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0318 - accuracy: 0.9876\n","Epoch 254: accuracy did not improve from 0.99832\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0319 - accuracy: 0.9874\n","Epoch 255/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0192 - accuracy: 0.9915\n","Epoch 255: accuracy did not improve from 0.99832\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0190 - accuracy: 0.9916\n","Epoch 256/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0124 - accuracy: 0.9946\n","Epoch 256: accuracy did not improve from 0.99832\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0124 - accuracy: 0.9946\n","Epoch 257/1000\n","380/387 [============================>.] - ETA: 0s - loss: 0.0110 - accuracy: 0.9954\n","Epoch 257: accuracy did not improve from 0.99832\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0111 - accuracy: 0.9954\n","Epoch 258/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0354 - accuracy: 0.9871\n","Epoch 258: accuracy did not improve from 0.99832\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0353 - accuracy: 0.9871\n","Epoch 259/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0197 - accuracy: 0.9927\n","Epoch 259: accuracy did not improve from 0.99832\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0198 - accuracy: 0.9927\n","Epoch 260/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0111 - accuracy: 0.9950\n","Epoch 260: accuracy did not improve from 0.99832\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0111 - accuracy: 0.9950\n","Epoch 261/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0075 - accuracy: 0.9969\n","Epoch 261: accuracy did not improve from 0.99832\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0074 - accuracy: 0.9969\n","Epoch 262/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0079 - accuracy: 0.9965\n","Epoch 262: accuracy did not improve from 0.99832\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0079 - accuracy: 0.9965\n","Epoch 263/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0128 - accuracy: 0.9945\n","Epoch 263: accuracy did not improve from 0.99832\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0128 - accuracy: 0.9945\n","Epoch 264/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0312 - accuracy: 0.9888\n","Epoch 264: accuracy did not improve from 0.99832\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0312 - accuracy: 0.9888\n","Epoch 265/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0318 - accuracy: 0.9876\n","Epoch 265: accuracy did not improve from 0.99832\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0318 - accuracy: 0.9874\n","Epoch 266/1000\n","380/387 [============================>.] - ETA: 0s - loss: 0.0180 - accuracy: 0.9923\n","Epoch 266: accuracy did not improve from 0.99832\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0181 - accuracy: 0.9924\n","Epoch 267/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0082 - accuracy: 0.9968\n","Epoch 267: accuracy did not improve from 0.99832\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0083 - accuracy: 0.9967\n","Epoch 268/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0128 - accuracy: 0.9949\n","Epoch 268: accuracy did not improve from 0.99832\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0129 - accuracy: 0.9949\n","Epoch 269/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0302 - accuracy: 0.9881\n","Epoch 269: accuracy did not improve from 0.99832\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0302 - accuracy: 0.9880\n","Epoch 270/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0221 - accuracy: 0.9910\n","Epoch 270: accuracy did not improve from 0.99832\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0220 - accuracy: 0.9911\n","Epoch 271/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0129 - accuracy: 0.9947\n","Epoch 271: accuracy did not improve from 0.99832\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0128 - accuracy: 0.9947\n","Epoch 272/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0071 - accuracy: 0.9969\n","Epoch 272: accuracy did not improve from 0.99832\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0071 - accuracy: 0.9969\n","Epoch 273/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0063 - accuracy: 0.9973\n","Epoch 273: accuracy did not improve from 0.99832\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0063 - accuracy: 0.9973\n","Epoch 274/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0050 - accuracy: 0.9980\n","Epoch 274: accuracy did not improve from 0.99832\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0052 - accuracy: 0.9980\n","Epoch 275/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0050 - accuracy: 0.9979\n","Epoch 275: accuracy did not improve from 0.99832\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0050 - accuracy: 0.9979\n","Epoch 276/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0262 - accuracy: 0.9915\n","Epoch 276: accuracy did not improve from 0.99832\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0262 - accuracy: 0.9914\n","Epoch 277/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0471 - accuracy: 0.9829\n","Epoch 277: accuracy did not improve from 0.99832\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0469 - accuracy: 0.9829\n","Epoch 278/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0251 - accuracy: 0.9902\n","Epoch 278: accuracy did not improve from 0.99832\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0254 - accuracy: 0.9901\n","Epoch 279/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0182 - accuracy: 0.9919\n","Epoch 279: accuracy did not improve from 0.99832\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0182 - accuracy: 0.9919\n","Epoch 280/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0091 - accuracy: 0.9960\n","Epoch 280: accuracy did not improve from 0.99832\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0091 - accuracy: 0.9960\n","Epoch 281/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0103 - accuracy: 0.9956\n","Epoch 281: accuracy did not improve from 0.99832\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0102 - accuracy: 0.9957\n","Epoch 282/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0078 - accuracy: 0.9966\n","Epoch 282: accuracy did not improve from 0.99832\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0078 - accuracy: 0.9966\n","Epoch 283/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0280 - accuracy: 0.9893\n","Epoch 283: accuracy did not improve from 0.99832\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0280 - accuracy: 0.9893\n","Epoch 284/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0410 - accuracy: 0.9848\n","Epoch 284: accuracy did not improve from 0.99832\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0409 - accuracy: 0.9848\n","Epoch 285/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0124 - accuracy: 0.9946\n","Epoch 285: accuracy did not improve from 0.99832\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0123 - accuracy: 0.9947\n","Epoch 286/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0080 - accuracy: 0.9967\n","Epoch 286: accuracy did not improve from 0.99832\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0080 - accuracy: 0.9968\n","Epoch 287/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0051 - accuracy: 0.9979\n","Epoch 287: accuracy did not improve from 0.99832\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0052 - accuracy: 0.9978\n","Epoch 288/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0044 - accuracy: 0.9982\n","Epoch 288: accuracy did not improve from 0.99832\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0044 - accuracy: 0.9982\n","Epoch 289/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0042 - accuracy: 0.9985\n","Epoch 289: accuracy improved from 0.99832 to 0.99848, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0042 - accuracy: 0.9985\n","Epoch 290/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0549 - accuracy: 0.9831\n","Epoch 290: accuracy did not improve from 0.99848\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0549 - accuracy: 0.9831\n","Epoch 291/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0286 - accuracy: 0.9892\n","Epoch 291: accuracy did not improve from 0.99848\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0285 - accuracy: 0.9892\n","Epoch 292/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0142 - accuracy: 0.9940\n","Epoch 292: accuracy did not improve from 0.99848\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0142 - accuracy: 0.9940\n","Epoch 293/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0128 - accuracy: 0.9948\n","Epoch 293: accuracy did not improve from 0.99848\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0127 - accuracy: 0.9948\n","Epoch 294/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0169 - accuracy: 0.9926\n","Epoch 294: accuracy did not improve from 0.99848\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0167 - accuracy: 0.9927\n","Epoch 295/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0142 - accuracy: 0.9940\n","Epoch 295: accuracy did not improve from 0.99848\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0145 - accuracy: 0.9940\n","Epoch 296/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0183 - accuracy: 0.9926\n","Epoch 296: accuracy did not improve from 0.99848\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0185 - accuracy: 0.9925\n","Epoch 297/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0147 - accuracy: 0.9941\n","Epoch 297: accuracy did not improve from 0.99848\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0147 - accuracy: 0.9941\n","Epoch 298/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0161 - accuracy: 0.9932\n","Epoch 298: accuracy did not improve from 0.99848\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0161 - accuracy: 0.9932\n","Epoch 299/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0152 - accuracy: 0.9935\n","Epoch 299: accuracy did not improve from 0.99848\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0152 - accuracy: 0.9936\n","Epoch 300/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0177 - accuracy: 0.9928\n","Epoch 300: accuracy did not improve from 0.99848\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0181 - accuracy: 0.9927\n","Epoch 301/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0164 - accuracy: 0.9935\n","Epoch 301: accuracy did not improve from 0.99848\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0163 - accuracy: 0.9935\n","Epoch 302/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0087 - accuracy: 0.9963\n","Epoch 302: accuracy did not improve from 0.99848\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0087 - accuracy: 0.9963\n","Epoch 303/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0052 - accuracy: 0.9979\n","Epoch 303: accuracy did not improve from 0.99848\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0052 - accuracy: 0.9979\n","Epoch 304/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0049 - accuracy: 0.9980\n","Epoch 304: accuracy did not improve from 0.99848\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0050 - accuracy: 0.9980\n","Epoch 305/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0040 - accuracy: 0.9986\n","Epoch 305: accuracy improved from 0.99848 to 0.99858, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0040 - accuracy: 0.9986\n","Epoch 306/1000\n","380/387 [============================>.] - ETA: 0s - loss: 0.0035 - accuracy: 0.9986\n","Epoch 306: accuracy improved from 0.99858 to 0.99861, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0035 - accuracy: 0.9986\n","Epoch 307/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0088 - accuracy: 0.9967\n","Epoch 307: accuracy did not improve from 0.99861\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0088 - accuracy: 0.9967\n","Epoch 308/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0475 - accuracy: 0.9842\n","Epoch 308: accuracy did not improve from 0.99861\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0473 - accuracy: 0.9842\n","Epoch 309/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0373 - accuracy: 0.9854\n","Epoch 309: accuracy did not improve from 0.99861\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0372 - accuracy: 0.9854\n","Epoch 310/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0174 - accuracy: 0.9931\n","Epoch 310: accuracy did not improve from 0.99861\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0173 - accuracy: 0.9931\n","Epoch 311/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0243 - accuracy: 0.9909\n","Epoch 311: accuracy did not improve from 0.99861\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0243 - accuracy: 0.9909\n","Epoch 312/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0102 - accuracy: 0.9959\n","Epoch 312: accuracy did not improve from 0.99861\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0103 - accuracy: 0.9959\n","Epoch 313/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0101 - accuracy: 0.9954\n","Epoch 313: accuracy did not improve from 0.99861\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0101 - accuracy: 0.9955\n","Epoch 314/1000\n","380/387 [============================>.] - ETA: 0s - loss: 0.0062 - accuracy: 0.9975\n","Epoch 314: accuracy did not improve from 0.99861\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0063 - accuracy: 0.9975\n","Epoch 315/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0051 - accuracy: 0.9979\n","Epoch 315: accuracy did not improve from 0.99861\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0051 - accuracy: 0.9979\n","Epoch 316/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0056 - accuracy: 0.9978\n","Epoch 316: accuracy did not improve from 0.99861\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0055 - accuracy: 0.9978\n","Epoch 317/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0037 - accuracy: 0.9985\n","Epoch 317: accuracy did not improve from 0.99861\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0037 - accuracy: 0.9985\n","Epoch 318/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0071 - accuracy: 0.9974\n","Epoch 318: accuracy did not improve from 0.99861\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0070 - accuracy: 0.9974\n","Epoch 319/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0200 - accuracy: 0.9931\n","Epoch 319: accuracy did not improve from 0.99861\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0210 - accuracy: 0.9926\n","Epoch 320/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0605 - accuracy: 0.9797\n","Epoch 320: accuracy did not improve from 0.99861\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0601 - accuracy: 0.9798\n","Epoch 321/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0288 - accuracy: 0.9886\n","Epoch 321: accuracy did not improve from 0.99861\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0287 - accuracy: 0.9886\n","Epoch 322/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0175 - accuracy: 0.9928\n","Epoch 322: accuracy did not improve from 0.99861\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0175 - accuracy: 0.9928\n","Epoch 323/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0078 - accuracy: 0.9967\n","Epoch 323: accuracy did not improve from 0.99861\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0078 - accuracy: 0.9967\n","Epoch 324/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0073 - accuracy: 0.9969\n","Epoch 324: accuracy did not improve from 0.99861\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0072 - accuracy: 0.9969\n","Epoch 325/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0172 - accuracy: 0.9933\n","Epoch 325: accuracy did not improve from 0.99861\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0174 - accuracy: 0.9930\n","Epoch 326/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0266 - accuracy: 0.9904\n","Epoch 326: accuracy did not improve from 0.99861\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0267 - accuracy: 0.9904\n","Epoch 327/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0151 - accuracy: 0.9937\n","Epoch 327: accuracy did not improve from 0.99861\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0150 - accuracy: 0.9937\n","Epoch 328/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0092 - accuracy: 0.9960\n","Epoch 328: accuracy did not improve from 0.99861\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0091 - accuracy: 0.9960\n","Epoch 329/1000\n","380/387 [============================>.] - ETA: 0s - loss: 0.0064 - accuracy: 0.9973\n","Epoch 329: accuracy did not improve from 0.99861\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0066 - accuracy: 0.9974\n","Epoch 330/1000\n","380/387 [============================>.] - ETA: 0s - loss: 0.0075 - accuracy: 0.9968\n","Epoch 330: accuracy did not improve from 0.99861\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0075 - accuracy: 0.9968\n","Epoch 331/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0050 - accuracy: 0.9981\n","Epoch 331: accuracy did not improve from 0.99861\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0050 - accuracy: 0.9981\n","Epoch 332/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0029 - accuracy: 0.9989\n","Epoch 332: accuracy improved from 0.99861 to 0.99893, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0028 - accuracy: 0.9989\n","Epoch 333/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0128 - accuracy: 0.9953\n","Epoch 333: accuracy did not improve from 0.99893\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0129 - accuracy: 0.9952\n","Epoch 334/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0462 - accuracy: 0.9841\n","Epoch 334: accuracy did not improve from 0.99893\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0460 - accuracy: 0.9842\n","Epoch 335/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0255 - accuracy: 0.9905\n","Epoch 335: accuracy did not improve from 0.99893\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0254 - accuracy: 0.9905\n","Epoch 336/1000\n","380/387 [============================>.] - ETA: 0s - loss: 0.0101 - accuracy: 0.9961\n","Epoch 336: accuracy did not improve from 0.99893\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0101 - accuracy: 0.9961\n","Epoch 337/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0104 - accuracy: 0.9955\n","Epoch 337: accuracy did not improve from 0.99893\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0103 - accuracy: 0.9956\n","Epoch 338/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0095 - accuracy: 0.9964\n","Epoch 338: accuracy did not improve from 0.99893\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0094 - accuracy: 0.9964\n","Epoch 339/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0046 - accuracy: 0.9981\n","Epoch 339: accuracy did not improve from 0.99893\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0048 - accuracy: 0.9981\n","Epoch 340/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0043 - accuracy: 0.9983\n","Epoch 340: accuracy did not improve from 0.99893\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0045 - accuracy: 0.9983\n","Epoch 341/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0147 - accuracy: 0.9939\n","Epoch 341: accuracy did not improve from 0.99893\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0147 - accuracy: 0.9939\n","Epoch 342/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0290 - accuracy: 0.9895\n","Epoch 342: accuracy did not improve from 0.99893\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0288 - accuracy: 0.9896\n","Epoch 343/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0313 - accuracy: 0.9889\n","Epoch 343: accuracy did not improve from 0.99893\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0312 - accuracy: 0.9889\n","Epoch 344/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0136 - accuracy: 0.9946\n","Epoch 344: accuracy did not improve from 0.99893\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0136 - accuracy: 0.9946\n","Epoch 345/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0074 - accuracy: 0.9969\n","Epoch 345: accuracy did not improve from 0.99893\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0074 - accuracy: 0.9969\n","Epoch 346/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0041 - accuracy: 0.9983\n","Epoch 346: accuracy did not improve from 0.99893\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0042 - accuracy: 0.9983\n","Epoch 347/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0070 - accuracy: 0.9975\n","Epoch 347: accuracy did not improve from 0.99893\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0070 - accuracy: 0.9975\n","Epoch 348/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0269 - accuracy: 0.9898\n","Epoch 348: accuracy did not improve from 0.99893\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0266 - accuracy: 0.9899\n","Epoch 349/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0363 - accuracy: 0.9872\n","Epoch 349: accuracy did not improve from 0.99893\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0363 - accuracy: 0.9871\n","Epoch 350/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0255 - accuracy: 0.9904\n","Epoch 350: accuracy did not improve from 0.99893\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0254 - accuracy: 0.9904\n","Epoch 351/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0145 - accuracy: 0.9946\n","Epoch 351: accuracy did not improve from 0.99893\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0144 - accuracy: 0.9946\n","Epoch 352/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0085 - accuracy: 0.9964\n","Epoch 352: accuracy did not improve from 0.99893\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0085 - accuracy: 0.9964\n","Epoch 353/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0052 - accuracy: 0.9979\n","Epoch 353: accuracy did not improve from 0.99893\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0052 - accuracy: 0.9979\n","Epoch 354/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0041 - accuracy: 0.9983\n","Epoch 354: accuracy did not improve from 0.99893\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0041 - accuracy: 0.9983\n","Epoch 355/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0041 - accuracy: 0.9984\n","Epoch 355: accuracy did not improve from 0.99893\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0041 - accuracy: 0.9984\n","Epoch 356/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0029 - accuracy: 0.9990\n","Epoch 356: accuracy improved from 0.99893 to 0.99899, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0029 - accuracy: 0.9990\n","Epoch 357/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0026 - accuracy: 0.9992\n","Epoch 357: accuracy improved from 0.99899 to 0.99915, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0027 - accuracy: 0.9992\n","Epoch 358/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0054 - accuracy: 0.9981\n","Epoch 358: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0059 - accuracy: 0.9977\n","Epoch 359/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0609 - accuracy: 0.9813\n","Epoch 359: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0609 - accuracy: 0.9813\n","Epoch 360/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0295 - accuracy: 0.9885\n","Epoch 360: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0295 - accuracy: 0.9885\n","Epoch 361/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0185 - accuracy: 0.9927\n","Epoch 361: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0190 - accuracy: 0.9926\n","Epoch 362/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0164 - accuracy: 0.9935\n","Epoch 362: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0163 - accuracy: 0.9936\n","Epoch 363/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0071 - accuracy: 0.9969\n","Epoch 363: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0071 - accuracy: 0.9969\n","Epoch 364/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0051 - accuracy: 0.9978\n","Epoch 364: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0051 - accuracy: 0.9978\n","Epoch 365/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0032 - accuracy: 0.9988\n","Epoch 365: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0033 - accuracy: 0.9987\n","Epoch 366/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0041 - accuracy: 0.9986\n","Epoch 366: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0041 - accuracy: 0.9986\n","Epoch 367/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0030 - accuracy: 0.9989\n","Epoch 367: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0030 - accuracy: 0.9988\n","Epoch 368/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0049 - accuracy: 0.9982\n","Epoch 368: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0051 - accuracy: 0.9981\n","Epoch 369/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0465 - accuracy: 0.9856\n","Epoch 369: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0465 - accuracy: 0.9856\n","Epoch 370/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0307 - accuracy: 0.9889\n","Epoch 370: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0305 - accuracy: 0.9889\n","Epoch 371/1000\n","380/387 [============================>.] - ETA: 0s - loss: 0.0136 - accuracy: 0.9945\n","Epoch 371: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0134 - accuracy: 0.9946\n","Epoch 372/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0066 - accuracy: 0.9973\n","Epoch 372: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0065 - accuracy: 0.9973\n","Epoch 373/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0036 - accuracy: 0.9984\n","Epoch 373: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0036 - accuracy: 0.9984\n","Epoch 374/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0030 - accuracy: 0.9988\n","Epoch 374: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0032 - accuracy: 0.9987\n","Epoch 375/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0032 - accuracy: 0.9989\n","Epoch 375: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0031 - accuracy: 0.9989\n","Epoch 376/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0146 - accuracy: 0.9962\n","Epoch 376: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0147 - accuracy: 0.9961\n","Epoch 377/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0420 - accuracy: 0.9843\n","Epoch 377: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0418 - accuracy: 0.9844\n","Epoch 378/1000\n","380/387 [============================>.] - ETA: 0s - loss: 0.0187 - accuracy: 0.9927\n","Epoch 378: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0186 - accuracy: 0.9928\n","Epoch 379/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0075 - accuracy: 0.9971\n","Epoch 379: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0075 - accuracy: 0.9971\n","Epoch 380/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0049 - accuracy: 0.9980\n","Epoch 380: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0049 - accuracy: 0.9980\n","Epoch 381/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0032 - accuracy: 0.9986\n","Epoch 381: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0032 - accuracy: 0.9986\n","Epoch 382/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0024 - accuracy: 0.9990\n","Epoch 382: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0024 - accuracy: 0.9990\n","Epoch 383/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0028 - accuracy: 0.9988\n","Epoch 383: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0028 - accuracy: 0.9988\n","Epoch 384/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0080 - accuracy: 0.9972\n","Epoch 384: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0081 - accuracy: 0.9971\n","Epoch 385/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0588 - accuracy: 0.9818\n","Epoch 385: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0587 - accuracy: 0.9818\n","Epoch 386/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0275 - accuracy: 0.9896\n","Epoch 386: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0275 - accuracy: 0.9896\n","Epoch 387/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0185 - accuracy: 0.9931\n","Epoch 387: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0186 - accuracy: 0.9930\n","Epoch 388/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0111 - accuracy: 0.9961\n","Epoch 388: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0111 - accuracy: 0.9961\n","Epoch 389/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0062 - accuracy: 0.9974\n","Epoch 389: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0061 - accuracy: 0.9974\n","Epoch 390/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0038 - accuracy: 0.9984\n","Epoch 390: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0039 - accuracy: 0.9984\n","Epoch 391/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0029 - accuracy: 0.9988\n","Epoch 391: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0030 - accuracy: 0.9988\n","Epoch 392/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0030 - accuracy: 0.9989\n","Epoch 392: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0030 - accuracy: 0.9988\n","Epoch 393/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0029 - accuracy: 0.9989\n","Epoch 393: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0028 - accuracy: 0.9989\n","Epoch 394/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0102 - accuracy: 0.9960\n","Epoch 394: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0102 - accuracy: 0.9960\n","Epoch 395/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0352 - accuracy: 0.9871\n","Epoch 395: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0350 - accuracy: 0.9872\n","Epoch 396/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0275 - accuracy: 0.9901\n","Epoch 396: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0274 - accuracy: 0.9901\n","Epoch 397/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0321 - accuracy: 0.9887\n","Epoch 397: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0320 - accuracy: 0.9886\n","Epoch 398/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0143 - accuracy: 0.9942\n","Epoch 398: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0145 - accuracy: 0.9941\n","Epoch 399/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0081 - accuracy: 0.9967\n","Epoch 399: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0081 - accuracy: 0.9967\n","Epoch 400/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0045 - accuracy: 0.9983\n","Epoch 400: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0045 - accuracy: 0.9983\n","Epoch 401/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0040 - accuracy: 0.9985\n","Epoch 401: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0040 - accuracy: 0.9985\n","Epoch 402/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0033 - accuracy: 0.9987\n","Epoch 402: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0033 - accuracy: 0.9987\n","Epoch 403/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0028 - accuracy: 0.9991\n","Epoch 403: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0028 - accuracy: 0.9990\n","Epoch 404/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0032 - accuracy: 0.9986\n","Epoch 404: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0032 - accuracy: 0.9986\n","Epoch 405/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0024 - accuracy: 0.9991\n","Epoch 405: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0025 - accuracy: 0.9991\n","Epoch 406/1000\n","380/387 [============================>.] - ETA: 0s - loss: 0.0541 - accuracy: 0.9827\n","Epoch 406: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0535 - accuracy: 0.9829\n","Epoch 407/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0265 - accuracy: 0.9898\n","Epoch 407: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0264 - accuracy: 0.9898\n","Epoch 408/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0155 - accuracy: 0.9940\n","Epoch 408: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0155 - accuracy: 0.9940\n","Epoch 409/1000\n","380/387 [============================>.] - ETA: 0s - loss: 0.0127 - accuracy: 0.9946\n","Epoch 409: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0126 - accuracy: 0.9947\n","Epoch 410/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0072 - accuracy: 0.9969\n","Epoch 410: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0071 - accuracy: 0.9969\n","Epoch 411/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0054 - accuracy: 0.9978\n","Epoch 411: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0055 - accuracy: 0.9978\n","Epoch 412/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0049 - accuracy: 0.9981\n","Epoch 412: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0050 - accuracy: 0.9981\n","Epoch 413/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0029 - accuracy: 0.9990\n","Epoch 413: accuracy did not improve from 0.99915\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0029 - accuracy: 0.9990\n","Epoch 414/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0023 - accuracy: 0.9992\n","Epoch 414: accuracy improved from 0.99915 to 0.99925, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0023 - accuracy: 0.9993\n","Epoch 415/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0022 - accuracy: 0.9992\n","Epoch 415: accuracy did not improve from 0.99925\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0022 - accuracy: 0.9992\n","Epoch 416/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0141 - accuracy: 0.9955\n","Epoch 416: accuracy did not improve from 0.99925\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0142 - accuracy: 0.9955\n","Epoch 417/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0510 - accuracy: 0.9829\n","Epoch 417: accuracy did not improve from 0.99925\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0510 - accuracy: 0.9829\n","Epoch 418/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0271 - accuracy: 0.9897\n","Epoch 418: accuracy did not improve from 0.99925\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0271 - accuracy: 0.9897\n","Epoch 419/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0174 - accuracy: 0.9926\n","Epoch 419: accuracy did not improve from 0.99925\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0174 - accuracy: 0.9926\n","Epoch 420/1000\n","380/387 [============================>.] - ETA: 0s - loss: 0.0134 - accuracy: 0.9946\n","Epoch 420: accuracy did not improve from 0.99925\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0135 - accuracy: 0.9946\n","Epoch 421/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0075 - accuracy: 0.9969\n","Epoch 421: accuracy did not improve from 0.99925\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0075 - accuracy: 0.9969\n","Epoch 422/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0046 - accuracy: 0.9983\n","Epoch 422: accuracy did not improve from 0.99925\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0047 - accuracy: 0.9982\n","Epoch 423/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0066 - accuracy: 0.9975\n","Epoch 423: accuracy did not improve from 0.99925\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0066 - accuracy: 0.9975\n","Epoch 424/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0041 - accuracy: 0.9985\n","Epoch 424: accuracy did not improve from 0.99925\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0041 - accuracy: 0.9985\n","Epoch 425/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0098 - accuracy: 0.9961\n","Epoch 425: accuracy did not improve from 0.99925\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0100 - accuracy: 0.9960\n","Epoch 426/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0311 - accuracy: 0.9888\n","Epoch 426: accuracy did not improve from 0.99925\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0310 - accuracy: 0.9888\n","Epoch 427/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0207 - accuracy: 0.9922\n","Epoch 427: accuracy did not improve from 0.99925\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0207 - accuracy: 0.9922\n","Epoch 428/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0148 - accuracy: 0.9946\n","Epoch 428: accuracy did not improve from 0.99925\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0147 - accuracy: 0.9946\n","Epoch 429/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0069 - accuracy: 0.9973\n","Epoch 429: accuracy did not improve from 0.99925\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0068 - accuracy: 0.9973\n","Epoch 430/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0036 - accuracy: 0.9988\n","Epoch 430: accuracy did not improve from 0.99925\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0036 - accuracy: 0.9988\n","Epoch 431/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0033 - accuracy: 0.9986\n","Epoch 431: accuracy did not improve from 0.99925\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0033 - accuracy: 0.9986\n","Epoch 432/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0026 - accuracy: 0.9991\n","Epoch 432: accuracy did not improve from 0.99925\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0026 - accuracy: 0.9991\n","Epoch 433/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0020 - accuracy: 0.9994\n","Epoch 433: accuracy improved from 0.99925 to 0.99939, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0020 - accuracy: 0.9994\n","Epoch 434/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0024 - accuracy: 0.9991\n","Epoch 434: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0024 - accuracy: 0.9991\n","Epoch 435/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0541 - accuracy: 0.9832\n","Epoch 435: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0544 - accuracy: 0.9832\n","Epoch 436/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0270 - accuracy: 0.9893\n","Epoch 436: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0267 - accuracy: 0.9893\n","Epoch 437/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0127 - accuracy: 0.9947\n","Epoch 437: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0126 - accuracy: 0.9947\n","Epoch 438/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0075 - accuracy: 0.9967\n","Epoch 438: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0075 - accuracy: 0.9967\n","Epoch 439/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0041 - accuracy: 0.9982\n","Epoch 439: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0041 - accuracy: 0.9982\n","Epoch 440/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0027 - accuracy: 0.9990\n","Epoch 440: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0027 - accuracy: 0.9990\n","Epoch 441/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 0.9992\n","Epoch 441: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0021 - accuracy: 0.9993\n","Epoch 442/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 0.9993\n","Epoch 442: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0021 - accuracy: 0.9993\n","Epoch 443/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0179 - accuracy: 0.9937\n","Epoch 443: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0179 - accuracy: 0.9937\n","Epoch 444/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0174 - accuracy: 0.9932\n","Epoch 444: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0174 - accuracy: 0.9932\n","Epoch 445/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0202 - accuracy: 0.9926\n","Epoch 445: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0202 - accuracy: 0.9926\n","Epoch 446/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0129 - accuracy: 0.9949\n","Epoch 446: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0136 - accuracy: 0.9946\n","Epoch 447/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0104 - accuracy: 0.9960\n","Epoch 447: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0104 - accuracy: 0.9961\n","Epoch 448/1000\n","380/387 [============================>.] - ETA: 0s - loss: 0.0077 - accuracy: 0.9969\n","Epoch 448: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0076 - accuracy: 0.9969\n","Epoch 449/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0066 - accuracy: 0.9973\n","Epoch 449: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0066 - accuracy: 0.9973\n","Epoch 450/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0073 - accuracy: 0.9970\n","Epoch 450: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0075 - accuracy: 0.9970\n","Epoch 451/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0306 - accuracy: 0.9896\n","Epoch 451: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0306 - accuracy: 0.9896\n","Epoch 452/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0104 - accuracy: 0.9957\n","Epoch 452: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0103 - accuracy: 0.9957\n","Epoch 453/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0055 - accuracy: 0.9978\n","Epoch 453: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0055 - accuracy: 0.9978\n","Epoch 454/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0049 - accuracy: 0.9978\n","Epoch 454: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0049 - accuracy: 0.9978\n","Epoch 455/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0030 - accuracy: 0.9990\n","Epoch 455: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0030 - accuracy: 0.9989\n","Epoch 456/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0060 - accuracy: 0.9982\n","Epoch 456: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0060 - accuracy: 0.9982\n","Epoch 457/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0209 - accuracy: 0.9927\n","Epoch 457: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0207 - accuracy: 0.9927\n","Epoch 458/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0152 - accuracy: 0.9941\n","Epoch 458: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0152 - accuracy: 0.9941\n","Epoch 459/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0161 - accuracy: 0.9941\n","Epoch 459: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0162 - accuracy: 0.9942\n","Epoch 460/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0187 - accuracy: 0.9931\n","Epoch 460: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0187 - accuracy: 0.9931\n","Epoch 461/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0081 - accuracy: 0.9967\n","Epoch 461: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0081 - accuracy: 0.9967\n","Epoch 462/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0054 - accuracy: 0.9979\n","Epoch 462: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0053 - accuracy: 0.9980\n","Epoch 463/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0039 - accuracy: 0.9986\n","Epoch 463: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0038 - accuracy: 0.9986\n","Epoch 464/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0025 - accuracy: 0.9991\n","Epoch 464: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0024 - accuracy: 0.9991\n","Epoch 465/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 0.9992\n","Epoch 465: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0021 - accuracy: 0.9992\n","Epoch 466/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0209 - accuracy: 0.9929\n","Epoch 466: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0209 - accuracy: 0.9929\n","Epoch 467/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0361 - accuracy: 0.9874\n","Epoch 467: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0366 - accuracy: 0.9874\n","Epoch 468/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0149 - accuracy: 0.9936\n","Epoch 468: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0149 - accuracy: 0.9937\n","Epoch 469/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0129 - accuracy: 0.9950\n","Epoch 469: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0129 - accuracy: 0.9950\n","Epoch 470/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0070 - accuracy: 0.9974\n","Epoch 470: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0069 - accuracy: 0.9975\n","Epoch 471/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0040 - accuracy: 0.9984\n","Epoch 471: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0039 - accuracy: 0.9984\n","Epoch 472/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0026 - accuracy: 0.9992\n","Epoch 472: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0026 - accuracy: 0.9992\n","Epoch 473/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0028 - accuracy: 0.9991\n","Epoch 473: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0028 - accuracy: 0.9991\n","Epoch 474/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0024 - accuracy: 0.9992\n","Epoch 474: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0024 - accuracy: 0.9992\n","Epoch 475/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0032 - accuracy: 0.9989\n","Epoch 475: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0032 - accuracy: 0.9989\n","Epoch 476/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0342 - accuracy: 0.9891\n","Epoch 476: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0342 - accuracy: 0.9891\n","Epoch 477/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0321 - accuracy: 0.9897\n","Epoch 477: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0320 - accuracy: 0.9897\n","Epoch 478/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0105 - accuracy: 0.9958\n","Epoch 478: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0105 - accuracy: 0.9958\n","Epoch 479/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0053 - accuracy: 0.9981\n","Epoch 479: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0053 - accuracy: 0.9981\n","Epoch 480/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0034 - accuracy: 0.9987\n","Epoch 480: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0033 - accuracy: 0.9987\n","Epoch 481/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0026 - accuracy: 0.9991\n","Epoch 481: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0027 - accuracy: 0.9991\n","Epoch 482/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0024 - accuracy: 0.9993\n","Epoch 482: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0024 - accuracy: 0.9993\n","Epoch 483/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0084 - accuracy: 0.9970\n","Epoch 483: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0085 - accuracy: 0.9968\n","Epoch 484/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0265 - accuracy: 0.9909\n","Epoch 484: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0265 - accuracy: 0.9909\n","Epoch 485/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0261 - accuracy: 0.9903\n","Epoch 485: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0260 - accuracy: 0.9904\n","Epoch 486/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0121 - accuracy: 0.9951\n","Epoch 486: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0121 - accuracy: 0.9951\n","Epoch 487/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0083 - accuracy: 0.9967\n","Epoch 487: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0083 - accuracy: 0.9967\n","Epoch 488/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0091 - accuracy: 0.9969\n","Epoch 488: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0093 - accuracy: 0.9969\n","Epoch 489/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0064 - accuracy: 0.9973\n","Epoch 489: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0064 - accuracy: 0.9973\n","Epoch 490/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0113 - accuracy: 0.9964\n","Epoch 490: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0115 - accuracy: 0.9964\n","Epoch 491/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0068 - accuracy: 0.9974\n","Epoch 491: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0068 - accuracy: 0.9974\n","Epoch 492/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0035 - accuracy: 0.9986\n","Epoch 492: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0035 - accuracy: 0.9986\n","Epoch 493/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0028 - accuracy: 0.9991\n","Epoch 493: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0028 - accuracy: 0.9991\n","Epoch 494/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0033 - accuracy: 0.9987\n","Epoch 494: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0033 - accuracy: 0.9987\n","Epoch 495/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0103 - accuracy: 0.9968\n","Epoch 495: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0113 - accuracy: 0.9965\n","Epoch 496/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0428 - accuracy: 0.9858\n","Epoch 496: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0433 - accuracy: 0.9858\n","Epoch 497/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0100 - accuracy: 0.9957\n","Epoch 497: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0102 - accuracy: 0.9957\n","Epoch 498/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0069 - accuracy: 0.9971\n","Epoch 498: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0069 - accuracy: 0.9970\n","Epoch 499/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0047 - accuracy: 0.9984\n","Epoch 499: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0047 - accuracy: 0.9984\n","Epoch 500/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 0.9990\n","Epoch 500: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0031 - accuracy: 0.9990\n","Epoch 501/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0024 - accuracy: 0.9993\n","Epoch 501: accuracy did not improve from 0.99939\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0024 - accuracy: 0.9993\n","Epoch 502/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0019 - accuracy: 0.9994\n","Epoch 502: accuracy improved from 0.99939 to 0.99941, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0019 - accuracy: 0.9994\n","Epoch 503/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0155 - accuracy: 0.9954\n","Epoch 503: accuracy did not improve from 0.99941\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0155 - accuracy: 0.9954\n","Epoch 504/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0407 - accuracy: 0.9877\n","Epoch 504: accuracy did not improve from 0.99941\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0418 - accuracy: 0.9877\n","Epoch 505/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0251 - accuracy: 0.9901\n","Epoch 505: accuracy did not improve from 0.99941\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0250 - accuracy: 0.9901\n","Epoch 506/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0076 - accuracy: 0.9972\n","Epoch 506: accuracy did not improve from 0.99941\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0076 - accuracy: 0.9971\n","Epoch 507/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0043 - accuracy: 0.9983\n","Epoch 507: accuracy did not improve from 0.99941\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0042 - accuracy: 0.9983\n","Epoch 508/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0028 - accuracy: 0.9991\n","Epoch 508: accuracy did not improve from 0.99941\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0028 - accuracy: 0.9991\n","Epoch 509/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0022 - accuracy: 0.9992\n","Epoch 509: accuracy did not improve from 0.99941\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0023 - accuracy: 0.9992\n","Epoch 510/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 0.9993\n","Epoch 510: accuracy did not improve from 0.99941\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0021 - accuracy: 0.9993\n","Epoch 511/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0040 - accuracy: 0.9986\n","Epoch 511: accuracy did not improve from 0.99941\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0040 - accuracy: 0.9986\n","Epoch 512/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0093 - accuracy: 0.9964\n","Epoch 512: accuracy did not improve from 0.99941\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0093 - accuracy: 0.9964\n","Epoch 513/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0279 - accuracy: 0.9912\n","Epoch 513: accuracy did not improve from 0.99941\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0282 - accuracy: 0.9912\n","Epoch 514/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0246 - accuracy: 0.9912\n","Epoch 514: accuracy did not improve from 0.99941\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0245 - accuracy: 0.9912\n","Epoch 515/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0182 - accuracy: 0.9934\n","Epoch 515: accuracy did not improve from 0.99941\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0182 - accuracy: 0.9934\n","Epoch 516/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0129 - accuracy: 0.9953\n","Epoch 516: accuracy did not improve from 0.99941\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0128 - accuracy: 0.9953\n","Epoch 517/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0055 - accuracy: 0.9982\n","Epoch 517: accuracy did not improve from 0.99941\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0055 - accuracy: 0.9982\n","Epoch 518/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0048 - accuracy: 0.9983\n","Epoch 518: accuracy did not improve from 0.99941\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0048 - accuracy: 0.9983\n","Epoch 519/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0029 - accuracy: 0.9991\n","Epoch 519: accuracy did not improve from 0.99941\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0029 - accuracy: 0.9991\n","Epoch 520/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0023 - accuracy: 0.9993\n","Epoch 520: accuracy did not improve from 0.99941\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0024 - accuracy: 0.9993\n","Epoch 521/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 0.9994\n","Epoch 521: accuracy did not improve from 0.99941\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0021 - accuracy: 0.9994\n","Epoch 522/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 0.9993\n","Epoch 522: accuracy did not improve from 0.99941\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0027 - accuracy: 0.9993\n","Epoch 523/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0217 - accuracy: 0.9938\n","Epoch 523: accuracy did not improve from 0.99941\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0224 - accuracy: 0.9936\n","Epoch 524/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0428 - accuracy: 0.9874\n","Epoch 524: accuracy did not improve from 0.99941\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0424 - accuracy: 0.9875\n","Epoch 525/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0129 - accuracy: 0.9949\n","Epoch 525: accuracy did not improve from 0.99941\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0128 - accuracy: 0.9949\n","Epoch 526/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0073 - accuracy: 0.9972\n","Epoch 526: accuracy did not improve from 0.99941\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0072 - accuracy: 0.9972\n","Epoch 527/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0057 - accuracy: 0.9980\n","Epoch 527: accuracy did not improve from 0.99941\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0057 - accuracy: 0.9980\n","Epoch 528/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0043 - accuracy: 0.9985\n","Epoch 528: accuracy did not improve from 0.99941\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0043 - accuracy: 0.9985\n","Epoch 529/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0031 - accuracy: 0.9989\n","Epoch 529: accuracy did not improve from 0.99941\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0031 - accuracy: 0.9989\n","Epoch 530/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 0.9994\n","Epoch 530: accuracy did not improve from 0.99941\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0022 - accuracy: 0.9994\n","Epoch 531/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0028 - accuracy: 0.9990\n","Epoch 531: accuracy did not improve from 0.99941\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0028 - accuracy: 0.9990\n","Epoch 532/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0019 - accuracy: 0.9995\n","Epoch 532: accuracy improved from 0.99941 to 0.99949, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0019 - accuracy: 0.9995\n","Epoch 533/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0037 - accuracy: 0.9988\n","Epoch 533: accuracy did not improve from 0.99949\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0041 - accuracy: 0.9986\n","Epoch 534/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0447 - accuracy: 0.9872\n","Epoch 534: accuracy did not improve from 0.99949\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0448 - accuracy: 0.9870\n","Epoch 535/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0189 - accuracy: 0.9929\n","Epoch 535: accuracy did not improve from 0.99949\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0197 - accuracy: 0.9928\n","Epoch 536/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0145 - accuracy: 0.9945\n","Epoch 536: accuracy did not improve from 0.99949\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0145 - accuracy: 0.9945\n","Epoch 537/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0056 - accuracy: 0.9980\n","Epoch 537: accuracy did not improve from 0.99949\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0056 - accuracy: 0.9980\n","Epoch 538/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0034 - accuracy: 0.9988\n","Epoch 538: accuracy did not improve from 0.99949\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0034 - accuracy: 0.9988\n","Epoch 539/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0025 - accuracy: 0.9991\n","Epoch 539: accuracy did not improve from 0.99949\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0025 - accuracy: 0.9991\n","Epoch 540/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0022 - accuracy: 0.9993\n","Epoch 540: accuracy did not improve from 0.99949\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0022 - accuracy: 0.9993\n","Epoch 541/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0019 - accuracy: 0.9994\n","Epoch 541: accuracy did not improve from 0.99949\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0019 - accuracy: 0.9994\n","Epoch 542/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0030 - accuracy: 0.9990\n","Epoch 542: accuracy did not improve from 0.99949\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0030 - accuracy: 0.9990\n","Epoch 543/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0158 - accuracy: 0.9949\n","Epoch 543: accuracy did not improve from 0.99949\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0159 - accuracy: 0.9949\n","Epoch 544/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0375 - accuracy: 0.9877\n","Epoch 544: accuracy did not improve from 0.99949\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0373 - accuracy: 0.9878\n","Epoch 545/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0127 - accuracy: 0.9950\n","Epoch 545: accuracy did not improve from 0.99949\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0127 - accuracy: 0.9950\n","Epoch 546/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0136 - accuracy: 0.9948\n","Epoch 546: accuracy did not improve from 0.99949\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0137 - accuracy: 0.9947\n","Epoch 547/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0079 - accuracy: 0.9969\n","Epoch 547: accuracy did not improve from 0.99949\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0079 - accuracy: 0.9969\n","Epoch 548/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0040 - accuracy: 0.9986\n","Epoch 548: accuracy did not improve from 0.99949\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0040 - accuracy: 0.9986\n","Epoch 549/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0024 - accuracy: 0.9991\n","Epoch 549: accuracy did not improve from 0.99949\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0024 - accuracy: 0.9991\n","Epoch 550/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0020 - accuracy: 0.9993\n","Epoch 550: accuracy did not improve from 0.99949\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0020 - accuracy: 0.9993\n","Epoch 551/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 0.9992\n","Epoch 551: accuracy did not improve from 0.99949\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0021 - accuracy: 0.9992\n","Epoch 552/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0018 - accuracy: 0.9995\n","Epoch 552: accuracy did not improve from 0.99949\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0018 - accuracy: 0.9995\n","Epoch 553/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0129 - accuracy: 0.9964\n","Epoch 553: accuracy did not improve from 0.99949\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0129 - accuracy: 0.9964\n","Epoch 554/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0663 - accuracy: 0.9821\n","Epoch 554: accuracy did not improve from 0.99949\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0662 - accuracy: 0.9821\n","Epoch 555/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0157 - accuracy: 0.9934\n","Epoch 555: accuracy did not improve from 0.99949\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0156 - accuracy: 0.9934\n","Epoch 556/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0078 - accuracy: 0.9968\n","Epoch 556: accuracy did not improve from 0.99949\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0077 - accuracy: 0.9968\n","Epoch 557/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0051 - accuracy: 0.9978\n","Epoch 557: accuracy did not improve from 0.99949\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0051 - accuracy: 0.9978\n","Epoch 558/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0032 - accuracy: 0.9989\n","Epoch 558: accuracy did not improve from 0.99949\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0033 - accuracy: 0.9989\n","Epoch 559/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0023 - accuracy: 0.9991\n","Epoch 559: accuracy did not improve from 0.99949\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0023 - accuracy: 0.9992\n","Epoch 560/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0019 - accuracy: 0.9993\n","Epoch 560: accuracy did not improve from 0.99949\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0019 - accuracy: 0.9993\n","Epoch 561/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 0.9994\n","Epoch 561: accuracy did not improve from 0.99949\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0018 - accuracy: 0.9994\n","Epoch 562/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0019 - accuracy: 0.9994\n","Epoch 562: accuracy did not improve from 0.99949\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0020 - accuracy: 0.9993\n","Epoch 563/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0232 - accuracy: 0.9932\n","Epoch 563: accuracy did not improve from 0.99949\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0231 - accuracy: 0.9932\n","Epoch 564/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0406 - accuracy: 0.9857\n","Epoch 564: accuracy did not improve from 0.99949\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0408 - accuracy: 0.9857\n","Epoch 565/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0141 - accuracy: 0.9945\n","Epoch 565: accuracy did not improve from 0.99949\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0141 - accuracy: 0.9946\n","Epoch 566/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0055 - accuracy: 0.9981\n","Epoch 566: accuracy did not improve from 0.99949\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0055 - accuracy: 0.9981\n","Epoch 567/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0034 - accuracy: 0.9989\n","Epoch 567: accuracy did not improve from 0.99949\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0034 - accuracy: 0.9989\n","Epoch 568/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0026 - accuracy: 0.9991\n","Epoch 568: accuracy did not improve from 0.99949\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0026 - accuracy: 0.9991\n","Epoch 569/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 0.9993\n","Epoch 569: accuracy did not improve from 0.99949\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0021 - accuracy: 0.9993\n","Epoch 570/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0019 - accuracy: 0.9994\n","Epoch 570: accuracy did not improve from 0.99949\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0019 - accuracy: 0.9994\n","Epoch 571/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0017 - accuracy: 0.9996\n","Epoch 571: accuracy improved from 0.99949 to 0.99956, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0017 - accuracy: 0.9996\n","Epoch 572/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0024 - accuracy: 0.9993\n","Epoch 572: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0024 - accuracy: 0.9993\n","Epoch 573/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0090 - accuracy: 0.9973\n","Epoch 573: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0090 - accuracy: 0.9973\n","Epoch 574/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0450 - accuracy: 0.9863\n","Epoch 574: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0446 - accuracy: 0.9864\n","Epoch 575/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0186 - accuracy: 0.9929\n","Epoch 575: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0186 - accuracy: 0.9928\n","Epoch 576/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0122 - accuracy: 0.9954\n","Epoch 576: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0122 - accuracy: 0.9954\n","Epoch 577/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0061 - accuracy: 0.9976\n","Epoch 577: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0061 - accuracy: 0.9976\n","Epoch 578/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0121 - accuracy: 0.9956\n","Epoch 578: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0121 - accuracy: 0.9956\n","Epoch 579/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0121 - accuracy: 0.9952\n","Epoch 579: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0121 - accuracy: 0.9952\n","Epoch 580/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0065 - accuracy: 0.9971\n","Epoch 580: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0065 - accuracy: 0.9971\n","Epoch 581/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0068 - accuracy: 0.9971\n","Epoch 581: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0068 - accuracy: 0.9971\n","Epoch 582/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0061 - accuracy: 0.9978\n","Epoch 582: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0061 - accuracy: 0.9978\n","Epoch 583/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0037 - accuracy: 0.9986\n","Epoch 583: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0037 - accuracy: 0.9986\n","Epoch 584/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0024 - accuracy: 0.9991\n","Epoch 584: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0024 - accuracy: 0.9992\n","Epoch 585/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0023 - accuracy: 0.9992\n","Epoch 585: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0023 - accuracy: 0.9992\n","Epoch 586/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0019 - accuracy: 0.9993\n","Epoch 586: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0020 - accuracy: 0.9993\n","Epoch 587/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0019 - accuracy: 0.9994\n","Epoch 587: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0019 - accuracy: 0.9994\n","Epoch 588/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0361 - accuracy: 0.9886\n","Epoch 588: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0361 - accuracy: 0.9886\n","Epoch 589/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0231 - accuracy: 0.9916\n","Epoch 589: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0231 - accuracy: 0.9916\n","Epoch 590/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0102 - accuracy: 0.9959\n","Epoch 590: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0104 - accuracy: 0.9958\n","Epoch 591/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0038 - accuracy: 0.9986\n","Epoch 591: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0038 - accuracy: 0.9986\n","Epoch 592/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0024 - accuracy: 0.9992\n","Epoch 592: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0024 - accuracy: 0.9992\n","Epoch 593/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 0.9993\n","Epoch 593: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0020 - accuracy: 0.9993\n","Epoch 594/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0019 - accuracy: 0.9994\n","Epoch 594: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0019 - accuracy: 0.9994\n","Epoch 595/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0017 - accuracy: 0.9994\n","Epoch 595: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0017 - accuracy: 0.9995\n","Epoch 596/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0017 - accuracy: 0.9993\n","Epoch 596: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0017 - accuracy: 0.9993\n","Epoch 597/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0237 - accuracy: 0.9924\n","Epoch 597: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0236 - accuracy: 0.9924\n","Epoch 598/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0315 - accuracy: 0.9900\n","Epoch 598: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0334 - accuracy: 0.9899\n","Epoch 599/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0198 - accuracy: 0.9918\n","Epoch 599: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0198 - accuracy: 0.9918\n","Epoch 600/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0100 - accuracy: 0.9957\n","Epoch 600: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0099 - accuracy: 0.9958\n","Epoch 601/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0065 - accuracy: 0.9973\n","Epoch 601: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0065 - accuracy: 0.9973\n","Epoch 602/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0035 - accuracy: 0.9986\n","Epoch 602: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0035 - accuracy: 0.9986\n","Epoch 603/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0030 - accuracy: 0.9987\n","Epoch 603: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0030 - accuracy: 0.9987\n","Epoch 604/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 0.9993\n","Epoch 604: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0021 - accuracy: 0.9993\n","Epoch 605/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0017 - accuracy: 0.9995\n","Epoch 605: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0016 - accuracy: 0.9995\n","Epoch 606/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0017 - accuracy: 0.9995\n","Epoch 606: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0017 - accuracy: 0.9995\n","Epoch 607/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0029 - accuracy: 0.9989\n","Epoch 607: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0028 - accuracy: 0.9989\n","Epoch 608/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0319 - accuracy: 0.9916\n","Epoch 608: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0317 - accuracy: 0.9916\n","Epoch 609/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0244 - accuracy: 0.9912\n","Epoch 609: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0244 - accuracy: 0.9912\n","Epoch 610/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0112 - accuracy: 0.9955\n","Epoch 610: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0112 - accuracy: 0.9954\n","Epoch 611/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0048 - accuracy: 0.9983\n","Epoch 611: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0048 - accuracy: 0.9983\n","Epoch 612/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0028 - accuracy: 0.9990\n","Epoch 612: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0028 - accuracy: 0.9990\n","Epoch 613/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0022 - accuracy: 0.9993\n","Epoch 613: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0022 - accuracy: 0.9993\n","Epoch 614/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0019 - accuracy: 0.9994\n","Epoch 614: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0019 - accuracy: 0.9994\n","Epoch 615/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0016 - accuracy: 0.9996\n","Epoch 615: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0016 - accuracy: 0.9996\n","Epoch 616/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 0.9996\n","Epoch 616: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0015 - accuracy: 0.9996\n","Epoch 617/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0415 - accuracy: 0.9877\n","Epoch 617: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0415 - accuracy: 0.9877\n","Epoch 618/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0302 - accuracy: 0.9903\n","Epoch 618: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0302 - accuracy: 0.9902\n","Epoch 619/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0165 - accuracy: 0.9935\n","Epoch 619: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0165 - accuracy: 0.9935\n","Epoch 620/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0072 - accuracy: 0.9970\n","Epoch 620: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0072 - accuracy: 0.9970\n","Epoch 621/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0040 - accuracy: 0.9984\n","Epoch 621: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0040 - accuracy: 0.9984\n","Epoch 622/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0028 - accuracy: 0.9991\n","Epoch 622: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0028 - accuracy: 0.9991\n","Epoch 623/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 0.9993\n","Epoch 623: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0021 - accuracy: 0.9993\n","Epoch 624/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 0.9995\n","Epoch 624: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0017 - accuracy: 0.9995\n","Epoch 625/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 0.9995\n","Epoch 625: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0015 - accuracy: 0.9995\n","Epoch 626/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0018 - accuracy: 0.9995\n","Epoch 626: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0017 - accuracy: 0.9995\n","Epoch 627/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0026 - accuracy: 0.9992\n","Epoch 627: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0025 - accuracy: 0.9992\n","Epoch 628/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0130 - accuracy: 0.9965\n","Epoch 628: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0130 - accuracy: 0.9965\n","Epoch 629/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0511 - accuracy: 0.9845\n","Epoch 629: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0518 - accuracy: 0.9845\n","Epoch 630/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0128 - accuracy: 0.9951\n","Epoch 630: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0128 - accuracy: 0.9950\n","Epoch 631/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0066 - accuracy: 0.9975\n","Epoch 631: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0066 - accuracy: 0.9975\n","Epoch 632/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0033 - accuracy: 0.9989\n","Epoch 632: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0033 - accuracy: 0.9989\n","Epoch 633/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0024 - accuracy: 0.9993\n","Epoch 633: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0024 - accuracy: 0.9993\n","Epoch 634/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0019 - accuracy: 0.9993\n","Epoch 634: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0019 - accuracy: 0.9993\n","Epoch 635/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0018 - accuracy: 0.9995\n","Epoch 635: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0018 - accuracy: 0.9995\n","Epoch 636/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0016 - accuracy: 0.9995\n","Epoch 636: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0016 - accuracy: 0.9995\n","Epoch 637/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0018 - accuracy: 0.9994\n","Epoch 637: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0018 - accuracy: 0.9994\n","Epoch 638/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0252 - accuracy: 0.9912\n","Epoch 638: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0253 - accuracy: 0.9912\n","Epoch 639/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0347 - accuracy: 0.9883\n","Epoch 639: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0346 - accuracy: 0.9883\n","Epoch 640/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0136 - accuracy: 0.9944\n","Epoch 640: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 7ms/step - loss: 0.0139 - accuracy: 0.9942\n","Epoch 641/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0095 - accuracy: 0.9964\n","Epoch 641: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0101 - accuracy: 0.9964\n","Epoch 642/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0068 - accuracy: 0.9974\n","Epoch 642: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0068 - accuracy: 0.9974\n","Epoch 643/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0036 - accuracy: 0.9987\n","Epoch 643: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0036 - accuracy: 0.9987\n","Epoch 644/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0025 - accuracy: 0.9991\n","Epoch 644: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0025 - accuracy: 0.9992\n","Epoch 645/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0019 - accuracy: 0.9993\n","Epoch 645: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0019 - accuracy: 0.9993\n","Epoch 646/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0018 - accuracy: 0.9995\n","Epoch 646: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0018 - accuracy: 0.9995\n","Epoch 647/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0100 - accuracy: 0.9964\n","Epoch 647: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0100 - accuracy: 0.9964\n","Epoch 648/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0241 - accuracy: 0.9917\n","Epoch 648: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0241 - accuracy: 0.9917\n","Epoch 649/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0118 - accuracy: 0.9953\n","Epoch 649: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0118 - accuracy: 0.9953\n","Epoch 650/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0094 - accuracy: 0.9963\n","Epoch 650: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0095 - accuracy: 0.9963\n","Epoch 651/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0051 - accuracy: 0.9982\n","Epoch 651: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0051 - accuracy: 0.9982\n","Epoch 652/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0031 - accuracy: 0.9989\n","Epoch 652: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0031 - accuracy: 0.9989\n","Epoch 653/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0022 - accuracy: 0.9994\n","Epoch 653: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0022 - accuracy: 0.9994\n","Epoch 654/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0019 - accuracy: 0.9994\n","Epoch 654: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0019 - accuracy: 0.9994\n","Epoch 655/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0017 - accuracy: 0.9995\n","Epoch 655: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0017 - accuracy: 0.9995\n","Epoch 656/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0016 - accuracy: 0.9996\n","Epoch 656: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0016 - accuracy: 0.9996\n","Epoch 657/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0325 - accuracy: 0.9903\n","Epoch 657: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0329 - accuracy: 0.9903\n","Epoch 658/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0344 - accuracy: 0.9877\n","Epoch 658: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0344 - accuracy: 0.9877\n","Epoch 659/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0127 - accuracy: 0.9948\n","Epoch 659: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0126 - accuracy: 0.9948\n","Epoch 660/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0098 - accuracy: 0.9965\n","Epoch 660: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0097 - accuracy: 0.9965\n","Epoch 661/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0043 - accuracy: 0.9983\n","Epoch 661: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0043 - accuracy: 0.9983\n","Epoch 662/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0024 - accuracy: 0.9991\n","Epoch 662: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0024 - accuracy: 0.9992\n","Epoch 663/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 0.9994\n","Epoch 663: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0020 - accuracy: 0.9994\n","Epoch 664/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0017 - accuracy: 0.9994\n","Epoch 664: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0017 - accuracy: 0.9994\n","Epoch 665/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0017 - accuracy: 0.9994\n","Epoch 665: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0017 - accuracy: 0.9994\n","Epoch 666/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0016 - accuracy: 0.9994\n","Epoch 666: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0016 - accuracy: 0.9994\n","Epoch 667/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0017 - accuracy: 0.9995\n","Epoch 667: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0017 - accuracy: 0.9994\n","Epoch 668/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0397 - accuracy: 0.9883\n","Epoch 668: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0395 - accuracy: 0.9884\n","Epoch 669/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0301 - accuracy: 0.9901\n","Epoch 669: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0301 - accuracy: 0.9902\n","Epoch 670/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0160 - accuracy: 0.9937\n","Epoch 670: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0159 - accuracy: 0.9937\n","Epoch 671/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0062 - accuracy: 0.9976\n","Epoch 671: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0062 - accuracy: 0.9976\n","Epoch 672/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0032 - accuracy: 0.9988\n","Epoch 672: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0032 - accuracy: 0.9987\n","Epoch 673/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0022 - accuracy: 0.9992\n","Epoch 673: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0022 - accuracy: 0.9992\n","Epoch 674/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 0.9994\n","Epoch 674: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0018 - accuracy: 0.9994\n","Epoch 675/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 0.9995\n","Epoch 675: accuracy did not improve from 0.99956\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0016 - accuracy: 0.9995\n","Epoch 676/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 0.9996\n","Epoch 676: accuracy improved from 0.99956 to 0.99962, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0015 - accuracy: 0.9996\n","Epoch 677/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0023 - accuracy: 0.9991\n","Epoch 677: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0023 - accuracy: 0.9992\n","Epoch 678/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0162 - accuracy: 0.9955\n","Epoch 678: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0163 - accuracy: 0.9954\n","Epoch 679/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0244 - accuracy: 0.9913\n","Epoch 679: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0241 - accuracy: 0.9914\n","Epoch 680/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0095 - accuracy: 0.9960\n","Epoch 680: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0096 - accuracy: 0.9959\n","Epoch 681/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0058 - accuracy: 0.9978\n","Epoch 681: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0058 - accuracy: 0.9978\n","Epoch 682/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0179 - accuracy: 0.9937\n","Epoch 682: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0179 - accuracy: 0.9937\n","Epoch 683/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0122 - accuracy: 0.9951\n","Epoch 683: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0128 - accuracy: 0.9951\n","Epoch 684/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0082 - accuracy: 0.9964\n","Epoch 684: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0082 - accuracy: 0.9964\n","Epoch 685/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0038 - accuracy: 0.9984\n","Epoch 685: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0038 - accuracy: 0.9984\n","Epoch 686/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0023 - accuracy: 0.9991\n","Epoch 686: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0022 - accuracy: 0.9992\n","Epoch 687/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 0.9994\n","Epoch 687: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0019 - accuracy: 0.9994\n","Epoch 688/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 0.9994\n","Epoch 688: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0018 - accuracy: 0.9994\n","Epoch 689/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 0.9995\n","Epoch 689: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0015 - accuracy: 0.9995\n","Epoch 690/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 0.9996\n","Epoch 690: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0015 - accuracy: 0.9996\n","Epoch 691/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0022 - accuracy: 0.9994\n","Epoch 691: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0022 - accuracy: 0.9994\n","Epoch 692/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0115 - accuracy: 0.9964\n","Epoch 692: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0115 - accuracy: 0.9964\n","Epoch 693/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0363 - accuracy: 0.9877\n","Epoch 693: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0361 - accuracy: 0.9877\n","Epoch 694/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0178 - accuracy: 0.9943\n","Epoch 694: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0177 - accuracy: 0.9943\n","Epoch 695/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0053 - accuracy: 0.9978\n","Epoch 695: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0053 - accuracy: 0.9978\n","Epoch 696/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0030 - accuracy: 0.9988\n","Epoch 696: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0030 - accuracy: 0.9988\n","Epoch 697/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 0.9992\n","Epoch 697: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0021 - accuracy: 0.9992\n","Epoch 698/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0017 - accuracy: 0.9994\n","Epoch 698: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0017 - accuracy: 0.9994\n","Epoch 699/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0019 - accuracy: 0.9993\n","Epoch 699: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0018 - accuracy: 0.9993\n","Epoch 700/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0022 - accuracy: 0.9993\n","Epoch 700: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0021 - accuracy: 0.9993\n","Epoch 701/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0268 - accuracy: 0.9924\n","Epoch 701: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0271 - accuracy: 0.9922\n","Epoch 702/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0317 - accuracy: 0.9894\n","Epoch 702: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0314 - accuracy: 0.9894\n","Epoch 703/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0083 - accuracy: 0.9967\n","Epoch 703: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0082 - accuracy: 0.9967\n","Epoch 704/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0073 - accuracy: 0.9972\n","Epoch 704: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0073 - accuracy: 0.9972\n","Epoch 705/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0050 - accuracy: 0.9981\n","Epoch 705: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0050 - accuracy: 0.9981\n","Epoch 706/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0031 - accuracy: 0.9988\n","Epoch 706: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0031 - accuracy: 0.9987\n","Epoch 707/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 0.9993\n","Epoch 707: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0020 - accuracy: 0.9993\n","Epoch 708/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0019 - accuracy: 0.9994\n","Epoch 708: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0020 - accuracy: 0.9993\n","Epoch 709/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0035 - accuracy: 0.9988\n","Epoch 709: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0035 - accuracy: 0.9988\n","Epoch 710/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0257 - accuracy: 0.9914\n","Epoch 710: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0256 - accuracy: 0.9914\n","Epoch 711/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0103 - accuracy: 0.9959\n","Epoch 711: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0103 - accuracy: 0.9959\n","Epoch 712/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0042 - accuracy: 0.9984\n","Epoch 712: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0042 - accuracy: 0.9984\n","Epoch 713/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0027 - accuracy: 0.9990\n","Epoch 713: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0027 - accuracy: 0.9990\n","Epoch 714/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 0.9992\n","Epoch 714: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0021 - accuracy: 0.9992\n","Epoch 715/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0038 - accuracy: 0.9988\n","Epoch 715: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0038 - accuracy: 0.9987\n","Epoch 716/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0097 - accuracy: 0.9968\n","Epoch 716: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0097 - accuracy: 0.9968\n","Epoch 717/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0120 - accuracy: 0.9953\n","Epoch 717: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0118 - accuracy: 0.9953\n","Epoch 718/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0147 - accuracy: 0.9947\n","Epoch 718: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0147 - accuracy: 0.9947\n","Epoch 719/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0195 - accuracy: 0.9935\n","Epoch 719: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0195 - accuracy: 0.9935\n","Epoch 720/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0067 - accuracy: 0.9975\n","Epoch 720: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0067 - accuracy: 0.9975\n","Epoch 721/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0033 - accuracy: 0.9988\n","Epoch 721: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0033 - accuracy: 0.9988\n","Epoch 722/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 0.9992\n","Epoch 722: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0023 - accuracy: 0.9992\n","Epoch 723/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0019 - accuracy: 0.9994\n","Epoch 723: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0019 - accuracy: 0.9994\n","Epoch 724/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0018 - accuracy: 0.9995\n","Epoch 724: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0017 - accuracy: 0.9995\n","Epoch 725/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0017 - accuracy: 0.9995\n","Epoch 725: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0017 - accuracy: 0.9995\n","Epoch 726/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0106 - accuracy: 0.9971\n","Epoch 726: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0113 - accuracy: 0.9970\n","Epoch 727/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0364 - accuracy: 0.9887\n","Epoch 727: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0363 - accuracy: 0.9887\n","Epoch 728/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0198 - accuracy: 0.9927\n","Epoch 728: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0198 - accuracy: 0.9927\n","Epoch 729/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0133 - accuracy: 0.9952\n","Epoch 729: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0132 - accuracy: 0.9952\n","Epoch 730/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0053 - accuracy: 0.9979\n","Epoch 730: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0053 - accuracy: 0.9979\n","Epoch 731/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0032 - accuracy: 0.9988\n","Epoch 731: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0032 - accuracy: 0.9988\n","Epoch 732/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 0.9992\n","Epoch 732: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0021 - accuracy: 0.9993\n","Epoch 733/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0016 - accuracy: 0.9995\n","Epoch 733: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0016 - accuracy: 0.9994\n","Epoch 734/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0016 - accuracy: 0.9996\n","Epoch 734: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0015 - accuracy: 0.9996\n","Epoch 735/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 0.9996\n","Epoch 735: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0013 - accuracy: 0.9996\n","Epoch 736/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 0.9995\n","Epoch 736: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0015 - accuracy: 0.9995\n","Epoch 737/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 0.9995\n","Epoch 737: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0016 - accuracy: 0.9995\n","Epoch 738/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0397 - accuracy: 0.9890\n","Epoch 738: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0397 - accuracy: 0.9890\n","Epoch 739/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0287 - accuracy: 0.9908\n","Epoch 739: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0286 - accuracy: 0.9909\n","Epoch 740/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0118 - accuracy: 0.9957\n","Epoch 740: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0118 - accuracy: 0.9957\n","Epoch 741/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0046 - accuracy: 0.9984\n","Epoch 741: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0046 - accuracy: 0.9984\n","Epoch 742/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0029 - accuracy: 0.9990\n","Epoch 742: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0029 - accuracy: 0.9989\n","Epoch 743/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0022 - accuracy: 0.9991\n","Epoch 743: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0022 - accuracy: 0.9991\n","Epoch 744/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0017 - accuracy: 0.9993\n","Epoch 744: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0017 - accuracy: 0.9993\n","Epoch 745/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0016 - accuracy: 0.9994\n","Epoch 745: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0016 - accuracy: 0.9994\n","Epoch 746/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 0.9992\n","Epoch 746: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0021 - accuracy: 0.9992\n","Epoch 747/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0306 - accuracy: 0.9900\n","Epoch 747: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0305 - accuracy: 0.9899\n","Epoch 748/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0109 - accuracy: 0.9956\n","Epoch 748: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0109 - accuracy: 0.9956\n","Epoch 749/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0082 - accuracy: 0.9971\n","Epoch 749: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0083 - accuracy: 0.9971\n","Epoch 750/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0046 - accuracy: 0.9982\n","Epoch 750: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0046 - accuracy: 0.9982\n","Epoch 751/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0023 - accuracy: 0.9992\n","Epoch 751: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0023 - accuracy: 0.9992\n","Epoch 752/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 0.9994\n","Epoch 752: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0018 - accuracy: 0.9994\n","Epoch 753/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0018 - accuracy: 0.9994\n","Epoch 753: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0018 - accuracy: 0.9994\n","Epoch 754/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0019 - accuracy: 0.9994\n","Epoch 754: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0019 - accuracy: 0.9994\n","Epoch 755/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0103 - accuracy: 0.9974\n","Epoch 755: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0107 - accuracy: 0.9971\n","Epoch 756/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0360 - accuracy: 0.9884\n","Epoch 756: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0360 - accuracy: 0.9884\n","Epoch 757/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0169 - accuracy: 0.9938\n","Epoch 757: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0169 - accuracy: 0.9938\n","Epoch 758/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0065 - accuracy: 0.9975\n","Epoch 758: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0065 - accuracy: 0.9975\n","Epoch 759/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0037 - accuracy: 0.9985\n","Epoch 759: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0037 - accuracy: 0.9985\n","Epoch 760/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0027 - accuracy: 0.9991\n","Epoch 760: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0027 - accuracy: 0.9992\n","Epoch 761/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0023 - accuracy: 0.9993\n","Epoch 761: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0023 - accuracy: 0.9993\n","Epoch 762/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0020 - accuracy: 0.9994\n","Epoch 762: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0020 - accuracy: 0.9994\n","Epoch 763/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 0.9995\n","Epoch 763: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0017 - accuracy: 0.9995\n","Epoch 764/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0017 - accuracy: 0.9995\n","Epoch 764: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0017 - accuracy: 0.9995\n","Epoch 765/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0058 - accuracy: 0.9978\n","Epoch 765: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0060 - accuracy: 0.9978\n","Epoch 766/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0336 - accuracy: 0.9892\n","Epoch 766: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0333 - accuracy: 0.9892\n","Epoch 767/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0147 - accuracy: 0.9947\n","Epoch 767: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0148 - accuracy: 0.9947\n","Epoch 768/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0076 - accuracy: 0.9970\n","Epoch 768: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0076 - accuracy: 0.9970\n","Epoch 769/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0073 - accuracy: 0.9972\n","Epoch 769: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0073 - accuracy: 0.9972\n","Epoch 770/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0053 - accuracy: 0.9980\n","Epoch 770: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0053 - accuracy: 0.9980\n","Epoch 771/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0033 - accuracy: 0.9986\n","Epoch 771: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0033 - accuracy: 0.9986\n","Epoch 772/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0025 - accuracy: 0.9991\n","Epoch 772: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0025 - accuracy: 0.9991\n","Epoch 773/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0019 - accuracy: 0.9994\n","Epoch 773: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0019 - accuracy: 0.9994\n","Epoch 774/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0016 - accuracy: 0.9995\n","Epoch 774: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0016 - accuracy: 0.9995\n","Epoch 775/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 0.9995\n","Epoch 775: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0016 - accuracy: 0.9995\n","Epoch 776/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0016 - accuracy: 0.9995\n","Epoch 776: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0016 - accuracy: 0.9995\n","Epoch 777/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0403 - accuracy: 0.9902\n","Epoch 777: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0402 - accuracy: 0.9902\n","Epoch 778/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0189 - accuracy: 0.9932\n","Epoch 778: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0188 - accuracy: 0.9933\n","Epoch 779/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0070 - accuracy: 0.9972\n","Epoch 779: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0069 - accuracy: 0.9972\n","Epoch 780/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0060 - accuracy: 0.9976\n","Epoch 780: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0060 - accuracy: 0.9976\n","Epoch 781/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0044 - accuracy: 0.9985\n","Epoch 781: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0043 - accuracy: 0.9985\n","Epoch 782/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0023 - accuracy: 0.9992\n","Epoch 782: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0023 - accuracy: 0.9992\n","Epoch 783/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 0.9993\n","Epoch 783: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0021 - accuracy: 0.9993\n","Epoch 784/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0017 - accuracy: 0.9994\n","Epoch 784: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0017 - accuracy: 0.9994\n","Epoch 785/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 0.9995\n","Epoch 785: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0015 - accuracy: 0.9995\n","Epoch 786/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0014 - accuracy: 0.9996\n","Epoch 786: accuracy did not improve from 0.99962\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0014 - accuracy: 0.9996\n","Epoch 787/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 0.9997\n","Epoch 787: accuracy improved from 0.99962 to 0.99966, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0013 - accuracy: 0.9997\n","Epoch 788/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0275 - accuracy: 0.9933\n","Epoch 788: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0273 - accuracy: 0.9933\n","Epoch 789/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0343 - accuracy: 0.9893\n","Epoch 789: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0345 - accuracy: 0.9893\n","Epoch 790/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0117 - accuracy: 0.9959\n","Epoch 790: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0117 - accuracy: 0.9959\n","Epoch 791/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0065 - accuracy: 0.9978\n","Epoch 791: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0064 - accuracy: 0.9979\n","Epoch 792/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0037 - accuracy: 0.9988\n","Epoch 792: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0037 - accuracy: 0.9988\n","Epoch 793/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0026 - accuracy: 0.9992\n","Epoch 793: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0026 - accuracy: 0.9992\n","Epoch 794/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0020 - accuracy: 0.9995\n","Epoch 794: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0020 - accuracy: 0.9995\n","Epoch 795/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0017 - accuracy: 0.9996\n","Epoch 795: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0017 - accuracy: 0.9996\n","Epoch 796/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 0.9996\n","Epoch 796: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0015 - accuracy: 0.9996\n","Epoch 797/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0014 - accuracy: 0.9995\n","Epoch 797: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0014 - accuracy: 0.9995\n","Epoch 798/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0152 - accuracy: 0.9950\n","Epoch 798: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0152 - accuracy: 0.9950\n","Epoch 799/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0372 - accuracy: 0.9880\n","Epoch 799: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0372 - accuracy: 0.9880\n","Epoch 800/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0104 - accuracy: 0.9960\n","Epoch 800: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0104 - accuracy: 0.9960\n","Epoch 801/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0054 - accuracy: 0.9978\n","Epoch 801: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0054 - accuracy: 0.9978\n","Epoch 802/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0036 - accuracy: 0.9988\n","Epoch 802: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0035 - accuracy: 0.9988\n","Epoch 803/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0024 - accuracy: 0.9992\n","Epoch 803: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0024 - accuracy: 0.9992\n","Epoch 804/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0019 - accuracy: 0.9994\n","Epoch 804: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0019 - accuracy: 0.9994\n","Epoch 805/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 0.9995\n","Epoch 805: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0016 - accuracy: 0.9995\n","Epoch 806/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 0.9995\n","Epoch 806: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0015 - accuracy: 0.9995\n","Epoch 807/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 0.9994\n","Epoch 807: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0021 - accuracy: 0.9994\n","Epoch 808/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 0.9996\n","Epoch 808: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0015 - accuracy: 0.9996\n","Epoch 809/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0405 - accuracy: 0.9892\n","Epoch 809: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0401 - accuracy: 0.9892\n","Epoch 810/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0192 - accuracy: 0.9925\n","Epoch 810: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0193 - accuracy: 0.9924\n","Epoch 811/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0113 - accuracy: 0.9959\n","Epoch 811: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0112 - accuracy: 0.9959\n","Epoch 812/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9978\n","Epoch 812: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0060 - accuracy: 0.9977\n","Epoch 813/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0033 - accuracy: 0.9986\n","Epoch 813: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0033 - accuracy: 0.9986\n","Epoch 814/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0020 - accuracy: 0.9994\n","Epoch 814: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0020 - accuracy: 0.9994\n","Epoch 815/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 0.9996\n","Epoch 815: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0015 - accuracy: 0.9995\n","Epoch 816/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 0.9996\n","Epoch 816: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0013 - accuracy: 0.9996\n","Epoch 817/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 0.9997\n","Epoch 817: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0013 - accuracy: 0.9997\n","Epoch 818/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0266 - accuracy: 0.9916\n","Epoch 818: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0264 - accuracy: 0.9916\n","Epoch 819/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0124 - accuracy: 0.9957\n","Epoch 819: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0124 - accuracy: 0.9958\n","Epoch 820/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0060 - accuracy: 0.9977\n","Epoch 820: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0060 - accuracy: 0.9977\n","Epoch 821/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0054 - accuracy: 0.9980\n","Epoch 821: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0054 - accuracy: 0.9980\n","Epoch 822/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0041 - accuracy: 0.9985\n","Epoch 822: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0041 - accuracy: 0.9985\n","Epoch 823/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 0.9993\n","Epoch 823: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0021 - accuracy: 0.9993\n","Epoch 824/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0016 - accuracy: 0.9995\n","Epoch 824: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0016 - accuracy: 0.9995\n","Epoch 825/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 0.9995\n","Epoch 825: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0015 - accuracy: 0.9995\n","Epoch 826/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0016 - accuracy: 0.9995\n","Epoch 826: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0015 - accuracy: 0.9995\n","Epoch 827/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0138 - accuracy: 0.9962\n","Epoch 827: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0139 - accuracy: 0.9962\n","Epoch 828/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0297 - accuracy: 0.9909\n","Epoch 828: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0297 - accuracy: 0.9907\n","Epoch 829/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0138 - accuracy: 0.9952\n","Epoch 829: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0139 - accuracy: 0.9952\n","Epoch 830/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0063 - accuracy: 0.9976\n","Epoch 830: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0064 - accuracy: 0.9975\n","Epoch 831/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0033 - accuracy: 0.9988\n","Epoch 831: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0033 - accuracy: 0.9988\n","Epoch 832/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 0.9993\n","Epoch 832: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0023 - accuracy: 0.9993\n","Epoch 833/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0019 - accuracy: 0.9994\n","Epoch 833: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0019 - accuracy: 0.9994\n","Epoch 834/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0016 - accuracy: 0.9995\n","Epoch 834: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0016 - accuracy: 0.9995\n","Epoch 835/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0013 - accuracy: 0.9996\n","Epoch 835: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0014 - accuracy: 0.9996\n","Epoch 836/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0243 - accuracy: 0.9927\n","Epoch 836: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0241 - accuracy: 0.9928\n","Epoch 837/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0227 - accuracy: 0.9924\n","Epoch 837: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0228 - accuracy: 0.9924\n","Epoch 838/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0074 - accuracy: 0.9975\n","Epoch 838: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0074 - accuracy: 0.9975\n","Epoch 839/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0048 - accuracy: 0.9982\n","Epoch 839: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0048 - accuracy: 0.9982\n","Epoch 840/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0032 - accuracy: 0.9990\n","Epoch 840: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0032 - accuracy: 0.9990\n","Epoch 841/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0026 - accuracy: 0.9991\n","Epoch 841: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0025 - accuracy: 0.9992\n","Epoch 842/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0018 - accuracy: 0.9994\n","Epoch 842: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0018 - accuracy: 0.9994\n","Epoch 843/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 0.9995\n","Epoch 843: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0015 - accuracy: 0.9995\n","Epoch 844/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0048 - accuracy: 0.9983\n","Epoch 844: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0048 - accuracy: 0.9983\n","Epoch 845/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0322 - accuracy: 0.9901\n","Epoch 845: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0323 - accuracy: 0.9902\n","Epoch 846/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0130 - accuracy: 0.9947\n","Epoch 846: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0130 - accuracy: 0.9947\n","Epoch 847/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0057 - accuracy: 0.9978\n","Epoch 847: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0058 - accuracy: 0.9977\n","Epoch 848/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0031 - accuracy: 0.9989\n","Epoch 848: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0031 - accuracy: 0.9989\n","Epoch 849/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0035 - accuracy: 0.9989\n","Epoch 849: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0034 - accuracy: 0.9989\n","Epoch 850/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 0.9993\n","Epoch 850: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0020 - accuracy: 0.9994\n","Epoch 851/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0017 - accuracy: 0.9995\n","Epoch 851: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0017 - accuracy: 0.9995\n","Epoch 852/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0016 - accuracy: 0.9996\n","Epoch 852: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0016 - accuracy: 0.9996\n","Epoch 853/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0047 - accuracy: 0.9983\n","Epoch 853: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0047 - accuracy: 0.9983\n","Epoch 854/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0419 - accuracy: 0.9875\n","Epoch 854: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0419 - accuracy: 0.9875\n","Epoch 855/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0092 - accuracy: 0.9963\n","Epoch 855: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0092 - accuracy: 0.9963\n","Epoch 856/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0046 - accuracy: 0.9982\n","Epoch 856: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0046 - accuracy: 0.9982\n","Epoch 857/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 0.9989\n","Epoch 857: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0031 - accuracy: 0.9989\n","Epoch 858/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 0.9994\n","Epoch 858: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0021 - accuracy: 0.9994\n","Epoch 859/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0017 - accuracy: 0.9996\n","Epoch 859: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0016 - accuracy: 0.9996\n","Epoch 860/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 0.9996\n","Epoch 860: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0015 - accuracy: 0.9996\n","Epoch 861/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 0.9996\n","Epoch 861: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0014 - accuracy: 0.9996\n","Epoch 862/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 0.9996\n","Epoch 862: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0014 - accuracy: 0.9996\n","Epoch 863/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0109 - accuracy: 0.9966\n","Epoch 863: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0111 - accuracy: 0.9964\n","Epoch 864/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0190 - accuracy: 0.9929\n","Epoch 864: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0189 - accuracy: 0.9929\n","Epoch 865/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0207 - accuracy: 0.9936\n","Epoch 865: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0212 - accuracy: 0.9936\n","Epoch 866/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0098 - accuracy: 0.9962\n","Epoch 866: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0098 - accuracy: 0.9962\n","Epoch 867/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0051 - accuracy: 0.9984\n","Epoch 867: accuracy did not improve from 0.99966\n","387/387 [==============================] - 4s 10ms/step - loss: 0.0052 - accuracy: 0.9983\n","Epoch 868/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0030 - accuracy: 0.9991\n","Epoch 868: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0030 - accuracy: 0.9991\n","Epoch 869/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0024 - accuracy: 0.9993\n","Epoch 869: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0024 - accuracy: 0.9993\n","Epoch 870/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0020 - accuracy: 0.9994\n","Epoch 870: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0020 - accuracy: 0.9994\n","Epoch 871/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 0.9994\n","Epoch 871: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0018 - accuracy: 0.9994\n","Epoch 872/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 0.9994\n","Epoch 872: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0019 - accuracy: 0.9994\n","Epoch 873/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0198 - accuracy: 0.9938\n","Epoch 873: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0198 - accuracy: 0.9938\n","Epoch 874/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0107 - accuracy: 0.9960\n","Epoch 874: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0107 - accuracy: 0.9961\n","Epoch 875/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0056 - accuracy: 0.9980\n","Epoch 875: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0056 - accuracy: 0.9980\n","Epoch 876/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0026 - accuracy: 0.9991\n","Epoch 876: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0026 - accuracy: 0.9992\n","Epoch 877/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0018 - accuracy: 0.9995\n","Epoch 877: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0018 - accuracy: 0.9995\n","Epoch 878/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 0.9995\n","Epoch 878: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0015 - accuracy: 0.9995\n","Epoch 879/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0014 - accuracy: 0.9995\n","Epoch 879: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0014 - accuracy: 0.9995\n","Epoch 880/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0013 - accuracy: 0.9996\n","Epoch 880: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0013 - accuracy: 0.9996\n","Epoch 881/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0480 - accuracy: 0.9884\n","Epoch 881: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0479 - accuracy: 0.9883\n","Epoch 882/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0196 - accuracy: 0.9938\n","Epoch 882: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0194 - accuracy: 0.9939\n","Epoch 883/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0066 - accuracy: 0.9976\n","Epoch 883: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0066 - accuracy: 0.9976\n","Epoch 884/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0039 - accuracy: 0.9986\n","Epoch 884: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0039 - accuracy: 0.9986\n","Epoch 885/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 0.9993\n","Epoch 885: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0025 - accuracy: 0.9993\n","Epoch 886/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 0.9994\n","Epoch 886: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0020 - accuracy: 0.9994\n","Epoch 887/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0019 - accuracy: 0.9995\n","Epoch 887: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0019 - accuracy: 0.9995\n","Epoch 888/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0017 - accuracy: 0.9995\n","Epoch 888: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0017 - accuracy: 0.9995\n","Epoch 889/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0025 - accuracy: 0.9991\n","Epoch 889: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0025 - accuracy: 0.9991\n","Epoch 890/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0211 - accuracy: 0.9926\n","Epoch 890: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0211 - accuracy: 0.9926\n","Epoch 891/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0177 - accuracy: 0.9939\n","Epoch 891: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0176 - accuracy: 0.9939\n","Epoch 892/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0150 - accuracy: 0.9946\n","Epoch 892: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0150 - accuracy: 0.9946\n","Epoch 893/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0057 - accuracy: 0.9980\n","Epoch 893: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0057 - accuracy: 0.9980\n","Epoch 894/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0026 - accuracy: 0.9990\n","Epoch 894: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0027 - accuracy: 0.9990\n","Epoch 895/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0022 - accuracy: 0.9991\n","Epoch 895: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0023 - accuracy: 0.9991\n","Epoch 896/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0017 - accuracy: 0.9994\n","Epoch 896: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0017 - accuracy: 0.9994\n","Epoch 897/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 0.9996\n","Epoch 897: accuracy did not improve from 0.99966\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0014 - accuracy: 0.9996\n","Epoch 898/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0012 - accuracy: 0.9997\n","Epoch 898: accuracy improved from 0.99966 to 0.99970, saving model to best_next_line_model.hdf5\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0012 - accuracy: 0.9997\n","Epoch 899/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0023 - accuracy: 0.9993\n","Epoch 899: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0023 - accuracy: 0.9993\n","Epoch 900/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0040 - accuracy: 0.9984\n","Epoch 900: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0041 - accuracy: 0.9984\n","Epoch 901/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0332 - accuracy: 0.9902\n","Epoch 901: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0333 - accuracy: 0.9901\n","Epoch 902/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0116 - accuracy: 0.9955\n","Epoch 902: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0119 - accuracy: 0.9955\n","Epoch 903/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0103 - accuracy: 0.9959\n","Epoch 903: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0102 - accuracy: 0.9959\n","Epoch 904/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0044 - accuracy: 0.9985\n","Epoch 904: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0043 - accuracy: 0.9985\n","Epoch 905/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 0.9991\n","Epoch 905: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0025 - accuracy: 0.9991\n","Epoch 906/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 0.9994\n","Epoch 906: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0019 - accuracy: 0.9994\n","Epoch 907/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0016 - accuracy: 0.9995\n","Epoch 907: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0016 - accuracy: 0.9995\n","Epoch 908/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0016 - accuracy: 0.9996\n","Epoch 908: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0016 - accuracy: 0.9996\n","Epoch 909/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 0.9995\n","Epoch 909: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0014 - accuracy: 0.9995\n","Epoch 910/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0029 - accuracy: 0.9991\n","Epoch 910: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0028 - accuracy: 0.9991\n","Epoch 911/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0332 - accuracy: 0.9899\n","Epoch 911: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0330 - accuracy: 0.9900\n","Epoch 912/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0200 - accuracy: 0.9928\n","Epoch 912: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0200 - accuracy: 0.9928\n","Epoch 913/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0084 - accuracy: 0.9967\n","Epoch 913: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0084 - accuracy: 0.9967\n","Epoch 914/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0053 - accuracy: 0.9978\n","Epoch 914: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0053 - accuracy: 0.9978\n","Epoch 915/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0035 - accuracy: 0.9987\n","Epoch 915: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0035 - accuracy: 0.9987\n","Epoch 916/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0020 - accuracy: 0.9993\n","Epoch 916: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0020 - accuracy: 0.9993\n","Epoch 917/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0018 - accuracy: 0.9994\n","Epoch 917: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0017 - accuracy: 0.9994\n","Epoch 918/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 0.9995\n","Epoch 918: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0015 - accuracy: 0.9995\n","Epoch 919/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0016 - accuracy: 0.9996\n","Epoch 919: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0016 - accuracy: 0.9996\n","Epoch 920/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0033 - accuracy: 0.9990\n","Epoch 920: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0034 - accuracy: 0.9989\n","Epoch 921/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0345 - accuracy: 0.9896\n","Epoch 921: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0345 - accuracy: 0.9896\n","Epoch 922/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0166 - accuracy: 0.9942\n","Epoch 922: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0166 - accuracy: 0.9942\n","Epoch 923/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0073 - accuracy: 0.9968\n","Epoch 923: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0073 - accuracy: 0.9968\n","Epoch 924/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0034 - accuracy: 0.9987\n","Epoch 924: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0034 - accuracy: 0.9987\n","Epoch 925/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0036 - accuracy: 0.9985\n","Epoch 925: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0036 - accuracy: 0.9985\n","Epoch 926/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0020 - accuracy: 0.9993\n","Epoch 926: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0020 - accuracy: 0.9994\n","Epoch 927/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0014 - accuracy: 0.9996\n","Epoch 927: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0015 - accuracy: 0.9996\n","Epoch 928/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0014 - accuracy: 0.9996\n","Epoch 928: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0014 - accuracy: 0.9996\n","Epoch 929/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0013 - accuracy: 0.9996\n","Epoch 929: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0013 - accuracy: 0.9996\n","Epoch 930/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0018 - accuracy: 0.9994\n","Epoch 930: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0018 - accuracy: 0.9995\n","Epoch 931/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 0.9995\n","Epoch 931: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0017 - accuracy: 0.9995\n","Epoch 932/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0232 - accuracy: 0.9939\n","Epoch 932: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0233 - accuracy: 0.9938\n","Epoch 933/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0263 - accuracy: 0.9908\n","Epoch 933: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0261 - accuracy: 0.9908\n","Epoch 934/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0067 - accuracy: 0.9973\n","Epoch 934: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0067 - accuracy: 0.9973\n","Epoch 935/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0043 - accuracy: 0.9983\n","Epoch 935: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0043 - accuracy: 0.9983\n","Epoch 936/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 0.9993\n","Epoch 936: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0021 - accuracy: 0.9993\n","Epoch 937/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0017 - accuracy: 0.9995\n","Epoch 937: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0017 - accuracy: 0.9995\n","Epoch 938/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0014 - accuracy: 0.9996\n","Epoch 938: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0014 - accuracy: 0.9996\n","Epoch 939/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0013 - accuracy: 0.9996\n","Epoch 939: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0013 - accuracy: 0.9996\n","Epoch 940/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0019 - accuracy: 0.9994\n","Epoch 940: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0019 - accuracy: 0.9993\n","Epoch 941/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0030 - accuracy: 0.9990\n","Epoch 941: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0030 - accuracy: 0.9990\n","Epoch 942/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0325 - accuracy: 0.9914\n","Epoch 942: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0325 - accuracy: 0.9914\n","Epoch 943/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0143 - accuracy: 0.9944\n","Epoch 943: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0143 - accuracy: 0.9944\n","Epoch 944/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0067 - accuracy: 0.9975\n","Epoch 944: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0067 - accuracy: 0.9975\n","Epoch 945/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0064 - accuracy: 0.9974\n","Epoch 945: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0064 - accuracy: 0.9974\n","Epoch 946/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0028 - accuracy: 0.9989\n","Epoch 946: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0028 - accuracy: 0.9989\n","Epoch 947/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 0.9994\n","Epoch 947: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0018 - accuracy: 0.9994\n","Epoch 948/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0014 - accuracy: 0.9994\n","Epoch 948: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0014 - accuracy: 0.9994\n","Epoch 949/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0013 - accuracy: 0.9996\n","Epoch 949: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0013 - accuracy: 0.9996\n","Epoch 950/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0013 - accuracy: 0.9995\n","Epoch 950: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0013 - accuracy: 0.9995\n","Epoch 951/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 0.9996\n","Epoch 951: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0013 - accuracy: 0.9996\n","Epoch 952/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0308 - accuracy: 0.9925\n","Epoch 952: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0310 - accuracy: 0.9925\n","Epoch 953/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0194 - accuracy: 0.9936\n","Epoch 953: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0193 - accuracy: 0.9937\n","Epoch 954/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0078 - accuracy: 0.9967\n","Epoch 954: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0078 - accuracy: 0.9967\n","Epoch 955/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0040 - accuracy: 0.9985\n","Epoch 955: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0040 - accuracy: 0.9985\n","Epoch 956/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0025 - accuracy: 0.9993\n","Epoch 956: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0025 - accuracy: 0.9993\n","Epoch 957/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0018 - accuracy: 0.9994\n","Epoch 957: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0018 - accuracy: 0.9995\n","Epoch 958/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0016 - accuracy: 0.9995\n","Epoch 958: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0016 - accuracy: 0.9995\n","Epoch 959/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0014 - accuracy: 0.9996\n","Epoch 959: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0014 - accuracy: 0.9996\n","Epoch 960/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0014 - accuracy: 0.9996\n","Epoch 960: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0014 - accuracy: 0.9996\n","Epoch 961/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0013 - accuracy: 0.9996\n","Epoch 961: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0013 - accuracy: 0.9996\n","Epoch 962/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 0.9995\n","Epoch 962: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0015 - accuracy: 0.9995\n","Epoch 963/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0351 - accuracy: 0.9905\n","Epoch 963: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0351 - accuracy: 0.9905\n","Epoch 964/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0235 - accuracy: 0.9924\n","Epoch 964: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0234 - accuracy: 0.9924\n","Epoch 965/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0110 - accuracy: 0.9958\n","Epoch 965: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0110 - accuracy: 0.9958\n","Epoch 966/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0045 - accuracy: 0.9982\n","Epoch 966: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0045 - accuracy: 0.9982\n","Epoch 967/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0024 - accuracy: 0.9990\n","Epoch 967: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0024 - accuracy: 0.9990\n","Epoch 968/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 0.9995\n","Epoch 968: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0015 - accuracy: 0.9995\n","Epoch 969/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0012 - accuracy: 0.9996\n","Epoch 969: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0012 - accuracy: 0.9996\n","Epoch 970/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 0.9996\n","Epoch 970: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0011 - accuracy: 0.9996\n","Epoch 971/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 0.9997\n","Epoch 971: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0011 - accuracy: 0.9997\n","Epoch 972/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0018 - accuracy: 0.9994\n","Epoch 972: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0018 - accuracy: 0.9994\n","Epoch 973/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 0.9996\n","Epoch 973: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0013 - accuracy: 0.9996\n","Epoch 974/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0017 - accuracy: 0.9996\n","Epoch 974: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0017 - accuracy: 0.9996\n","Epoch 975/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0340 - accuracy: 0.9914\n","Epoch 975: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0340 - accuracy: 0.9914\n","Epoch 976/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0318 - accuracy: 0.9899\n","Epoch 976: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0318 - accuracy: 0.9900\n","Epoch 977/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0090 - accuracy: 0.9969\n","Epoch 977: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0090 - accuracy: 0.9969\n","Epoch 978/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0036 - accuracy: 0.9989\n","Epoch 978: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0036 - accuracy: 0.9989\n","Epoch 979/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 0.9993\n","Epoch 979: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0023 - accuracy: 0.9993\n","Epoch 980/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0018 - accuracy: 0.9995\n","Epoch 980: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0018 - accuracy: 0.9995\n","Epoch 981/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 0.9995\n","Epoch 981: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0015 - accuracy: 0.9995\n","Epoch 982/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 0.9996\n","Epoch 982: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0014 - accuracy: 0.9996\n","Epoch 983/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0013 - accuracy: 0.9996\n","Epoch 983: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0013 - accuracy: 0.9996\n","Epoch 984/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0073 - accuracy: 0.9978\n","Epoch 984: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0073 - accuracy: 0.9978\n","Epoch 985/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0198 - accuracy: 0.9942\n","Epoch 985: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0197 - accuracy: 0.9942\n","Epoch 986/1000\n","381/387 [============================>.] - ETA: 0s - loss: 0.0141 - accuracy: 0.9953\n","Epoch 986: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0140 - accuracy: 0.9953\n","Epoch 987/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0072 - accuracy: 0.9975\n","Epoch 987: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0072 - accuracy: 0.9975\n","Epoch 988/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0039 - accuracy: 0.9985\n","Epoch 988: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0039 - accuracy: 0.9985\n","Epoch 989/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0028 - accuracy: 0.9990\n","Epoch 989: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0028 - accuracy: 0.9990\n","Epoch 990/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 0.9993\n","Epoch 990: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0021 - accuracy: 0.9993\n","Epoch 991/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0016 - accuracy: 0.9996\n","Epoch 991: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0016 - accuracy: 0.9996\n","Epoch 992/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0014 - accuracy: 0.9996\n","Epoch 992: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0013 - accuracy: 0.9996\n","Epoch 993/1000\n","386/387 [============================>.] - ETA: 0s - loss: 0.0014 - accuracy: 0.9996\n","Epoch 993: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0014 - accuracy: 0.9996\n","Epoch 994/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 0.9996\n","Epoch 994: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0016 - accuracy: 0.9996\n","Epoch 995/1000\n","383/387 [============================>.] - ETA: 0s - loss: 0.0082 - accuracy: 0.9984\n","Epoch 995: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0083 - accuracy: 0.9983\n","Epoch 996/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0674 - accuracy: 0.9851\n","Epoch 996: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0674 - accuracy: 0.9851\n","Epoch 997/1000\n","382/387 [============================>.] - ETA: 0s - loss: 0.0155 - accuracy: 0.9949\n","Epoch 997: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 8ms/step - loss: 0.0153 - accuracy: 0.9950\n","Epoch 998/1000\n","385/387 [============================>.] - ETA: 0s - loss: 0.0047 - accuracy: 0.9983\n","Epoch 998: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0047 - accuracy: 0.9983\n","Epoch 999/1000\n","384/387 [============================>.] - ETA: 0s - loss: 0.0028 - accuracy: 0.9991\n","Epoch 999: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0028 - accuracy: 0.9991\n","Epoch 1000/1000\n","387/387 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 0.9994\n","Epoch 1000: accuracy did not improve from 0.99970\n","387/387 [==============================] - 3s 9ms/step - loss: 0.0022 - accuracy: 0.9994\n"]}]},{"cell_type":"markdown","metadata":{"id":"JpiuEoig5iId"},"source":["# Training the lyric/word prediction model"]},{"cell_type":"code","metadata":{"id":"Ua_XN1vN0YxE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1645399019093,"user_tz":-360,"elapsed":1925077,"user":{"displayName":"Mimsadi Islam","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07228862094531790502"}},"outputId":"de6ecd91-2cd0-4cc5-8ace-5470361698b7"},"source":["list_of_training = [\"model_3\"]\n","\n","K.set_value(model_3.optimizer.learning_rate, 0.001)\n","for each_model in list_of_training:\n","    filepath = f\"best_{each_model}.hdf5\"\n","    model_checkpoint = ModelCheckpoint(filepath, monitor=\"loss\", save_best_only=True, verbose=1)\n","\n","    if each_model == \"model_1\":\n","        history = model_1.fit(predictors, label,batch_size=1024, epochs=4000 , verbose=1, callbacks=[model_checkpoint])\n","    elif each_model == \"model_2\":\n","        history = model_2.fit(predictors, label,batch_size=1024, epochs=4000 , verbose=1, callbacks=[model_checkpoint])\n","    elif each_model == \"model_3\":\n","        history = model_3.fit(predictors, label,batch_size=1024, epochs=4000 , verbose=1, callbacks=[model_checkpoint])\n","\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n","Epoch 2751/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.4905 - accuracy: 0.8862\n","Epoch 2751: loss did not improve from 0.33690\n","8/8 [==============================] - 0s 56ms/step - loss: 0.4962 - accuracy: 0.8844\n","Epoch 2752/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.4646 - accuracy: 0.8905\n","Epoch 2752: loss did not improve from 0.33690\n","8/8 [==============================] - 0s 53ms/step - loss: 0.4697 - accuracy: 0.8888\n","Epoch 2753/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.4521 - accuracy: 0.8924\n","Epoch 2753: loss did not improve from 0.33690\n","8/8 [==============================] - 0s 51ms/step - loss: 0.4534 - accuracy: 0.8913\n","Epoch 2754/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.4271 - accuracy: 0.8961\n","Epoch 2754: loss did not improve from 0.33690\n","8/8 [==============================] - 0s 56ms/step - loss: 0.4305 - accuracy: 0.8943\n","Epoch 2755/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.4172 - accuracy: 0.8969\n","Epoch 2755: loss did not improve from 0.33690\n","8/8 [==============================] - 0s 55ms/step - loss: 0.4157 - accuracy: 0.8967\n","Epoch 2756/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3982 - accuracy: 0.9003\n","Epoch 2756: loss did not improve from 0.33690\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3994 - accuracy: 0.8994\n","Epoch 2757/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3861 - accuracy: 0.9019\n","Epoch 2757: loss did not improve from 0.33690\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3878 - accuracy: 0.9009\n","Epoch 2758/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3743 - accuracy: 0.9014\n","Epoch 2758: loss did not improve from 0.33690\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3753 - accuracy: 0.9007\n","Epoch 2759/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3660 - accuracy: 0.8989\n","Epoch 2759: loss did not improve from 0.33690\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3663 - accuracy: 0.8990\n","Epoch 2760/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3624 - accuracy: 0.9005\n","Epoch 2760: loss did not improve from 0.33690\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3604 - accuracy: 0.9011\n","Epoch 2761/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3518 - accuracy: 0.9003\n","Epoch 2761: loss did not improve from 0.33690\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3560 - accuracy: 0.8992\n","Epoch 2762/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3496 - accuracy: 0.8993\n","Epoch 2762: loss did not improve from 0.33690\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3496 - accuracy: 0.8993\n","Epoch 2763/4000\n","8/8 [==============================] - ETA: 0s - loss: 0.3484 - accuracy: 0.9009\n","Epoch 2763: loss did not improve from 0.33690\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3484 - accuracy: 0.9009\n","Epoch 2764/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3443 - accuracy: 0.9016\n","Epoch 2764: loss did not improve from 0.33690\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3468 - accuracy: 0.9009\n","Epoch 2765/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3445 - accuracy: 0.8996\n","Epoch 2765: loss did not improve from 0.33690\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3462 - accuracy: 0.8989\n","Epoch 2766/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3394 - accuracy: 0.9028\n","Epoch 2766: loss did not improve from 0.33690\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3427 - accuracy: 0.9012\n","Epoch 2767/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3435 - accuracy: 0.9005\n","Epoch 2767: loss did not improve from 0.33690\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3435 - accuracy: 0.9003\n","Epoch 2768/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3421 - accuracy: 0.9021\n","Epoch 2768: loss did not improve from 0.33690\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3441 - accuracy: 0.9009\n","Epoch 2769/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3403 - accuracy: 0.9008\n","Epoch 2769: loss did not improve from 0.33690\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3419 - accuracy: 0.8998\n","Epoch 2770/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3424 - accuracy: 0.9007\n","Epoch 2770: loss did not improve from 0.33690\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3383 - accuracy: 0.9014\n","Epoch 2771/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3374 - accuracy: 0.9029\n","Epoch 2771: loss did not improve from 0.33690\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3394 - accuracy: 0.9015\n","Epoch 2772/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3349 - accuracy: 0.9000\n","Epoch 2772: loss did not improve from 0.33690\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3388 - accuracy: 0.8997\n","Epoch 2773/4000\n","8/8 [==============================] - ETA: 0s - loss: 0.3379 - accuracy: 0.9002\n","Epoch 2773: loss did not improve from 0.33690\n","8/8 [==============================] - 0s 57ms/step - loss: 0.3379 - accuracy: 0.9002\n","Epoch 2774/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3395 - accuracy: 0.9021\n","Epoch 2774: loss did not improve from 0.33690\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3370 - accuracy: 0.9028\n","Epoch 2775/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3363 - accuracy: 0.9014\n","Epoch 2775: loss did not improve from 0.33690\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3383 - accuracy: 0.8998\n","Epoch 2776/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3317 - accuracy: 0.9021\n","Epoch 2776: loss improved from 0.33690 to 0.33596, saving model to best_model_3.hdf5\n","8/8 [==============================] - 1s 110ms/step - loss: 0.3360 - accuracy: 0.9006\n","Epoch 2777/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3409 - accuracy: 0.9009\n","Epoch 2777: loss did not improve from 0.33596\n","8/8 [==============================] - 0s 56ms/step - loss: 0.3392 - accuracy: 0.9012\n","Epoch 2778/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3382 - accuracy: 0.8993\n","Epoch 2778: loss did not improve from 0.33596\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3386 - accuracy: 0.8987\n","Epoch 2779/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3365 - accuracy: 0.9019\n","Epoch 2779: loss did not improve from 0.33596\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3374 - accuracy: 0.9011\n","Epoch 2780/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3342 - accuracy: 0.9014\n","Epoch 2780: loss did not improve from 0.33596\n","8/8 [==============================] - 0s 56ms/step - loss: 0.3371 - accuracy: 0.9001\n","Epoch 2781/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3312 - accuracy: 0.9015\n","Epoch 2781: loss improved from 0.33596 to 0.33575, saving model to best_model_3.hdf5\n","8/8 [==============================] - 1s 105ms/step - loss: 0.3358 - accuracy: 0.9001\n","Epoch 2782/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3397 - accuracy: 0.9032\n","Epoch 2782: loss did not improve from 0.33575\n","8/8 [==============================] - 0s 48ms/step - loss: 0.3365 - accuracy: 0.9034\n","Epoch 2783/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3404 - accuracy: 0.9015\n","Epoch 2783: loss did not improve from 0.33575\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3397 - accuracy: 0.9016\n","Epoch 2784/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3360 - accuracy: 0.9026\n","Epoch 2784: loss did not improve from 0.33575\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3395 - accuracy: 0.9006\n","Epoch 2785/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3386 - accuracy: 0.8980\n","Epoch 2785: loss did not improve from 0.33575\n","8/8 [==============================] - 0s 49ms/step - loss: 0.3408 - accuracy: 0.8979\n","Epoch 2786/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3321 - accuracy: 0.9019\n","Epoch 2786: loss improved from 0.33575 to 0.33467, saving model to best_model_3.hdf5\n","8/8 [==============================] - 1s 105ms/step - loss: 0.3347 - accuracy: 0.9015\n","Epoch 2787/4000\n","8/8 [==============================] - ETA: 0s - loss: 0.3353 - accuracy: 0.8994\n","Epoch 2787: loss did not improve from 0.33467\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3353 - accuracy: 0.8994\n","Epoch 2788/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3292 - accuracy: 0.9044\n","Epoch 2788: loss improved from 0.33467 to 0.33115, saving model to best_model_3.hdf5\n","8/8 [==============================] - 1s 104ms/step - loss: 0.3312 - accuracy: 0.9031\n","Epoch 2789/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3368 - accuracy: 0.9005\n","Epoch 2789: loss did not improve from 0.33115\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3369 - accuracy: 0.9002\n","Epoch 2790/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3335 - accuracy: 0.9036\n","Epoch 2790: loss did not improve from 0.33115\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3358 - accuracy: 0.9021\n","Epoch 2791/4000\n","8/8 [==============================] - ETA: 0s - loss: 0.3358 - accuracy: 0.9006\n","Epoch 2791: loss did not improve from 0.33115\n","8/8 [==============================] - 0s 56ms/step - loss: 0.3358 - accuracy: 0.9006\n","Epoch 2792/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3308 - accuracy: 0.9026\n","Epoch 2792: loss did not improve from 0.33115\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3325 - accuracy: 0.9011\n","Epoch 2793/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3374 - accuracy: 0.8965\n","Epoch 2793: loss did not improve from 0.33115\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3355 - accuracy: 0.8974\n","Epoch 2794/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3330 - accuracy: 0.9011\n","Epoch 2794: loss did not improve from 0.33115\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3333 - accuracy: 0.9005\n","Epoch 2795/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3280 - accuracy: 0.9004\n","Epoch 2795: loss did not improve from 0.33115\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3329 - accuracy: 0.8988\n","Epoch 2796/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3322 - accuracy: 0.8993\n","Epoch 2796: loss did not improve from 0.33115\n","8/8 [==============================] - 0s 56ms/step - loss: 0.3348 - accuracy: 0.8983\n","Epoch 2797/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3272 - accuracy: 0.9032\n","Epoch 2797: loss did not improve from 0.33115\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3360 - accuracy: 0.9005\n","Epoch 2798/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3315 - accuracy: 0.9029\n","Epoch 2798: loss did not improve from 0.33115\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3340 - accuracy: 0.9010\n","Epoch 2799/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3299 - accuracy: 0.9009\n","Epoch 2799: loss did not improve from 0.33115\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3334 - accuracy: 0.8996\n","Epoch 2800/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3277 - accuracy: 0.9033\n","Epoch 2800: loss did not improve from 0.33115\n","8/8 [==============================] - 0s 56ms/step - loss: 0.3325 - accuracy: 0.9024\n","Epoch 2801/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3344 - accuracy: 0.9012\n","Epoch 2801: loss did not improve from 0.33115\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3327 - accuracy: 0.9012\n","Epoch 2802/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3348 - accuracy: 0.8987\n","Epoch 2802: loss did not improve from 0.33115\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3337 - accuracy: 0.8988\n","Epoch 2803/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3300 - accuracy: 0.9012\n","Epoch 2803: loss did not improve from 0.33115\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3337 - accuracy: 0.8993\n","Epoch 2804/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3216 - accuracy: 0.9039\n","Epoch 2804: loss improved from 0.33115 to 0.32847, saving model to best_model_3.hdf5\n","8/8 [==============================] - 1s 104ms/step - loss: 0.3285 - accuracy: 0.9015\n","Epoch 2805/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3314 - accuracy: 0.9022\n","Epoch 2805: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 58ms/step - loss: 0.3308 - accuracy: 0.9023\n","Epoch 2806/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3307 - accuracy: 0.9016\n","Epoch 2806: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3316 - accuracy: 0.9014\n","Epoch 2807/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3271 - accuracy: 0.9030\n","Epoch 2807: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3323 - accuracy: 0.9010\n","Epoch 2808/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3265 - accuracy: 0.9032\n","Epoch 2808: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3310 - accuracy: 0.9007\n","Epoch 2809/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3310 - accuracy: 0.8998\n","Epoch 2809: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3331 - accuracy: 0.8990\n","Epoch 2810/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3308 - accuracy: 0.9004\n","Epoch 2810: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3337 - accuracy: 0.8992\n","Epoch 2811/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3328 - accuracy: 0.9015\n","Epoch 2811: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3337 - accuracy: 0.9015\n","Epoch 2812/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3293 - accuracy: 0.9004\n","Epoch 2812: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 49ms/step - loss: 0.3329 - accuracy: 0.8994\n","Epoch 2813/4000\n","8/8 [==============================] - ETA: 0s - loss: 0.3325 - accuracy: 0.9009\n","Epoch 2813: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 56ms/step - loss: 0.3325 - accuracy: 0.9009\n","Epoch 2814/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3346 - accuracy: 0.9009\n","Epoch 2814: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3390 - accuracy: 0.8993\n","Epoch 2815/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3299 - accuracy: 0.9019\n","Epoch 2815: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3336 - accuracy: 0.9005\n","Epoch 2816/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3338 - accuracy: 0.9009\n","Epoch 2816: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3366 - accuracy: 0.8997\n","Epoch 2817/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3367 - accuracy: 0.8991\n","Epoch 2817: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3347 - accuracy: 0.8998\n","Epoch 2818/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3316 - accuracy: 0.9026\n","Epoch 2818: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 57ms/step - loss: 0.3337 - accuracy: 0.9019\n","Epoch 2819/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3327 - accuracy: 0.9003\n","Epoch 2819: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3317 - accuracy: 0.9011\n","Epoch 2820/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3280 - accuracy: 0.9026\n","Epoch 2820: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3311 - accuracy: 0.9006\n","Epoch 2821/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3339 - accuracy: 0.9028\n","Epoch 2821: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3336 - accuracy: 0.9024\n","Epoch 2822/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3342 - accuracy: 0.9012\n","Epoch 2822: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3358 - accuracy: 0.9006\n","Epoch 2823/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3318 - accuracy: 0.9018\n","Epoch 2823: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3350 - accuracy: 0.9011\n","Epoch 2824/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3326 - accuracy: 0.9012\n","Epoch 2824: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3335 - accuracy: 0.9007\n","Epoch 2825/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3339 - accuracy: 0.9001\n","Epoch 2825: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3340 - accuracy: 0.8993\n","Epoch 2826/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3365 - accuracy: 0.9005\n","Epoch 2826: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3392 - accuracy: 0.9003\n","Epoch 2827/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3337 - accuracy: 0.9033\n","Epoch 2827: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3372 - accuracy: 0.9016\n","Epoch 2828/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3373 - accuracy: 0.9014\n","Epoch 2828: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3390 - accuracy: 0.9009\n","Epoch 2829/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3326 - accuracy: 0.9003\n","Epoch 2829: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 49ms/step - loss: 0.3363 - accuracy: 0.8989\n","Epoch 2830/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3365 - accuracy: 0.8998\n","Epoch 2830: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3385 - accuracy: 0.8989\n","Epoch 2831/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3303 - accuracy: 0.9039\n","Epoch 2831: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3354 - accuracy: 0.9015\n","Epoch 2832/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3311 - accuracy: 0.9025\n","Epoch 2832: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3356 - accuracy: 0.9003\n","Epoch 2833/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3366 - accuracy: 0.8996\n","Epoch 2833: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3331 - accuracy: 0.9006\n","Epoch 2834/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3330 - accuracy: 0.9011\n","Epoch 2834: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3334 - accuracy: 0.9015\n","Epoch 2835/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3337 - accuracy: 0.8975\n","Epoch 2835: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3325 - accuracy: 0.8977\n","Epoch 2836/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3311 - accuracy: 0.9004\n","Epoch 2836: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3318 - accuracy: 0.9002\n","Epoch 2837/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3319 - accuracy: 0.9023\n","Epoch 2837: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3352 - accuracy: 0.9019\n","Epoch 2838/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3279 - accuracy: 0.9018\n","Epoch 2838: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3338 - accuracy: 0.8999\n","Epoch 2839/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3300 - accuracy: 0.9025\n","Epoch 2839: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3347 - accuracy: 0.9007\n","Epoch 2840/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3318 - accuracy: 0.9003\n","Epoch 2840: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3343 - accuracy: 0.8990\n","Epoch 2841/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3342 - accuracy: 0.9025\n","Epoch 2841: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3365 - accuracy: 0.9015\n","Epoch 2842/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3331 - accuracy: 0.9016\n","Epoch 2842: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3345 - accuracy: 0.9010\n","Epoch 2843/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3295 - accuracy: 0.9011\n","Epoch 2843: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3331 - accuracy: 0.8998\n","Epoch 2844/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3338 - accuracy: 0.9015\n","Epoch 2844: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3365 - accuracy: 0.9011\n","Epoch 2845/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3339 - accuracy: 0.9015\n","Epoch 2845: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3344 - accuracy: 0.9018\n","Epoch 2846/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3333 - accuracy: 0.9019\n","Epoch 2846: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3317 - accuracy: 0.9023\n","Epoch 2847/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3307 - accuracy: 0.9025\n","Epoch 2847: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3326 - accuracy: 0.9011\n","Epoch 2848/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3299 - accuracy: 0.9008\n","Epoch 2848: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3324 - accuracy: 0.9003\n","Epoch 2849/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3348 - accuracy: 0.8989\n","Epoch 2849: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3343 - accuracy: 0.8992\n","Epoch 2850/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3287 - accuracy: 0.9005\n","Epoch 2850: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3307 - accuracy: 0.8994\n","Epoch 2851/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3236 - accuracy: 0.9028\n","Epoch 2851: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3298 - accuracy: 0.9001\n","Epoch 2852/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3338 - accuracy: 0.9012\n","Epoch 2852: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3333 - accuracy: 0.9009\n","Epoch 2853/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3346 - accuracy: 0.8997\n","Epoch 2853: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3314 - accuracy: 0.9006\n","Epoch 2854/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3259 - accuracy: 0.9009\n","Epoch 2854: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3286 - accuracy: 0.8994\n","Epoch 2855/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3330 - accuracy: 0.8996\n","Epoch 2855: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3293 - accuracy: 0.9005\n","Epoch 2856/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3319 - accuracy: 0.9000\n","Epoch 2856: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3298 - accuracy: 0.9006\n","Epoch 2857/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3324 - accuracy: 0.8991\n","Epoch 2857: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 56ms/step - loss: 0.3300 - accuracy: 0.8998\n","Epoch 2858/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3269 - accuracy: 0.8997\n","Epoch 2858: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3300 - accuracy: 0.8988\n","Epoch 2859/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3312 - accuracy: 0.9003\n","Epoch 2859: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3318 - accuracy: 0.9002\n","Epoch 2860/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3362 - accuracy: 0.8996\n","Epoch 2860: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3361 - accuracy: 0.8994\n","Epoch 2861/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3352 - accuracy: 0.8998\n","Epoch 2861: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3360 - accuracy: 0.8990\n","Epoch 2862/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3325 - accuracy: 0.9011\n","Epoch 2862: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3349 - accuracy: 0.8996\n","Epoch 2863/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3348 - accuracy: 0.8972\n","Epoch 2863: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3335 - accuracy: 0.8983\n","Epoch 2864/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3314 - accuracy: 0.9015\n","Epoch 2864: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3332 - accuracy: 0.9010\n","Epoch 2865/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3306 - accuracy: 0.9021\n","Epoch 2865: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3330 - accuracy: 0.9009\n","Epoch 2866/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3341 - accuracy: 0.9014\n","Epoch 2866: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3351 - accuracy: 0.9014\n","Epoch 2867/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3375 - accuracy: 0.9008\n","Epoch 2867: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3345 - accuracy: 0.9018\n","Epoch 2868/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3279 - accuracy: 0.9022\n","Epoch 2868: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3332 - accuracy: 0.8999\n","Epoch 2869/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3286 - accuracy: 0.9019\n","Epoch 2869: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3304 - accuracy: 0.9006\n","Epoch 2870/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3314 - accuracy: 0.9003\n","Epoch 2870: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3327 - accuracy: 0.8998\n","Epoch 2871/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3337 - accuracy: 0.9007\n","Epoch 2871: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 56ms/step - loss: 0.3357 - accuracy: 0.8997\n","Epoch 2872/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3272 - accuracy: 0.9022\n","Epoch 2872: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3303 - accuracy: 0.9010\n","Epoch 2873/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3335 - accuracy: 0.9046\n","Epoch 2873: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3336 - accuracy: 0.9046\n","Epoch 2874/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3324 - accuracy: 0.9009\n","Epoch 2874: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3362 - accuracy: 0.9001\n","Epoch 2875/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3301 - accuracy: 0.9012\n","Epoch 2875: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3309 - accuracy: 0.9011\n","Epoch 2876/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3230 - accuracy: 0.9014\n","Epoch 2876: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3290 - accuracy: 0.8994\n","Epoch 2877/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3342 - accuracy: 0.9005\n","Epoch 2877: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3327 - accuracy: 0.9005\n","Epoch 2878/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3293 - accuracy: 0.9033\n","Epoch 2878: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3329 - accuracy: 0.9019\n","Epoch 2879/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3277 - accuracy: 0.9016\n","Epoch 2879: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3325 - accuracy: 0.8999\n","Epoch 2880/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3276 - accuracy: 0.9032\n","Epoch 2880: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3295 - accuracy: 0.9023\n","Epoch 2881/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3311 - accuracy: 0.9019\n","Epoch 2881: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3325 - accuracy: 0.9009\n","Epoch 2882/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3328 - accuracy: 0.9015\n","Epoch 2882: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3353 - accuracy: 0.9003\n","Epoch 2883/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3293 - accuracy: 0.9032\n","Epoch 2883: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 57ms/step - loss: 0.3328 - accuracy: 0.9020\n","Epoch 2884/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3308 - accuracy: 0.9018\n","Epoch 2884: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3351 - accuracy: 0.9007\n","Epoch 2885/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3366 - accuracy: 0.9015\n","Epoch 2885: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3331 - accuracy: 0.9021\n","Epoch 2886/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3348 - accuracy: 0.9004\n","Epoch 2886: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3356 - accuracy: 0.9002\n","Epoch 2887/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3351 - accuracy: 0.9015\n","Epoch 2887: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3351 - accuracy: 0.9009\n","Epoch 2888/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3249 - accuracy: 0.9044\n","Epoch 2888: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 56ms/step - loss: 0.3316 - accuracy: 0.9019\n","Epoch 2889/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3322 - accuracy: 0.8993\n","Epoch 2889: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3337 - accuracy: 0.8990\n","Epoch 2890/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3316 - accuracy: 0.9011\n","Epoch 2890: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3316 - accuracy: 0.9018\n","Epoch 2891/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3247 - accuracy: 0.9036\n","Epoch 2891: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3309 - accuracy: 0.9015\n","Epoch 2892/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3281 - accuracy: 0.9035\n","Epoch 2892: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3344 - accuracy: 0.9007\n","Epoch 2893/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3313 - accuracy: 0.9021\n","Epoch 2893: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3331 - accuracy: 0.9014\n","Epoch 2894/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3335 - accuracy: 0.9008\n","Epoch 2894: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3321 - accuracy: 0.9011\n","Epoch 2895/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3292 - accuracy: 0.9012\n","Epoch 2895: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 56ms/step - loss: 0.3336 - accuracy: 0.8997\n","Epoch 2896/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3322 - accuracy: 0.9011\n","Epoch 2896: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3334 - accuracy: 0.9011\n","Epoch 2897/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3314 - accuracy: 0.8996\n","Epoch 2897: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3317 - accuracy: 0.8993\n","Epoch 2898/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3320 - accuracy: 0.8991\n","Epoch 2898: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3321 - accuracy: 0.8990\n","Epoch 2899/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3343 - accuracy: 0.8996\n","Epoch 2899: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3349 - accuracy: 0.8992\n","Epoch 2900/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3305 - accuracy: 0.9001\n","Epoch 2900: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3310 - accuracy: 0.8997\n","Epoch 2901/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3290 - accuracy: 0.9011\n","Epoch 2901: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3321 - accuracy: 0.9003\n","Epoch 2902/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3280 - accuracy: 0.9011\n","Epoch 2902: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3314 - accuracy: 0.8999\n","Epoch 2903/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3300 - accuracy: 0.8998\n","Epoch 2903: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3326 - accuracy: 0.8985\n","Epoch 2904/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3281 - accuracy: 0.9026\n","Epoch 2904: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3309 - accuracy: 0.9005\n","Epoch 2905/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3284 - accuracy: 0.9011\n","Epoch 2905: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3318 - accuracy: 0.8993\n","Epoch 2906/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3286 - accuracy: 0.9008\n","Epoch 2906: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3322 - accuracy: 0.8999\n","Epoch 2907/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3221 - accuracy: 0.9036\n","Epoch 2907: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3305 - accuracy: 0.9015\n","Epoch 2908/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3345 - accuracy: 0.8991\n","Epoch 2908: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3332 - accuracy: 0.8994\n","Epoch 2909/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3302 - accuracy: 0.9030\n","Epoch 2909: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3331 - accuracy: 0.9014\n","Epoch 2910/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3291 - accuracy: 0.9022\n","Epoch 2910: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3344 - accuracy: 0.9010\n","Epoch 2911/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3340 - accuracy: 0.9008\n","Epoch 2911: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3353 - accuracy: 0.9006\n","Epoch 2912/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3284 - accuracy: 0.9004\n","Epoch 2912: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3317 - accuracy: 0.8993\n","Epoch 2913/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3262 - accuracy: 0.9016\n","Epoch 2913: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3320 - accuracy: 0.8999\n","Epoch 2914/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3319 - accuracy: 0.9014\n","Epoch 2914: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3331 - accuracy: 0.9010\n","Epoch 2915/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3360 - accuracy: 0.8965\n","Epoch 2915: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3332 - accuracy: 0.8974\n","Epoch 2916/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3335 - accuracy: 0.9007\n","Epoch 2916: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3343 - accuracy: 0.9006\n","Epoch 2917/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3355 - accuracy: 0.8994\n","Epoch 2917: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3349 - accuracy: 0.8992\n","Epoch 2918/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3319 - accuracy: 0.9025\n","Epoch 2918: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3331 - accuracy: 0.9012\n","Epoch 2919/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3331 - accuracy: 0.8996\n","Epoch 2919: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 57ms/step - loss: 0.3359 - accuracy: 0.8987\n","Epoch 2920/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3301 - accuracy: 0.9028\n","Epoch 2920: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3321 - accuracy: 0.9024\n","Epoch 2921/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3315 - accuracy: 0.9016\n","Epoch 2921: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3309 - accuracy: 0.9019\n","Epoch 2922/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3317 - accuracy: 0.9012\n","Epoch 2922: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3336 - accuracy: 0.9002\n","Epoch 2923/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3343 - accuracy: 0.9003\n","Epoch 2923: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3322 - accuracy: 0.9012\n","Epoch 2924/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3241 - accuracy: 0.9032\n","Epoch 2924: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3341 - accuracy: 0.9005\n","Epoch 2925/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3342 - accuracy: 0.8997\n","Epoch 2925: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3341 - accuracy: 0.8994\n","Epoch 2926/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3337 - accuracy: 0.9003\n","Epoch 2926: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3333 - accuracy: 0.9007\n","Epoch 2927/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3293 - accuracy: 0.8998\n","Epoch 2927: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3351 - accuracy: 0.8984\n","Epoch 2928/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3288 - accuracy: 0.9019\n","Epoch 2928: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3359 - accuracy: 0.8988\n","Epoch 2929/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3299 - accuracy: 0.9032\n","Epoch 2929: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3357 - accuracy: 0.9009\n","Epoch 2930/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3316 - accuracy: 0.9035\n","Epoch 2930: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3355 - accuracy: 0.9011\n","Epoch 2931/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3379 - accuracy: 0.8970\n","Epoch 2931: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3384 - accuracy: 0.8970\n","Epoch 2932/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3342 - accuracy: 0.9003\n","Epoch 2932: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3370 - accuracy: 0.8997\n","Epoch 2933/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3369 - accuracy: 0.9011\n","Epoch 2933: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3369 - accuracy: 0.9005\n","Epoch 2934/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3345 - accuracy: 0.8987\n","Epoch 2934: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 56ms/step - loss: 0.3332 - accuracy: 0.8989\n","Epoch 2935/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3295 - accuracy: 0.9000\n","Epoch 2935: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3307 - accuracy: 0.9002\n","Epoch 2936/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3293 - accuracy: 0.9014\n","Epoch 2936: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3352 - accuracy: 0.8996\n","Epoch 2937/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3319 - accuracy: 0.8963\n","Epoch 2937: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3299 - accuracy: 0.8976\n","Epoch 2938/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3307 - accuracy: 0.8998\n","Epoch 2938: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3340 - accuracy: 0.8990\n","Epoch 2939/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3235 - accuracy: 0.9021\n","Epoch 2939: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3300 - accuracy: 0.8996\n","Epoch 2940/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3286 - accuracy: 0.9016\n","Epoch 2940: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3333 - accuracy: 0.9002\n","Epoch 2941/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3301 - accuracy: 0.8996\n","Epoch 2941: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3344 - accuracy: 0.8992\n","Epoch 2942/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3352 - accuracy: 0.8986\n","Epoch 2942: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3369 - accuracy: 0.8990\n","Epoch 2943/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3348 - accuracy: 0.9036\n","Epoch 2943: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3351 - accuracy: 0.9027\n","Epoch 2944/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3286 - accuracy: 0.9008\n","Epoch 2944: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3309 - accuracy: 0.9002\n","Epoch 2945/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3359 - accuracy: 0.9000\n","Epoch 2945: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3343 - accuracy: 0.8998\n","Epoch 2946/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3303 - accuracy: 0.8975\n","Epoch 2946: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3321 - accuracy: 0.8977\n","Epoch 2947/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3300 - accuracy: 0.9015\n","Epoch 2947: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3313 - accuracy: 0.9009\n","Epoch 2948/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3306 - accuracy: 0.8987\n","Epoch 2948: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3287 - accuracy: 0.9001\n","Epoch 2949/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3272 - accuracy: 0.8996\n","Epoch 2949: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3306 - accuracy: 0.8989\n","Epoch 2950/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3266 - accuracy: 0.8993\n","Epoch 2950: loss did not improve from 0.32847\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3285 - accuracy: 0.8983\n","Epoch 2951/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3300 - accuracy: 0.8986\n","Epoch 2951: loss improved from 0.32847 to 0.32644, saving model to best_model_3.hdf5\n","8/8 [==============================] - 1s 109ms/step - loss: 0.3264 - accuracy: 0.9003\n","Epoch 2952/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3210 - accuracy: 0.9019\n","Epoch 2952: loss improved from 0.32644 to 0.32579, saving model to best_model_3.hdf5\n","8/8 [==============================] - 1s 103ms/step - loss: 0.3258 - accuracy: 0.9006\n","Epoch 2953/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3293 - accuracy: 0.8990\n","Epoch 2953: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3297 - accuracy: 0.8987\n","Epoch 2954/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3281 - accuracy: 0.9018\n","Epoch 2954: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3304 - accuracy: 0.9009\n","Epoch 2955/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3308 - accuracy: 0.8994\n","Epoch 2955: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 56ms/step - loss: 0.3316 - accuracy: 0.8994\n","Epoch 2956/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3236 - accuracy: 0.9019\n","Epoch 2956: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3319 - accuracy: 0.8999\n","Epoch 2957/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3302 - accuracy: 0.9025\n","Epoch 2957: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3319 - accuracy: 0.9018\n","Epoch 2958/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3275 - accuracy: 0.9009\n","Epoch 2958: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3300 - accuracy: 0.8999\n","Epoch 2959/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3262 - accuracy: 0.9039\n","Epoch 2959: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3318 - accuracy: 0.9018\n","Epoch 2960/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3296 - accuracy: 0.9003\n","Epoch 2960: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3333 - accuracy: 0.8987\n","Epoch 2961/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3317 - accuracy: 0.8986\n","Epoch 2961: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 56ms/step - loss: 0.3328 - accuracy: 0.8981\n","Epoch 2962/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3264 - accuracy: 0.9016\n","Epoch 2962: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3326 - accuracy: 0.9003\n","Epoch 2963/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3358 - accuracy: 0.9012\n","Epoch 2963: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3335 - accuracy: 0.9012\n","Epoch 2964/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3310 - accuracy: 0.9019\n","Epoch 2964: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3349 - accuracy: 0.9001\n","Epoch 2965/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3340 - accuracy: 0.9023\n","Epoch 2965: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3332 - accuracy: 0.9018\n","Epoch 2966/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3288 - accuracy: 0.9028\n","Epoch 2966: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3334 - accuracy: 0.9006\n","Epoch 2967/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3354 - accuracy: 0.8990\n","Epoch 2967: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3341 - accuracy: 0.8998\n","Epoch 2968/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3295 - accuracy: 0.9001\n","Epoch 2968: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3316 - accuracy: 0.8990\n","Epoch 2969/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3321 - accuracy: 0.9011\n","Epoch 2969: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3314 - accuracy: 0.9007\n","Epoch 2970/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3329 - accuracy: 0.9005\n","Epoch 2970: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3335 - accuracy: 0.8999\n","Epoch 2971/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3302 - accuracy: 0.9003\n","Epoch 2971: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3316 - accuracy: 0.8998\n","Epoch 2972/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3279 - accuracy: 0.9040\n","Epoch 2972: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3319 - accuracy: 0.9015\n","Epoch 2973/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3322 - accuracy: 0.9005\n","Epoch 2973: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3339 - accuracy: 0.9001\n","Epoch 2974/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3298 - accuracy: 0.9012\n","Epoch 2974: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3320 - accuracy: 0.9005\n","Epoch 2975/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3341 - accuracy: 0.8989\n","Epoch 2975: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3321 - accuracy: 0.8994\n","Epoch 2976/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3303 - accuracy: 0.9019\n","Epoch 2976: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3287 - accuracy: 0.9024\n","Epoch 2977/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3267 - accuracy: 0.9005\n","Epoch 2977: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3282 - accuracy: 0.9003\n","Epoch 2978/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3250 - accuracy: 0.9016\n","Epoch 2978: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3321 - accuracy: 0.8996\n","Epoch 2979/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3303 - accuracy: 0.9008\n","Epoch 2979: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3290 - accuracy: 0.8999\n","Epoch 2980/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3301 - accuracy: 0.8991\n","Epoch 2980: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3326 - accuracy: 0.8990\n","Epoch 2981/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3290 - accuracy: 0.9012\n","Epoch 2981: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3332 - accuracy: 0.8999\n","Epoch 2982/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3330 - accuracy: 0.8989\n","Epoch 2982: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3326 - accuracy: 0.8987\n","Epoch 2983/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3372 - accuracy: 0.8987\n","Epoch 2983: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3393 - accuracy: 0.8977\n","Epoch 2984/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3376 - accuracy: 0.9008\n","Epoch 2984: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3382 - accuracy: 0.9002\n","Epoch 2985/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3338 - accuracy: 0.9044\n","Epoch 2985: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3401 - accuracy: 0.9019\n","Epoch 2986/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3409 - accuracy: 0.8993\n","Epoch 2986: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3444 - accuracy: 0.8983\n","Epoch 2987/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3445 - accuracy: 0.9008\n","Epoch 2987: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3456 - accuracy: 0.8999\n","Epoch 2988/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3467 - accuracy: 0.9018\n","Epoch 2988: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3502 - accuracy: 0.9005\n","Epoch 2989/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3390 - accuracy: 0.9003\n","Epoch 2989: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3468 - accuracy: 0.8984\n","Epoch 2990/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3553 - accuracy: 0.8955\n","Epoch 2990: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3538 - accuracy: 0.8958\n","Epoch 2991/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3555 - accuracy: 0.8966\n","Epoch 2991: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3563 - accuracy: 0.8967\n","Epoch 2992/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3530 - accuracy: 0.8998\n","Epoch 2992: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3582 - accuracy: 0.8985\n","Epoch 2993/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3631 - accuracy: 0.8976\n","Epoch 2993: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3586 - accuracy: 0.8994\n","Epoch 2994/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3583 - accuracy: 0.8966\n","Epoch 2994: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3572 - accuracy: 0.8966\n","Epoch 2995/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3663 - accuracy: 0.8980\n","Epoch 2995: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3677 - accuracy: 0.8967\n","Epoch 2996/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3673 - accuracy: 0.8973\n","Epoch 2996: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3721 - accuracy: 0.8954\n","Epoch 2997/4000\n","8/8 [==============================] - ETA: 0s - loss: 0.3904 - accuracy: 0.8939\n","Epoch 2997: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3904 - accuracy: 0.8939\n","Epoch 2998/4000\n","8/8 [==============================] - ETA: 0s - loss: 0.3966 - accuracy: 0.8895\n","Epoch 2998: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 49ms/step - loss: 0.3966 - accuracy: 0.8895\n","Epoch 2999/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.4201 - accuracy: 0.8876\n","Epoch 2999: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 54ms/step - loss: 0.4272 - accuracy: 0.8862\n","Epoch 3000/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.4388 - accuracy: 0.8799\n","Epoch 3000: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 54ms/step - loss: 0.4444 - accuracy: 0.8778\n","Epoch 3001/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.4808 - accuracy: 0.8749\n","Epoch 3001: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 50ms/step - loss: 0.4890 - accuracy: 0.8730\n","Epoch 3002/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.5292 - accuracy: 0.8655\n","Epoch 3002: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 50ms/step - loss: 0.5334 - accuracy: 0.8629\n","Epoch 3003/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.5899 - accuracy: 0.8523\n","Epoch 3003: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 53ms/step - loss: 0.5964 - accuracy: 0.8499\n","Epoch 3004/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.6230 - accuracy: 0.8436\n","Epoch 3004: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 52ms/step - loss: 0.6330 - accuracy: 0.8420\n","Epoch 3005/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.7175 - accuracy: 0.8306\n","Epoch 3005: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 51ms/step - loss: 0.7262 - accuracy: 0.8282\n","Epoch 3006/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.7358 - accuracy: 0.8227\n","Epoch 3006: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 54ms/step - loss: 0.7459 - accuracy: 0.8203\n","Epoch 3007/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.6986 - accuracy: 0.8361\n","Epoch 3007: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 53ms/step - loss: 0.7088 - accuracy: 0.8328\n","Epoch 3008/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.7198 - accuracy: 0.8316\n","Epoch 3008: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 52ms/step - loss: 0.7284 - accuracy: 0.8306\n","Epoch 3009/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.7276 - accuracy: 0.8387\n","Epoch 3009: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 56ms/step - loss: 0.7343 - accuracy: 0.8379\n","Epoch 3010/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.6929 - accuracy: 0.8432\n","Epoch 3010: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 54ms/step - loss: 0.6942 - accuracy: 0.8420\n","Epoch 3011/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.6491 - accuracy: 0.8525\n","Epoch 3011: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 51ms/step - loss: 0.6547 - accuracy: 0.8505\n","Epoch 3012/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.6343 - accuracy: 0.8590\n","Epoch 3012: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 51ms/step - loss: 0.6366 - accuracy: 0.8583\n","Epoch 3013/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.6385 - accuracy: 0.8523\n","Epoch 3013: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 50ms/step - loss: 0.6443 - accuracy: 0.8512\n","Epoch 3014/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.6065 - accuracy: 0.8598\n","Epoch 3014: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 51ms/step - loss: 0.6102 - accuracy: 0.8572\n","Epoch 3015/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.5521 - accuracy: 0.8733\n","Epoch 3015: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 52ms/step - loss: 0.5554 - accuracy: 0.8726\n","Epoch 3016/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.5098 - accuracy: 0.8863\n","Epoch 3016: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 51ms/step - loss: 0.5125 - accuracy: 0.8845\n","Epoch 3017/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.4937 - accuracy: 0.8825\n","Epoch 3017: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 54ms/step - loss: 0.4982 - accuracy: 0.8812\n","Epoch 3018/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.4513 - accuracy: 0.8902\n","Epoch 3018: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 51ms/step - loss: 0.4515 - accuracy: 0.8901\n","Epoch 3019/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.4199 - accuracy: 0.8977\n","Epoch 3019: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 52ms/step - loss: 0.4258 - accuracy: 0.8962\n","Epoch 3020/4000\n","8/8 [==============================] - ETA: 0s - loss: 0.4077 - accuracy: 0.8975\n","Epoch 3020: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 50ms/step - loss: 0.4077 - accuracy: 0.8975\n","Epoch 3021/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3866 - accuracy: 0.9007\n","Epoch 3021: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3870 - accuracy: 0.9007\n","Epoch 3022/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3729 - accuracy: 0.9008\n","Epoch 3022: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3769 - accuracy: 0.9002\n","Epoch 3023/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3641 - accuracy: 0.9023\n","Epoch 3023: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3685 - accuracy: 0.9011\n","Epoch 3024/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3597 - accuracy: 0.9004\n","Epoch 3024: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3611 - accuracy: 0.8997\n","Epoch 3025/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3491 - accuracy: 0.9026\n","Epoch 3025: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3547 - accuracy: 0.9006\n","Epoch 3026/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3486 - accuracy: 0.9029\n","Epoch 3026: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3500 - accuracy: 0.9031\n","Epoch 3027/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3423 - accuracy: 0.9014\n","Epoch 3027: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3440 - accuracy: 0.9007\n","Epoch 3028/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3424 - accuracy: 0.9014\n","Epoch 3028: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3442 - accuracy: 0.9003\n","Epoch 3029/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3377 - accuracy: 0.9016\n","Epoch 3029: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3401 - accuracy: 0.8997\n","Epoch 3030/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3374 - accuracy: 0.8993\n","Epoch 3030: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3386 - accuracy: 0.8993\n","Epoch 3031/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3325 - accuracy: 0.9021\n","Epoch 3031: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3353 - accuracy: 0.9006\n","Epoch 3032/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3348 - accuracy: 0.9012\n","Epoch 3032: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3364 - accuracy: 0.9006\n","Epoch 3033/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3252 - accuracy: 0.9046\n","Epoch 3033: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3328 - accuracy: 0.9021\n","Epoch 3034/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3320 - accuracy: 0.9046\n","Epoch 3034: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3332 - accuracy: 0.9033\n","Epoch 3035/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3341 - accuracy: 0.9018\n","Epoch 3035: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3317 - accuracy: 0.9023\n","Epoch 3036/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3239 - accuracy: 0.9035\n","Epoch 3036: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3298 - accuracy: 0.9009\n","Epoch 3037/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3297 - accuracy: 0.9000\n","Epoch 3037: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3282 - accuracy: 0.9009\n","Epoch 3038/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3285 - accuracy: 0.9016\n","Epoch 3038: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3297 - accuracy: 0.9014\n","Epoch 3039/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3307 - accuracy: 0.8996\n","Epoch 3039: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3289 - accuracy: 0.9003\n","Epoch 3040/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3242 - accuracy: 0.9009\n","Epoch 3040: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3265 - accuracy: 0.9001\n","Epoch 3041/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3240 - accuracy: 0.9011\n","Epoch 3041: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3268 - accuracy: 0.8992\n","Epoch 3042/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3246 - accuracy: 0.9012\n","Epoch 3042: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3294 - accuracy: 0.9002\n","Epoch 3043/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3277 - accuracy: 0.9022\n","Epoch 3043: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3289 - accuracy: 0.9021\n","Epoch 3044/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3307 - accuracy: 0.9008\n","Epoch 3044: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3304 - accuracy: 0.9010\n","Epoch 3045/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3297 - accuracy: 0.8994\n","Epoch 3045: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3289 - accuracy: 0.8996\n","Epoch 3046/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3225 - accuracy: 0.9032\n","Epoch 3046: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3270 - accuracy: 0.9009\n","Epoch 3047/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3303 - accuracy: 0.9014\n","Epoch 3047: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3294 - accuracy: 0.9014\n","Epoch 3048/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3238 - accuracy: 0.9021\n","Epoch 3048: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3279 - accuracy: 0.9006\n","Epoch 3049/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3307 - accuracy: 0.8998\n","Epoch 3049: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3288 - accuracy: 0.9003\n","Epoch 3050/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3202 - accuracy: 0.9036\n","Epoch 3050: loss did not improve from 0.32579\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3272 - accuracy: 0.9009\n","Epoch 3051/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3209 - accuracy: 0.9018\n","Epoch 3051: loss improved from 0.32579 to 0.32540, saving model to best_model_3.hdf5\n","8/8 [==============================] - 1s 109ms/step - loss: 0.3254 - accuracy: 0.8997\n","Epoch 3052/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3224 - accuracy: 0.9016\n","Epoch 3052: loss did not improve from 0.32540\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3266 - accuracy: 0.8999\n","Epoch 3053/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3306 - accuracy: 0.8990\n","Epoch 3053: loss did not improve from 0.32540\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3280 - accuracy: 0.9001\n","Epoch 3054/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3254 - accuracy: 0.9029\n","Epoch 3054: loss did not improve from 0.32540\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3285 - accuracy: 0.9010\n","Epoch 3055/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3256 - accuracy: 0.9009\n","Epoch 3055: loss did not improve from 0.32540\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3277 - accuracy: 0.8999\n","Epoch 3056/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3274 - accuracy: 0.9019\n","Epoch 3056: loss did not improve from 0.32540\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3296 - accuracy: 0.9014\n","Epoch 3057/4000\n","8/8 [==============================] - ETA: 0s - loss: 0.3250 - accuracy: 0.9029\n","Epoch 3057: loss improved from 0.32540 to 0.32498, saving model to best_model_3.hdf5\n","8/8 [==============================] - 1s 111ms/step - loss: 0.3250 - accuracy: 0.9029\n","Epoch 3058/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3281 - accuracy: 0.9004\n","Epoch 3058: loss did not improve from 0.32498\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3282 - accuracy: 0.9003\n","Epoch 3059/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3223 - accuracy: 0.9033\n","Epoch 3059: loss did not improve from 0.32498\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3260 - accuracy: 0.9020\n","Epoch 3060/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3264 - accuracy: 0.9005\n","Epoch 3060: loss improved from 0.32498 to 0.32382, saving model to best_model_3.hdf5\n","8/8 [==============================] - 1s 92ms/step - loss: 0.3238 - accuracy: 0.9011\n","Epoch 3061/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3318 - accuracy: 0.8991\n","Epoch 3061: loss did not improve from 0.32382\n","8/8 [==============================] - 0s 56ms/step - loss: 0.3281 - accuracy: 0.9001\n","Epoch 3062/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3184 - accuracy: 0.9043\n","Epoch 3062: loss did not improve from 0.32382\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3249 - accuracy: 0.9025\n","Epoch 3063/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3252 - accuracy: 0.9019\n","Epoch 3063: loss did not improve from 0.32382\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3270 - accuracy: 0.9014\n","Epoch 3064/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3218 - accuracy: 0.9042\n","Epoch 3064: loss did not improve from 0.32382\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3251 - accuracy: 0.9023\n","Epoch 3065/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3279 - accuracy: 0.9015\n","Epoch 3065: loss did not improve from 0.32382\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3297 - accuracy: 0.9007\n","Epoch 3066/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3209 - accuracy: 0.9018\n","Epoch 3066: loss did not improve from 0.32382\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3261 - accuracy: 0.9001\n","Epoch 3067/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3246 - accuracy: 0.9015\n","Epoch 3067: loss did not improve from 0.32382\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3266 - accuracy: 0.9006\n","Epoch 3068/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3242 - accuracy: 0.9016\n","Epoch 3068: loss did not improve from 0.32382\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3254 - accuracy: 0.9012\n","Epoch 3069/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3234 - accuracy: 0.9016\n","Epoch 3069: loss did not improve from 0.32382\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3272 - accuracy: 0.9009\n","Epoch 3070/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3196 - accuracy: 0.8989\n","Epoch 3070: loss did not improve from 0.32382\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3238 - accuracy: 0.8977\n","Epoch 3071/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3222 - accuracy: 0.9001\n","Epoch 3071: loss improved from 0.32382 to 0.32333, saving model to best_model_3.hdf5\n","8/8 [==============================] - 1s 103ms/step - loss: 0.3233 - accuracy: 0.9006\n","Epoch 3072/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3270 - accuracy: 0.9016\n","Epoch 3072: loss did not improve from 0.32333\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3296 - accuracy: 0.9007\n","Epoch 3073/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3237 - accuracy: 0.9016\n","Epoch 3073: loss did not improve from 0.32333\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3273 - accuracy: 0.8997\n","Epoch 3074/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3270 - accuracy: 0.8996\n","Epoch 3074: loss did not improve from 0.32333\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3296 - accuracy: 0.8996\n","Epoch 3075/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3233 - accuracy: 0.8994\n","Epoch 3075: loss did not improve from 0.32333\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3265 - accuracy: 0.8981\n","Epoch 3076/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3214 - accuracy: 0.9023\n","Epoch 3076: loss did not improve from 0.32333\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3272 - accuracy: 0.9003\n","Epoch 3077/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3248 - accuracy: 0.9008\n","Epoch 3077: loss improved from 0.32333 to 0.32275, saving model to best_model_3.hdf5\n","8/8 [==============================] - 1s 108ms/step - loss: 0.3228 - accuracy: 0.9019\n","Epoch 3078/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3250 - accuracy: 0.8975\n","Epoch 3078: loss did not improve from 0.32275\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3269 - accuracy: 0.8974\n","Epoch 3079/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3253 - accuracy: 0.9011\n","Epoch 3079: loss did not improve from 0.32275\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3257 - accuracy: 0.9010\n","Epoch 3080/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3196 - accuracy: 0.9018\n","Epoch 3080: loss did not improve from 0.32275\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3247 - accuracy: 0.8994\n","Epoch 3081/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3213 - accuracy: 0.9011\n","Epoch 3081: loss did not improve from 0.32275\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3232 - accuracy: 0.9001\n","Epoch 3082/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3214 - accuracy: 0.9026\n","Epoch 3082: loss did not improve from 0.32275\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3248 - accuracy: 0.9016\n","Epoch 3083/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3245 - accuracy: 0.9011\n","Epoch 3083: loss did not improve from 0.32275\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3266 - accuracy: 0.9001\n","Epoch 3084/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3256 - accuracy: 0.8993\n","Epoch 3084: loss did not improve from 0.32275\n","8/8 [==============================] - 0s 49ms/step - loss: 0.3255 - accuracy: 0.8992\n","Epoch 3085/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3176 - accuracy: 0.9046\n","Epoch 3085: loss improved from 0.32275 to 0.32239, saving model to best_model_3.hdf5\n","8/8 [==============================] - 1s 110ms/step - loss: 0.3224 - accuracy: 0.9021\n","Epoch 3086/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3208 - accuracy: 0.9026\n","Epoch 3086: loss did not improve from 0.32239\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3251 - accuracy: 0.9006\n","Epoch 3087/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3246 - accuracy: 0.8986\n","Epoch 3087: loss did not improve from 0.32239\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3267 - accuracy: 0.8977\n","Epoch 3088/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3236 - accuracy: 0.9008\n","Epoch 3088: loss did not improve from 0.32239\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3267 - accuracy: 0.8990\n","Epoch 3089/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3214 - accuracy: 0.9026\n","Epoch 3089: loss did not improve from 0.32239\n","8/8 [==============================] - 0s 56ms/step - loss: 0.3277 - accuracy: 0.9001\n","Epoch 3090/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3280 - accuracy: 0.9007\n","Epoch 3090: loss did not improve from 0.32239\n","8/8 [==============================] - 0s 48ms/step - loss: 0.3313 - accuracy: 0.8998\n","Epoch 3091/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3264 - accuracy: 0.9008\n","Epoch 3091: loss did not improve from 0.32239\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3269 - accuracy: 0.8999\n","Epoch 3092/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3201 - accuracy: 0.9043\n","Epoch 3092: loss did not improve from 0.32239\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3240 - accuracy: 0.9029\n","Epoch 3093/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3303 - accuracy: 0.8991\n","Epoch 3093: loss did not improve from 0.32239\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3271 - accuracy: 0.8996\n","Epoch 3094/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3280 - accuracy: 0.9032\n","Epoch 3094: loss did not improve from 0.32239\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3280 - accuracy: 0.9020\n","Epoch 3095/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3280 - accuracy: 0.8975\n","Epoch 3095: loss did not improve from 0.32239\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3250 - accuracy: 0.8988\n","Epoch 3096/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3203 - accuracy: 0.9029\n","Epoch 3096: loss did not improve from 0.32239\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3244 - accuracy: 0.9014\n","Epoch 3097/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3250 - accuracy: 0.9019\n","Epoch 3097: loss did not improve from 0.32239\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3241 - accuracy: 0.9018\n","Epoch 3098/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3186 - accuracy: 0.9044\n","Epoch 3098: loss did not improve from 0.32239\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3233 - accuracy: 0.9025\n","Epoch 3099/4000\n","8/8 [==============================] - ETA: 0s - loss: 0.3248 - accuracy: 0.9012\n","Epoch 3099: loss did not improve from 0.32239\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3248 - accuracy: 0.9012\n","Epoch 3100/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3328 - accuracy: 0.9003\n","Epoch 3100: loss did not improve from 0.32239\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3328 - accuracy: 0.8994\n","Epoch 3101/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3250 - accuracy: 0.9023\n","Epoch 3101: loss did not improve from 0.32239\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3268 - accuracy: 0.9015\n","Epoch 3102/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3275 - accuracy: 0.8991\n","Epoch 3102: loss did not improve from 0.32239\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3287 - accuracy: 0.8992\n","Epoch 3103/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3219 - accuracy: 0.9021\n","Epoch 3103: loss did not improve from 0.32239\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3279 - accuracy: 0.8989\n","Epoch 3104/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3264 - accuracy: 0.9032\n","Epoch 3104: loss did not improve from 0.32239\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3278 - accuracy: 0.9028\n","Epoch 3105/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3225 - accuracy: 0.9019\n","Epoch 3105: loss did not improve from 0.32239\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3287 - accuracy: 0.8997\n","Epoch 3106/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3274 - accuracy: 0.9005\n","Epoch 3106: loss did not improve from 0.32239\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3276 - accuracy: 0.9007\n","Epoch 3107/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3260 - accuracy: 0.8997\n","Epoch 3107: loss did not improve from 0.32239\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3247 - accuracy: 0.9001\n","Epoch 3108/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3183 - accuracy: 0.9035\n","Epoch 3108: loss did not improve from 0.32239\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3251 - accuracy: 0.9011\n","Epoch 3109/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3221 - accuracy: 0.9026\n","Epoch 3109: loss did not improve from 0.32239\n","8/8 [==============================] - 0s 49ms/step - loss: 0.3264 - accuracy: 0.9009\n","Epoch 3110/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3270 - accuracy: 0.9007\n","Epoch 3110: loss did not improve from 0.32239\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3277 - accuracy: 0.9002\n","Epoch 3111/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3225 - accuracy: 0.9016\n","Epoch 3111: loss did not improve from 0.32239\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3245 - accuracy: 0.9011\n","Epoch 3112/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3262 - accuracy: 0.9008\n","Epoch 3112: loss did not improve from 0.32239\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3259 - accuracy: 0.9009\n","Epoch 3113/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3280 - accuracy: 0.8986\n","Epoch 3113: loss did not improve from 0.32239\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3257 - accuracy: 0.8996\n","Epoch 3114/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3209 - accuracy: 0.9012\n","Epoch 3114: loss improved from 0.32239 to 0.32175, saving model to best_model_3.hdf5\n","8/8 [==============================] - 1s 108ms/step - loss: 0.3217 - accuracy: 0.9015\n","Epoch 3115/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3209 - accuracy: 0.9011\n","Epoch 3115: loss did not improve from 0.32175\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3250 - accuracy: 0.8998\n","Epoch 3116/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3240 - accuracy: 0.9046\n","Epoch 3116: loss did not improve from 0.32175\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3270 - accuracy: 0.9033\n","Epoch 3117/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3232 - accuracy: 0.9007\n","Epoch 3117: loss did not improve from 0.32175\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3265 - accuracy: 0.8990\n","Epoch 3118/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3177 - accuracy: 0.9025\n","Epoch 3118: loss improved from 0.32175 to 0.32123, saving model to best_model_3.hdf5\n","8/8 [==============================] - 1s 106ms/step - loss: 0.3212 - accuracy: 0.9018\n","Epoch 3119/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3273 - accuracy: 0.9014\n","Epoch 3119: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3297 - accuracy: 0.9003\n","Epoch 3120/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3312 - accuracy: 0.9000\n","Epoch 3120: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3281 - accuracy: 0.9014\n","Epoch 3121/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3258 - accuracy: 0.9028\n","Epoch 3121: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3274 - accuracy: 0.9016\n","Epoch 3122/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3194 - accuracy: 0.9032\n","Epoch 3122: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3266 - accuracy: 0.9009\n","Epoch 3123/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3251 - accuracy: 0.9001\n","Epoch 3123: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3251 - accuracy: 0.8998\n","Epoch 3124/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3236 - accuracy: 0.9014\n","Epoch 3124: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3280 - accuracy: 0.9003\n","Epoch 3125/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3271 - accuracy: 0.9029\n","Epoch 3125: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3271 - accuracy: 0.9023\n","Epoch 3126/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3246 - accuracy: 0.9003\n","Epoch 3126: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3246 - accuracy: 0.9007\n","Epoch 3127/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3280 - accuracy: 0.9009\n","Epoch 3127: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3247 - accuracy: 0.9016\n","Epoch 3128/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3224 - accuracy: 0.9019\n","Epoch 3128: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3246 - accuracy: 0.9012\n","Epoch 3129/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3291 - accuracy: 0.9023\n","Epoch 3129: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3270 - accuracy: 0.9021\n","Epoch 3130/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3211 - accuracy: 0.9015\n","Epoch 3130: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3247 - accuracy: 0.9006\n","Epoch 3131/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3208 - accuracy: 0.9011\n","Epoch 3131: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3242 - accuracy: 0.8998\n","Epoch 3132/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3192 - accuracy: 0.9012\n","Epoch 3132: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3219 - accuracy: 0.9005\n","Epoch 3133/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3250 - accuracy: 0.9018\n","Epoch 3133: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3267 - accuracy: 0.9014\n","Epoch 3134/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3222 - accuracy: 0.9001\n","Epoch 3134: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3245 - accuracy: 0.8998\n","Epoch 3135/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3208 - accuracy: 0.9036\n","Epoch 3135: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3245 - accuracy: 0.9018\n","Epoch 3136/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3175 - accuracy: 0.9028\n","Epoch 3136: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3241 - accuracy: 0.9003\n","Epoch 3137/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3221 - accuracy: 0.9003\n","Epoch 3137: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3228 - accuracy: 0.8996\n","Epoch 3138/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3204 - accuracy: 0.9030\n","Epoch 3138: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3257 - accuracy: 0.9016\n","Epoch 3139/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3271 - accuracy: 0.9008\n","Epoch 3139: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 56ms/step - loss: 0.3296 - accuracy: 0.9006\n","Epoch 3140/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3280 - accuracy: 0.9014\n","Epoch 3140: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3306 - accuracy: 0.8998\n","Epoch 3141/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3223 - accuracy: 0.9019\n","Epoch 3141: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3269 - accuracy: 0.8997\n","Epoch 3142/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3290 - accuracy: 0.8994\n","Epoch 3142: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3274 - accuracy: 0.8997\n","Epoch 3143/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3207 - accuracy: 0.9053\n","Epoch 3143: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3251 - accuracy: 0.9034\n","Epoch 3144/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3244 - accuracy: 0.9004\n","Epoch 3144: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3284 - accuracy: 0.8990\n","Epoch 3145/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3277 - accuracy: 0.9007\n","Epoch 3145: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3282 - accuracy: 0.8999\n","Epoch 3146/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3222 - accuracy: 0.9028\n","Epoch 3146: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3267 - accuracy: 0.9010\n","Epoch 3147/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3243 - accuracy: 0.9000\n","Epoch 3147: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3248 - accuracy: 0.8999\n","Epoch 3148/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3293 - accuracy: 0.8989\n","Epoch 3148: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3303 - accuracy: 0.8981\n","Epoch 3149/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3236 - accuracy: 0.9026\n","Epoch 3149: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3257 - accuracy: 0.9015\n","Epoch 3150/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3269 - accuracy: 0.9016\n","Epoch 3150: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3289 - accuracy: 0.9005\n","Epoch 3151/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3285 - accuracy: 0.9012\n","Epoch 3151: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3290 - accuracy: 0.9011\n","Epoch 3152/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3286 - accuracy: 0.8996\n","Epoch 3152: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3257 - accuracy: 0.8994\n","Epoch 3153/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3203 - accuracy: 0.9016\n","Epoch 3153: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3245 - accuracy: 0.8996\n","Epoch 3154/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3255 - accuracy: 0.8991\n","Epoch 3154: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3270 - accuracy: 0.8983\n","Epoch 3155/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3215 - accuracy: 0.9032\n","Epoch 3155: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3244 - accuracy: 0.9020\n","Epoch 3156/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3240 - accuracy: 0.9004\n","Epoch 3156: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3300 - accuracy: 0.8990\n","Epoch 3157/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3275 - accuracy: 0.9021\n","Epoch 3157: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3287 - accuracy: 0.9019\n","Epoch 3158/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3261 - accuracy: 0.9009\n","Epoch 3158: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3303 - accuracy: 0.8990\n","Epoch 3159/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3289 - accuracy: 0.9004\n","Epoch 3159: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3279 - accuracy: 0.9009\n","Epoch 3160/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3300 - accuracy: 0.8998\n","Epoch 3160: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3287 - accuracy: 0.9005\n","Epoch 3161/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3203 - accuracy: 0.9008\n","Epoch 3161: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3268 - accuracy: 0.8999\n","Epoch 3162/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3273 - accuracy: 0.9001\n","Epoch 3162: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3284 - accuracy: 0.8987\n","Epoch 3163/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3263 - accuracy: 0.8997\n","Epoch 3163: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3247 - accuracy: 0.8999\n","Epoch 3164/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3243 - accuracy: 0.9007\n","Epoch 3164: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3294 - accuracy: 0.8985\n","Epoch 3165/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3272 - accuracy: 0.9030\n","Epoch 3165: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3282 - accuracy: 0.9023\n","Epoch 3166/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3274 - accuracy: 0.9023\n","Epoch 3166: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3302 - accuracy: 0.9014\n","Epoch 3167/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3292 - accuracy: 0.9003\n","Epoch 3167: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3300 - accuracy: 0.8993\n","Epoch 3168/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3259 - accuracy: 0.9019\n","Epoch 3168: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3282 - accuracy: 0.9007\n","Epoch 3169/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3285 - accuracy: 0.8984\n","Epoch 3169: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3273 - accuracy: 0.8989\n","Epoch 3170/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3213 - accuracy: 0.9009\n","Epoch 3170: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3234 - accuracy: 0.8994\n","Epoch 3171/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3201 - accuracy: 0.9026\n","Epoch 3171: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3248 - accuracy: 0.9011\n","Epoch 3172/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3280 - accuracy: 0.9003\n","Epoch 3172: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3278 - accuracy: 0.9007\n","Epoch 3173/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3250 - accuracy: 0.9019\n","Epoch 3173: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3256 - accuracy: 0.9014\n","Epoch 3174/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3284 - accuracy: 0.9007\n","Epoch 3174: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3287 - accuracy: 0.8996\n","Epoch 3175/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3239 - accuracy: 0.9015\n","Epoch 3175: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 48ms/step - loss: 0.3253 - accuracy: 0.9009\n","Epoch 3176/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3210 - accuracy: 0.9040\n","Epoch 3176: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3253 - accuracy: 0.9025\n","Epoch 3177/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3261 - accuracy: 0.9028\n","Epoch 3177: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3294 - accuracy: 0.9015\n","Epoch 3178/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3244 - accuracy: 0.9012\n","Epoch 3178: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3262 - accuracy: 0.8990\n","Epoch 3179/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3211 - accuracy: 0.9009\n","Epoch 3179: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3236 - accuracy: 0.9007\n","Epoch 3180/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3232 - accuracy: 0.9029\n","Epoch 3180: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3259 - accuracy: 0.9020\n","Epoch 3181/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3238 - accuracy: 0.9019\n","Epoch 3181: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3247 - accuracy: 0.9010\n","Epoch 3182/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3246 - accuracy: 0.9018\n","Epoch 3182: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3261 - accuracy: 0.9010\n","Epoch 3183/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3289 - accuracy: 0.8990\n","Epoch 3183: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3266 - accuracy: 0.8992\n","Epoch 3184/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3237 - accuracy: 0.8986\n","Epoch 3184: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 56ms/step - loss: 0.3267 - accuracy: 0.8983\n","Epoch 3185/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3239 - accuracy: 0.9011\n","Epoch 3185: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3247 - accuracy: 0.9014\n","Epoch 3186/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3251 - accuracy: 0.9003\n","Epoch 3186: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3235 - accuracy: 0.9005\n","Epoch 3187/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3249 - accuracy: 0.8994\n","Epoch 3187: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3273 - accuracy: 0.8987\n","Epoch 3188/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3250 - accuracy: 0.9026\n","Epoch 3188: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3254 - accuracy: 0.9031\n","Epoch 3189/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3225 - accuracy: 0.9007\n","Epoch 3189: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3247 - accuracy: 0.8997\n","Epoch 3190/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3244 - accuracy: 0.9008\n","Epoch 3190: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3249 - accuracy: 0.9009\n","Epoch 3191/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3235 - accuracy: 0.9004\n","Epoch 3191: loss did not improve from 0.32123\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3231 - accuracy: 0.8999\n","Epoch 3192/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3220 - accuracy: 0.9018\n","Epoch 3192: loss improved from 0.32123 to 0.32110, saving model to best_model_3.hdf5\n","8/8 [==============================] - 1s 106ms/step - loss: 0.3211 - accuracy: 0.9019\n","Epoch 3193/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3191 - accuracy: 0.8998\n","Epoch 3193: loss improved from 0.32110 to 0.32027, saving model to best_model_3.hdf5\n","8/8 [==============================] - 1s 98ms/step - loss: 0.3203 - accuracy: 0.8993\n","Epoch 3194/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3198 - accuracy: 0.9012\n","Epoch 3194: loss did not improve from 0.32027\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3208 - accuracy: 0.9006\n","Epoch 3195/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3171 - accuracy: 0.9019\n","Epoch 3195: loss did not improve from 0.32027\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3216 - accuracy: 0.9005\n","Epoch 3196/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3176 - accuracy: 0.9019\n","Epoch 3196: loss did not improve from 0.32027\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3239 - accuracy: 0.8992\n","Epoch 3197/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3229 - accuracy: 0.9023\n","Epoch 3197: loss did not improve from 0.32027\n","8/8 [==============================] - 0s 49ms/step - loss: 0.3235 - accuracy: 0.9021\n","Epoch 3198/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3284 - accuracy: 0.9011\n","Epoch 3198: loss did not improve from 0.32027\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3287 - accuracy: 0.9007\n","Epoch 3199/4000\n","8/8 [==============================] - ETA: 0s - loss: 0.3280 - accuracy: 0.9010\n","Epoch 3199: loss did not improve from 0.32027\n","8/8 [==============================] - 0s 48ms/step - loss: 0.3280 - accuracy: 0.9010\n","Epoch 3200/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3191 - accuracy: 0.9011\n","Epoch 3200: loss did not improve from 0.32027\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3237 - accuracy: 0.9003\n","Epoch 3201/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3233 - accuracy: 0.9004\n","Epoch 3201: loss did not improve from 0.32027\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3241 - accuracy: 0.8997\n","Epoch 3202/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3214 - accuracy: 0.9012\n","Epoch 3202: loss did not improve from 0.32027\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3249 - accuracy: 0.9001\n","Epoch 3203/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3274 - accuracy: 0.8965\n","Epoch 3203: loss did not improve from 0.32027\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3245 - accuracy: 0.8977\n","Epoch 3204/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3193 - accuracy: 0.9021\n","Epoch 3204: loss did not improve from 0.32027\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3246 - accuracy: 0.9006\n","Epoch 3205/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3272 - accuracy: 0.9025\n","Epoch 3205: loss did not improve from 0.32027\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3247 - accuracy: 0.9027\n","Epoch 3206/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3302 - accuracy: 0.9007\n","Epoch 3206: loss did not improve from 0.32027\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3322 - accuracy: 0.9011\n","Epoch 3207/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3306 - accuracy: 0.9009\n","Epoch 3207: loss did not improve from 0.32027\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3349 - accuracy: 0.8994\n","Epoch 3208/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3259 - accuracy: 0.9012\n","Epoch 3208: loss did not improve from 0.32027\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3359 - accuracy: 0.8981\n","Epoch 3209/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3351 - accuracy: 0.8998\n","Epoch 3209: loss did not improve from 0.32027\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3371 - accuracy: 0.8993\n","Epoch 3210/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3337 - accuracy: 0.8994\n","Epoch 3210: loss did not improve from 0.32027\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3349 - accuracy: 0.8984\n","Epoch 3211/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3296 - accuracy: 0.9030\n","Epoch 3211: loss did not improve from 0.32027\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3352 - accuracy: 0.9016\n","Epoch 3212/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3340 - accuracy: 0.8970\n","Epoch 3212: loss did not improve from 0.32027\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3348 - accuracy: 0.8975\n","Epoch 3213/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3269 - accuracy: 0.9032\n","Epoch 3213: loss did not improve from 0.32027\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3321 - accuracy: 0.9023\n","Epoch 3214/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3283 - accuracy: 0.8994\n","Epoch 3214: loss did not improve from 0.32027\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3293 - accuracy: 0.8996\n","Epoch 3215/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3305 - accuracy: 0.8982\n","Epoch 3215: loss did not improve from 0.32027\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3334 - accuracy: 0.8975\n","Epoch 3216/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3267 - accuracy: 0.8986\n","Epoch 3216: loss did not improve from 0.32027\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3261 - accuracy: 0.8980\n","Epoch 3217/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3265 - accuracy: 0.9019\n","Epoch 3217: loss did not improve from 0.32027\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3238 - accuracy: 0.9033\n","Epoch 3218/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3273 - accuracy: 0.8997\n","Epoch 3218: loss did not improve from 0.32027\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3259 - accuracy: 0.8998\n","Epoch 3219/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3197 - accuracy: 0.9009\n","Epoch 3219: loss did not improve from 0.32027\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3227 - accuracy: 0.8999\n","Epoch 3220/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3260 - accuracy: 0.9007\n","Epoch 3220: loss did not improve from 0.32027\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3255 - accuracy: 0.9011\n","Epoch 3221/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3259 - accuracy: 0.9007\n","Epoch 3221: loss did not improve from 0.32027\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3244 - accuracy: 0.9011\n","Epoch 3222/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3184 - accuracy: 0.9007\n","Epoch 3222: loss did not improve from 0.32027\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3222 - accuracy: 0.8994\n","Epoch 3223/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3214 - accuracy: 0.9003\n","Epoch 3223: loss did not improve from 0.32027\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3230 - accuracy: 0.8992\n","Epoch 3224/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3278 - accuracy: 0.8987\n","Epoch 3224: loss did not improve from 0.32027\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3258 - accuracy: 0.8996\n","Epoch 3225/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3172 - accuracy: 0.9026\n","Epoch 3225: loss did not improve from 0.32027\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3244 - accuracy: 0.9002\n","Epoch 3226/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3251 - accuracy: 0.8996\n","Epoch 3226: loss did not improve from 0.32027\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3255 - accuracy: 0.8997\n","Epoch 3227/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3200 - accuracy: 0.8997\n","Epoch 3227: loss did not improve from 0.32027\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3222 - accuracy: 0.9001\n","Epoch 3228/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3211 - accuracy: 0.9007\n","Epoch 3228: loss did not improve from 0.32027\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3216 - accuracy: 0.9005\n","Epoch 3229/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3266 - accuracy: 0.8991\n","Epoch 3229: loss did not improve from 0.32027\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3232 - accuracy: 0.9009\n","Epoch 3230/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3204 - accuracy: 0.8990\n","Epoch 3230: loss did not improve from 0.32027\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3207 - accuracy: 0.8990\n","Epoch 3231/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3235 - accuracy: 0.9015\n","Epoch 3231: loss did not improve from 0.32027\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3240 - accuracy: 0.9018\n","Epoch 3232/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3237 - accuracy: 0.8998\n","Epoch 3232: loss did not improve from 0.32027\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3241 - accuracy: 0.8996\n","Epoch 3233/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3240 - accuracy: 0.9003\n","Epoch 3233: loss did not improve from 0.32027\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3238 - accuracy: 0.8996\n","Epoch 3234/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3267 - accuracy: 0.8989\n","Epoch 3234: loss did not improve from 0.32027\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3248 - accuracy: 0.8994\n","Epoch 3235/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3294 - accuracy: 0.8994\n","Epoch 3235: loss did not improve from 0.32027\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3236 - accuracy: 0.8998\n","Epoch 3236/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3220 - accuracy: 0.8987\n","Epoch 3236: loss did not improve from 0.32027\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3240 - accuracy: 0.8983\n","Epoch 3237/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3179 - accuracy: 0.9025\n","Epoch 3237: loss did not improve from 0.32027\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3212 - accuracy: 0.9019\n","Epoch 3238/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3271 - accuracy: 0.9012\n","Epoch 3238: loss did not improve from 0.32027\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3258 - accuracy: 0.9014\n","Epoch 3239/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3209 - accuracy: 0.9021\n","Epoch 3239: loss did not improve from 0.32027\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3218 - accuracy: 0.9016\n","Epoch 3240/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3222 - accuracy: 0.9001\n","Epoch 3240: loss improved from 0.32027 to 0.32010, saving model to best_model_3.hdf5\n","8/8 [==============================] - 1s 114ms/step - loss: 0.3201 - accuracy: 0.9009\n","Epoch 3241/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3246 - accuracy: 0.8997\n","Epoch 3241: loss did not improve from 0.32010\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3240 - accuracy: 0.8994\n","Epoch 3242/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3164 - accuracy: 0.9018\n","Epoch 3242: loss did not improve from 0.32010\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3205 - accuracy: 0.9006\n","Epoch 3243/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3241 - accuracy: 0.9016\n","Epoch 3243: loss did not improve from 0.32010\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3259 - accuracy: 0.9001\n","Epoch 3244/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3287 - accuracy: 0.8983\n","Epoch 3244: loss did not improve from 0.32010\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3281 - accuracy: 0.8988\n","Epoch 3245/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3226 - accuracy: 0.9014\n","Epoch 3245: loss did not improve from 0.32010\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3239 - accuracy: 0.9012\n","Epoch 3246/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3158 - accuracy: 0.9040\n","Epoch 3246: loss did not improve from 0.32010\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3222 - accuracy: 0.9016\n","Epoch 3247/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3240 - accuracy: 0.8987\n","Epoch 3247: loss did not improve from 0.32010\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3247 - accuracy: 0.8983\n","Epoch 3248/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3217 - accuracy: 0.8987\n","Epoch 3248: loss did not improve from 0.32010\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3210 - accuracy: 0.8989\n","Epoch 3249/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3235 - accuracy: 0.9011\n","Epoch 3249: loss did not improve from 0.32010\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3259 - accuracy: 0.8996\n","Epoch 3250/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3136 - accuracy: 0.9015\n","Epoch 3250: loss improved from 0.32010 to 0.31912, saving model to best_model_3.hdf5\n","8/8 [==============================] - 1s 108ms/step - loss: 0.3191 - accuracy: 0.8996\n","Epoch 3251/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3232 - accuracy: 0.8998\n","Epoch 3251: loss did not improve from 0.31912\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3253 - accuracy: 0.8989\n","Epoch 3252/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3202 - accuracy: 0.9018\n","Epoch 3252: loss did not improve from 0.31912\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3242 - accuracy: 0.8998\n","Epoch 3253/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3223 - accuracy: 0.9018\n","Epoch 3253: loss did not improve from 0.31912\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3253 - accuracy: 0.9009\n","Epoch 3254/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3237 - accuracy: 0.9001\n","Epoch 3254: loss did not improve from 0.31912\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3233 - accuracy: 0.9001\n","Epoch 3255/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3220 - accuracy: 0.9019\n","Epoch 3255: loss did not improve from 0.31912\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3237 - accuracy: 0.9007\n","Epoch 3256/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3234 - accuracy: 0.8996\n","Epoch 3256: loss did not improve from 0.31912\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3233 - accuracy: 0.8992\n","Epoch 3257/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3192 - accuracy: 0.9022\n","Epoch 3257: loss did not improve from 0.31912\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3241 - accuracy: 0.9003\n","Epoch 3258/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3260 - accuracy: 0.9009\n","Epoch 3258: loss did not improve from 0.31912\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3249 - accuracy: 0.9014\n","Epoch 3259/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3223 - accuracy: 0.9001\n","Epoch 3259: loss did not improve from 0.31912\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3220 - accuracy: 0.8994\n","Epoch 3260/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3228 - accuracy: 0.9007\n","Epoch 3260: loss did not improve from 0.31912\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3218 - accuracy: 0.9009\n","Epoch 3261/4000\n","8/8 [==============================] - ETA: 0s - loss: 0.3191 - accuracy: 0.9009\n","Epoch 3261: loss improved from 0.31912 to 0.31911, saving model to best_model_3.hdf5\n","8/8 [==============================] - 1s 103ms/step - loss: 0.3191 - accuracy: 0.9009\n","Epoch 3262/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3128 - accuracy: 0.9039\n","Epoch 3262: loss improved from 0.31911 to 0.31749, saving model to best_model_3.hdf5\n","8/8 [==============================] - 1s 105ms/step - loss: 0.3175 - accuracy: 0.9024\n","Epoch 3263/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3188 - accuracy: 0.8997\n","Epoch 3263: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3180 - accuracy: 0.8990\n","Epoch 3264/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3269 - accuracy: 0.8977\n","Epoch 3264: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3244 - accuracy: 0.8976\n","Epoch 3265/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3235 - accuracy: 0.9028\n","Epoch 3265: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3238 - accuracy: 0.9031\n","Epoch 3266/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3218 - accuracy: 0.9009\n","Epoch 3266: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3267 - accuracy: 0.8994\n","Epoch 3267/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3291 - accuracy: 0.8994\n","Epoch 3267: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3284 - accuracy: 0.8997\n","Epoch 3268/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3221 - accuracy: 0.9029\n","Epoch 3268: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3250 - accuracy: 0.9010\n","Epoch 3269/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3274 - accuracy: 0.9012\n","Epoch 3269: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3271 - accuracy: 0.9014\n","Epoch 3270/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3209 - accuracy: 0.9008\n","Epoch 3270: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3255 - accuracy: 0.8994\n","Epoch 3271/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3275 - accuracy: 0.9005\n","Epoch 3271: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3286 - accuracy: 0.8996\n","Epoch 3272/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3174 - accuracy: 0.9054\n","Epoch 3272: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3246 - accuracy: 0.9027\n","Epoch 3273/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3259 - accuracy: 0.9015\n","Epoch 3273: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 49ms/step - loss: 0.3265 - accuracy: 0.9010\n","Epoch 3274/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3225 - accuracy: 0.9035\n","Epoch 3274: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3306 - accuracy: 0.9009\n","Epoch 3275/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3343 - accuracy: 0.8986\n","Epoch 3275: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3305 - accuracy: 0.8987\n","Epoch 3276/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3338 - accuracy: 0.8996\n","Epoch 3276: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3310 - accuracy: 0.9002\n","Epoch 3277/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3257 - accuracy: 0.9012\n","Epoch 3277: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3292 - accuracy: 0.8999\n","Epoch 3278/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3248 - accuracy: 0.9018\n","Epoch 3278: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3287 - accuracy: 0.9010\n","Epoch 3279/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3291 - accuracy: 0.9001\n","Epoch 3279: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3292 - accuracy: 0.8996\n","Epoch 3280/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3242 - accuracy: 0.9015\n","Epoch 3280: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3267 - accuracy: 0.9014\n","Epoch 3281/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3231 - accuracy: 0.8998\n","Epoch 3281: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3273 - accuracy: 0.8988\n","Epoch 3282/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3279 - accuracy: 0.9023\n","Epoch 3282: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3286 - accuracy: 0.9019\n","Epoch 3283/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3223 - accuracy: 0.9040\n","Epoch 3283: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3275 - accuracy: 0.9027\n","Epoch 3284/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3215 - accuracy: 0.9016\n","Epoch 3284: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3253 - accuracy: 0.9002\n","Epoch 3285/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3282 - accuracy: 0.9019\n","Epoch 3285: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3287 - accuracy: 0.9020\n","Epoch 3286/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3275 - accuracy: 0.9009\n","Epoch 3286: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3268 - accuracy: 0.9009\n","Epoch 3287/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3315 - accuracy: 0.8997\n","Epoch 3287: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3301 - accuracy: 0.8999\n","Epoch 3288/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3209 - accuracy: 0.9016\n","Epoch 3288: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3265 - accuracy: 0.9001\n","Epoch 3289/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3238 - accuracy: 0.8993\n","Epoch 3289: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3269 - accuracy: 0.8979\n","Epoch 3290/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3222 - accuracy: 0.9008\n","Epoch 3290: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3258 - accuracy: 0.8999\n","Epoch 3291/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3249 - accuracy: 0.8984\n","Epoch 3291: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3214 - accuracy: 0.8999\n","Epoch 3292/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3216 - accuracy: 0.8989\n","Epoch 3292: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3224 - accuracy: 0.8987\n","Epoch 3293/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3171 - accuracy: 0.9021\n","Epoch 3293: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3232 - accuracy: 0.8998\n","Epoch 3294/4000\n","8/8 [==============================] - ETA: 0s - loss: 0.3210 - accuracy: 0.9011\n","Epoch 3294: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3210 - accuracy: 0.9011\n","Epoch 3295/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3151 - accuracy: 0.9029\n","Epoch 3295: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 49ms/step - loss: 0.3219 - accuracy: 0.8996\n","Epoch 3296/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3181 - accuracy: 0.9005\n","Epoch 3296: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3200 - accuracy: 0.9005\n","Epoch 3297/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3205 - accuracy: 0.9021\n","Epoch 3297: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3240 - accuracy: 0.9012\n","Epoch 3298/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3231 - accuracy: 0.9007\n","Epoch 3298: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3232 - accuracy: 0.9003\n","Epoch 3299/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3240 - accuracy: 0.9040\n","Epoch 3299: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3246 - accuracy: 0.9033\n","Epoch 3300/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3233 - accuracy: 0.9000\n","Epoch 3300: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 49ms/step - loss: 0.3241 - accuracy: 0.9003\n","Epoch 3301/4000\n","8/8 [==============================] - ETA: 0s - loss: 0.3224 - accuracy: 0.9011\n","Epoch 3301: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3224 - accuracy: 0.9011\n","Epoch 3302/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3165 - accuracy: 0.9001\n","Epoch 3302: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3229 - accuracy: 0.8974\n","Epoch 3303/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3263 - accuracy: 0.9003\n","Epoch 3303: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3265 - accuracy: 0.9003\n","Epoch 3304/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3195 - accuracy: 0.9028\n","Epoch 3304: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 56ms/step - loss: 0.3240 - accuracy: 0.9018\n","Epoch 3305/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3218 - accuracy: 0.9028\n","Epoch 3305: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3254 - accuracy: 0.8999\n","Epoch 3306/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3236 - accuracy: 0.9001\n","Epoch 3306: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3266 - accuracy: 0.8993\n","Epoch 3307/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3198 - accuracy: 0.9040\n","Epoch 3307: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3268 - accuracy: 0.9016\n","Epoch 3308/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3286 - accuracy: 0.8991\n","Epoch 3308: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3267 - accuracy: 0.9002\n","Epoch 3309/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3215 - accuracy: 0.9011\n","Epoch 3309: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3276 - accuracy: 0.8999\n","Epoch 3310/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3260 - accuracy: 0.9033\n","Epoch 3310: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3315 - accuracy: 0.9007\n","Epoch 3311/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3322 - accuracy: 0.9005\n","Epoch 3311: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3339 - accuracy: 0.9003\n","Epoch 3312/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3337 - accuracy: 0.9026\n","Epoch 3312: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3356 - accuracy: 0.9018\n","Epoch 3313/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3354 - accuracy: 0.8990\n","Epoch 3313: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3392 - accuracy: 0.8979\n","Epoch 3314/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3421 - accuracy: 0.9005\n","Epoch 3314: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3459 - accuracy: 0.8985\n","Epoch 3315/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3490 - accuracy: 0.8980\n","Epoch 3315: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3509 - accuracy: 0.8971\n","Epoch 3316/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3615 - accuracy: 0.8956\n","Epoch 3316: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3644 - accuracy: 0.8944\n","Epoch 3317/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3817 - accuracy: 0.8891\n","Epoch 3317: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3834 - accuracy: 0.8887\n","Epoch 3318/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.4273 - accuracy: 0.8806\n","Epoch 3318: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 49ms/step - loss: 0.4488 - accuracy: 0.8741\n","Epoch 3319/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.6032 - accuracy: 0.8415\n","Epoch 3319: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 52ms/step - loss: 0.6195 - accuracy: 0.8377\n","Epoch 3320/4000\n","8/8 [==============================] - ETA: 0s - loss: 0.7664 - accuracy: 0.8108\n","Epoch 3320: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 53ms/step - loss: 0.7664 - accuracy: 0.8108\n","Epoch 3321/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.7935 - accuracy: 0.8128\n","Epoch 3321: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 50ms/step - loss: 0.7940 - accuracy: 0.8121\n","Epoch 3322/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.8225 - accuracy: 0.8072\n","Epoch 3322: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 54ms/step - loss: 0.8319 - accuracy: 0.8055\n","Epoch 3323/4000\n","8/8 [==============================] - ETA: 0s - loss: 0.8590 - accuracy: 0.8078\n","Epoch 3323: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 50ms/step - loss: 0.8590 - accuracy: 0.8078\n","Epoch 3324/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.8113 - accuracy: 0.8175\n","Epoch 3324: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 53ms/step - loss: 0.8231 - accuracy: 0.8145\n","Epoch 3325/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.7663 - accuracy: 0.8337\n","Epoch 3325: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 51ms/step - loss: 0.7706 - accuracy: 0.8315\n","Epoch 3326/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.7193 - accuracy: 0.8390\n","Epoch 3326: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 52ms/step - loss: 0.7180 - accuracy: 0.8394\n","Epoch 3327/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.6497 - accuracy: 0.8601\n","Epoch 3327: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 51ms/step - loss: 0.6549 - accuracy: 0.8579\n","Epoch 3328/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.6068 - accuracy: 0.8676\n","Epoch 3328: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 53ms/step - loss: 0.6095 - accuracy: 0.8662\n","Epoch 3329/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.5761 - accuracy: 0.8733\n","Epoch 3329: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 52ms/step - loss: 0.5760 - accuracy: 0.8738\n","Epoch 3330/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.5264 - accuracy: 0.8845\n","Epoch 3330: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 55ms/step - loss: 0.5279 - accuracy: 0.8835\n","Epoch 3331/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.4850 - accuracy: 0.8910\n","Epoch 3331: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 52ms/step - loss: 0.4895 - accuracy: 0.8888\n","Epoch 3332/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.4567 - accuracy: 0.8915\n","Epoch 3332: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 54ms/step - loss: 0.4600 - accuracy: 0.8908\n","Epoch 3333/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.4304 - accuracy: 0.8961\n","Epoch 3333: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 52ms/step - loss: 0.4345 - accuracy: 0.8953\n","Epoch 3334/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.4147 - accuracy: 0.8989\n","Epoch 3334: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 53ms/step - loss: 0.4189 - accuracy: 0.8971\n","Epoch 3335/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3934 - accuracy: 0.9008\n","Epoch 3335: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3953 - accuracy: 0.8989\n","Epoch 3336/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3792 - accuracy: 0.8993\n","Epoch 3336: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3836 - accuracy: 0.8977\n","Epoch 3337/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3689 - accuracy: 0.9014\n","Epoch 3337: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3723 - accuracy: 0.8996\n","Epoch 3338/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3574 - accuracy: 0.9029\n","Epoch 3338: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3637 - accuracy: 0.9006\n","Epoch 3339/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3494 - accuracy: 0.9032\n","Epoch 3339: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3538 - accuracy: 0.9019\n","Epoch 3340/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3492 - accuracy: 0.8983\n","Epoch 3340: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3485 - accuracy: 0.8993\n","Epoch 3341/4000\n","8/8 [==============================] - ETA: 0s - loss: 0.3428 - accuracy: 0.8987\n","Epoch 3341: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3428 - accuracy: 0.8987\n","Epoch 3342/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3374 - accuracy: 0.9023\n","Epoch 3342: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3381 - accuracy: 0.9021\n","Epoch 3343/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3344 - accuracy: 0.9012\n","Epoch 3343: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3342 - accuracy: 0.9005\n","Epoch 3344/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3305 - accuracy: 0.9037\n","Epoch 3344: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3312 - accuracy: 0.9033\n","Epoch 3345/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3271 - accuracy: 0.9044\n","Epoch 3345: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3314 - accuracy: 0.9023\n","Epoch 3346/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3309 - accuracy: 0.9015\n","Epoch 3346: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3287 - accuracy: 0.9016\n","Epoch 3347/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3236 - accuracy: 0.9011\n","Epoch 3347: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3270 - accuracy: 0.8996\n","Epoch 3348/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3334 - accuracy: 0.8994\n","Epoch 3348: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3305 - accuracy: 0.9002\n","Epoch 3349/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3233 - accuracy: 0.9008\n","Epoch 3349: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3267 - accuracy: 0.9002\n","Epoch 3350/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3216 - accuracy: 0.9029\n","Epoch 3350: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3246 - accuracy: 0.9020\n","Epoch 3351/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3245 - accuracy: 0.9029\n","Epoch 3351: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3249 - accuracy: 0.9019\n","Epoch 3352/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3221 - accuracy: 0.9001\n","Epoch 3352: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3235 - accuracy: 0.8987\n","Epoch 3353/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3197 - accuracy: 0.9012\n","Epoch 3353: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3240 - accuracy: 0.8993\n","Epoch 3354/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3231 - accuracy: 0.9018\n","Epoch 3354: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3241 - accuracy: 0.9011\n","Epoch 3355/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3207 - accuracy: 0.9007\n","Epoch 3355: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3248 - accuracy: 0.8987\n","Epoch 3356/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3243 - accuracy: 0.9018\n","Epoch 3356: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3232 - accuracy: 0.9014\n","Epoch 3357/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3220 - accuracy: 0.9000\n","Epoch 3357: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3217 - accuracy: 0.9003\n","Epoch 3358/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3205 - accuracy: 0.9022\n","Epoch 3358: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3253 - accuracy: 0.9007\n","Epoch 3359/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3187 - accuracy: 0.8997\n","Epoch 3359: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3209 - accuracy: 0.8998\n","Epoch 3360/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3248 - accuracy: 0.9009\n","Epoch 3360: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3244 - accuracy: 0.9010\n","Epoch 3361/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3138 - accuracy: 0.9036\n","Epoch 3361: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3201 - accuracy: 0.9016\n","Epoch 3362/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3199 - accuracy: 0.9008\n","Epoch 3362: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3195 - accuracy: 0.9007\n","Epoch 3363/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3213 - accuracy: 0.9018\n","Epoch 3363: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3195 - accuracy: 0.9027\n","Epoch 3364/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3188 - accuracy: 0.9026\n","Epoch 3364: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3194 - accuracy: 0.9014\n","Epoch 3365/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3166 - accuracy: 0.9042\n","Epoch 3365: loss did not improve from 0.31749\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3197 - accuracy: 0.9034\n","Epoch 3366/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3135 - accuracy: 0.9012\n","Epoch 3366: loss improved from 0.31749 to 0.31482, saving model to best_model_3.hdf5\n","8/8 [==============================] - 1s 108ms/step - loss: 0.3148 - accuracy: 0.9010\n","Epoch 3367/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3168 - accuracy: 0.8991\n","Epoch 3367: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3156 - accuracy: 0.8994\n","Epoch 3368/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3158 - accuracy: 0.9003\n","Epoch 3368: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3187 - accuracy: 0.8994\n","Epoch 3369/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3132 - accuracy: 0.9035\n","Epoch 3369: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3174 - accuracy: 0.9011\n","Epoch 3370/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3165 - accuracy: 0.9021\n","Epoch 3370: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3186 - accuracy: 0.9010\n","Epoch 3371/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3137 - accuracy: 0.8993\n","Epoch 3371: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 56ms/step - loss: 0.3194 - accuracy: 0.8979\n","Epoch 3372/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3152 - accuracy: 0.9040\n","Epoch 3372: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3205 - accuracy: 0.9018\n","Epoch 3373/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3148 - accuracy: 0.9018\n","Epoch 3373: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3221 - accuracy: 0.8993\n","Epoch 3374/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3155 - accuracy: 0.9015\n","Epoch 3374: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3196 - accuracy: 0.8998\n","Epoch 3375/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3152 - accuracy: 0.9025\n","Epoch 3375: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3168 - accuracy: 0.9023\n","Epoch 3376/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3180 - accuracy: 0.8993\n","Epoch 3376: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3181 - accuracy: 0.8992\n","Epoch 3377/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3177 - accuracy: 0.9035\n","Epoch 3377: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3194 - accuracy: 0.9027\n","Epoch 3378/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3165 - accuracy: 0.9015\n","Epoch 3378: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3223 - accuracy: 0.8998\n","Epoch 3379/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3230 - accuracy: 0.9008\n","Epoch 3379: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3213 - accuracy: 0.9001\n","Epoch 3380/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3164 - accuracy: 0.9037\n","Epoch 3380: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3204 - accuracy: 0.9027\n","Epoch 3381/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3180 - accuracy: 0.9023\n","Epoch 3381: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3192 - accuracy: 0.9011\n","Epoch 3382/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3210 - accuracy: 0.9015\n","Epoch 3382: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3197 - accuracy: 0.9025\n","Epoch 3383/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3099 - accuracy: 0.9014\n","Epoch 3383: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3184 - accuracy: 0.8989\n","Epoch 3384/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3118 - accuracy: 0.9039\n","Epoch 3384: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3183 - accuracy: 0.9014\n","Epoch 3385/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3190 - accuracy: 0.8996\n","Epoch 3385: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3192 - accuracy: 0.8993\n","Epoch 3386/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3182 - accuracy: 0.9023\n","Epoch 3386: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3209 - accuracy: 0.8999\n","Epoch 3387/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3159 - accuracy: 0.9030\n","Epoch 3387: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3188 - accuracy: 0.9016\n","Epoch 3388/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3203 - accuracy: 0.9007\n","Epoch 3388: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3191 - accuracy: 0.9006\n","Epoch 3389/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3101 - accuracy: 0.9033\n","Epoch 3389: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3171 - accuracy: 0.9010\n","Epoch 3390/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3183 - accuracy: 0.9015\n","Epoch 3390: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3191 - accuracy: 0.9011\n","Epoch 3391/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3243 - accuracy: 0.8987\n","Epoch 3391: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3205 - accuracy: 0.9006\n","Epoch 3392/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3192 - accuracy: 0.9000\n","Epoch 3392: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3197 - accuracy: 0.9003\n","Epoch 3393/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3223 - accuracy: 0.8993\n","Epoch 3393: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3209 - accuracy: 0.8998\n","Epoch 3394/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3182 - accuracy: 0.9023\n","Epoch 3394: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3182 - accuracy: 0.9015\n","Epoch 3395/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3179 - accuracy: 0.9005\n","Epoch 3395: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3164 - accuracy: 0.9010\n","Epoch 3396/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3162 - accuracy: 0.8979\n","Epoch 3396: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3177 - accuracy: 0.8976\n","Epoch 3397/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3146 - accuracy: 0.9003\n","Epoch 3397: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3161 - accuracy: 0.8996\n","Epoch 3398/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3154 - accuracy: 0.8996\n","Epoch 3398: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3194 - accuracy: 0.8992\n","Epoch 3399/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3176 - accuracy: 0.8977\n","Epoch 3399: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3198 - accuracy: 0.8965\n","Epoch 3400/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3187 - accuracy: 0.9026\n","Epoch 3400: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3212 - accuracy: 0.9014\n","Epoch 3401/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3168 - accuracy: 0.9023\n","Epoch 3401: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3192 - accuracy: 0.9009\n","Epoch 3402/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3172 - accuracy: 0.9016\n","Epoch 3402: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3198 - accuracy: 0.8999\n","Epoch 3403/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3157 - accuracy: 0.9019\n","Epoch 3403: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3162 - accuracy: 0.9014\n","Epoch 3404/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3205 - accuracy: 0.8976\n","Epoch 3404: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3224 - accuracy: 0.8968\n","Epoch 3405/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3209 - accuracy: 0.9007\n","Epoch 3405: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3186 - accuracy: 0.9014\n","Epoch 3406/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3181 - accuracy: 0.9001\n","Epoch 3406: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3167 - accuracy: 0.9006\n","Epoch 3407/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3163 - accuracy: 0.9025\n","Epoch 3407: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3179 - accuracy: 0.9012\n","Epoch 3408/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3218 - accuracy: 0.8987\n","Epoch 3408: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3224 - accuracy: 0.8983\n","Epoch 3409/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3133 - accuracy: 0.9018\n","Epoch 3409: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3171 - accuracy: 0.9005\n","Epoch 3410/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3149 - accuracy: 0.9021\n","Epoch 3410: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3195 - accuracy: 0.8998\n","Epoch 3411/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3136 - accuracy: 0.9011\n","Epoch 3411: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3174 - accuracy: 0.8992\n","Epoch 3412/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3161 - accuracy: 0.9000\n","Epoch 3412: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3169 - accuracy: 0.9006\n","Epoch 3413/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3210 - accuracy: 0.9001\n","Epoch 3413: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3207 - accuracy: 0.8997\n","Epoch 3414/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3146 - accuracy: 0.9032\n","Epoch 3414: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3178 - accuracy: 0.9015\n","Epoch 3415/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3106 - accuracy: 0.9016\n","Epoch 3415: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3165 - accuracy: 0.8992\n","Epoch 3416/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3161 - accuracy: 0.9026\n","Epoch 3416: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3196 - accuracy: 0.9014\n","Epoch 3417/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3125 - accuracy: 0.9037\n","Epoch 3417: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3158 - accuracy: 0.9021\n","Epoch 3418/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3189 - accuracy: 0.8998\n","Epoch 3418: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3166 - accuracy: 0.9005\n","Epoch 3419/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3131 - accuracy: 0.9019\n","Epoch 3419: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3172 - accuracy: 0.9006\n","Epoch 3420/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3155 - accuracy: 0.9019\n","Epoch 3420: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3158 - accuracy: 0.9012\n","Epoch 3421/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3135 - accuracy: 0.9005\n","Epoch 3421: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3168 - accuracy: 0.8993\n","Epoch 3422/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3142 - accuracy: 0.9016\n","Epoch 3422: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3179 - accuracy: 0.8999\n","Epoch 3423/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3198 - accuracy: 0.9003\n","Epoch 3423: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3167 - accuracy: 0.9012\n","Epoch 3424/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3185 - accuracy: 0.9018\n","Epoch 3424: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3194 - accuracy: 0.9016\n","Epoch 3425/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3105 - accuracy: 0.9047\n","Epoch 3425: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3160 - accuracy: 0.9028\n","Epoch 3426/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3155 - accuracy: 0.9005\n","Epoch 3426: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3167 - accuracy: 0.9011\n","Epoch 3427/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3116 - accuracy: 0.9022\n","Epoch 3427: loss did not improve from 0.31482\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3164 - accuracy: 0.9007\n","Epoch 3428/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3128 - accuracy: 0.9007\n","Epoch 3428: loss improved from 0.31482 to 0.31266, saving model to best_model_3.hdf5\n","8/8 [==============================] - 1s 100ms/step - loss: 0.3127 - accuracy: 0.9010\n","Epoch 3429/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3151 - accuracy: 0.9009\n","Epoch 3429: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3142 - accuracy: 0.9014\n","Epoch 3430/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3111 - accuracy: 0.9012\n","Epoch 3430: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3143 - accuracy: 0.9003\n","Epoch 3431/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3137 - accuracy: 0.9007\n","Epoch 3431: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 56ms/step - loss: 0.3150 - accuracy: 0.8997\n","Epoch 3432/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3108 - accuracy: 0.9028\n","Epoch 3432: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3169 - accuracy: 0.9002\n","Epoch 3433/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3137 - accuracy: 0.9009\n","Epoch 3433: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3151 - accuracy: 0.9007\n","Epoch 3434/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3172 - accuracy: 0.8996\n","Epoch 3434: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3178 - accuracy: 0.8998\n","Epoch 3435/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3159 - accuracy: 0.9018\n","Epoch 3435: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3170 - accuracy: 0.9002\n","Epoch 3436/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3159 - accuracy: 0.8986\n","Epoch 3436: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3140 - accuracy: 0.8992\n","Epoch 3437/4000\n","8/8 [==============================] - ETA: 0s - loss: 0.3152 - accuracy: 0.9007\n","Epoch 3437: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3152 - accuracy: 0.9007\n","Epoch 3438/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3192 - accuracy: 0.8979\n","Epoch 3438: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3163 - accuracy: 0.8997\n","Epoch 3439/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3149 - accuracy: 0.9015\n","Epoch 3439: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3173 - accuracy: 0.9005\n","Epoch 3440/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3154 - accuracy: 0.9028\n","Epoch 3440: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3160 - accuracy: 0.9023\n","Epoch 3441/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3165 - accuracy: 0.8996\n","Epoch 3441: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3168 - accuracy: 0.9001\n","Epoch 3442/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3182 - accuracy: 0.9005\n","Epoch 3442: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3175 - accuracy: 0.9010\n","Epoch 3443/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3137 - accuracy: 0.9030\n","Epoch 3443: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3182 - accuracy: 0.9011\n","Epoch 3444/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3152 - accuracy: 0.8996\n","Epoch 3444: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3170 - accuracy: 0.8987\n","Epoch 3445/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3133 - accuracy: 0.9014\n","Epoch 3445: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3156 - accuracy: 0.9007\n","Epoch 3446/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3185 - accuracy: 0.8998\n","Epoch 3446: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3167 - accuracy: 0.9007\n","Epoch 3447/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3109 - accuracy: 0.9035\n","Epoch 3447: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3168 - accuracy: 0.9012\n","Epoch 3448/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3154 - accuracy: 0.8996\n","Epoch 3448: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3170 - accuracy: 0.8984\n","Epoch 3449/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3101 - accuracy: 0.9035\n","Epoch 3449: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3173 - accuracy: 0.9006\n","Epoch 3450/4000\n","8/8 [==============================] - ETA: 0s - loss: 0.3169 - accuracy: 0.9005\n","Epoch 3450: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3169 - accuracy: 0.9005\n","Epoch 3451/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3155 - accuracy: 0.9019\n","Epoch 3451: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3192 - accuracy: 0.9002\n","Epoch 3452/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3169 - accuracy: 0.8998\n","Epoch 3452: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3205 - accuracy: 0.8976\n","Epoch 3453/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3134 - accuracy: 0.9036\n","Epoch 3453: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3203 - accuracy: 0.9015\n","Epoch 3454/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3137 - accuracy: 0.9028\n","Epoch 3454: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3211 - accuracy: 0.8999\n","Epoch 3455/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3167 - accuracy: 0.9016\n","Epoch 3455: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3185 - accuracy: 0.9007\n","Epoch 3456/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3133 - accuracy: 0.8997\n","Epoch 3456: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3180 - accuracy: 0.8985\n","Epoch 3457/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3145 - accuracy: 0.9015\n","Epoch 3457: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3162 - accuracy: 0.9006\n","Epoch 3458/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3159 - accuracy: 0.9025\n","Epoch 3458: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3186 - accuracy: 0.9015\n","Epoch 3459/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3168 - accuracy: 0.9000\n","Epoch 3459: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3157 - accuracy: 0.9005\n","Epoch 3460/4000\n","8/8 [==============================] - ETA: 0s - loss: 0.3137 - accuracy: 0.9001\n","Epoch 3460: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 62ms/step - loss: 0.3137 - accuracy: 0.9001\n","Epoch 3461/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3157 - accuracy: 0.9003\n","Epoch 3461: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3163 - accuracy: 0.8990\n","Epoch 3462/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3208 - accuracy: 0.8994\n","Epoch 3462: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3174 - accuracy: 0.9009\n","Epoch 3463/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3127 - accuracy: 0.9040\n","Epoch 3463: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3178 - accuracy: 0.9010\n","Epoch 3464/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3145 - accuracy: 0.9046\n","Epoch 3464: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3169 - accuracy: 0.9033\n","Epoch 3465/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3177 - accuracy: 0.9011\n","Epoch 3465: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3191 - accuracy: 0.9005\n","Epoch 3466/4000\n","8/8 [==============================] - ETA: 0s - loss: 0.3143 - accuracy: 0.9012\n","Epoch 3466: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3143 - accuracy: 0.9012\n","Epoch 3467/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3179 - accuracy: 0.8994\n","Epoch 3467: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3176 - accuracy: 0.8987\n","Epoch 3468/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3186 - accuracy: 0.9018\n","Epoch 3468: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3184 - accuracy: 0.9018\n","Epoch 3469/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3136 - accuracy: 0.9022\n","Epoch 3469: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3184 - accuracy: 0.8998\n","Epoch 3470/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3134 - accuracy: 0.9040\n","Epoch 3470: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 56ms/step - loss: 0.3174 - accuracy: 0.9025\n","Epoch 3471/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3132 - accuracy: 0.9028\n","Epoch 3471: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3200 - accuracy: 0.9009\n","Epoch 3472/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3182 - accuracy: 0.9021\n","Epoch 3472: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3196 - accuracy: 0.9011\n","Epoch 3473/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3168 - accuracy: 0.9022\n","Epoch 3473: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3190 - accuracy: 0.9012\n","Epoch 3474/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3157 - accuracy: 0.9028\n","Epoch 3474: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3194 - accuracy: 0.9014\n","Epoch 3475/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3170 - accuracy: 0.9021\n","Epoch 3475: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3197 - accuracy: 0.9002\n","Epoch 3476/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3220 - accuracy: 0.9015\n","Epoch 3476: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3181 - accuracy: 0.9019\n","Epoch 3477/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3154 - accuracy: 0.9015\n","Epoch 3477: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3173 - accuracy: 0.9009\n","Epoch 3478/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3176 - accuracy: 0.9003\n","Epoch 3478: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3188 - accuracy: 0.8993\n","Epoch 3479/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3147 - accuracy: 0.9012\n","Epoch 3479: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3183 - accuracy: 0.8997\n","Epoch 3480/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3164 - accuracy: 0.9004\n","Epoch 3480: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3157 - accuracy: 0.9003\n","Epoch 3481/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3223 - accuracy: 0.8993\n","Epoch 3481: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3186 - accuracy: 0.9001\n","Epoch 3482/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3140 - accuracy: 0.9023\n","Epoch 3482: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3173 - accuracy: 0.9006\n","Epoch 3483/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3163 - accuracy: 0.9004\n","Epoch 3483: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 49ms/step - loss: 0.3196 - accuracy: 0.8996\n","Epoch 3484/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3170 - accuracy: 0.9016\n","Epoch 3484: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 49ms/step - loss: 0.3168 - accuracy: 0.9016\n","Epoch 3485/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3191 - accuracy: 0.9000\n","Epoch 3485: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3190 - accuracy: 0.8989\n","Epoch 3486/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3146 - accuracy: 0.9012\n","Epoch 3486: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3162 - accuracy: 0.8998\n","Epoch 3487/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3209 - accuracy: 0.9004\n","Epoch 3487: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3162 - accuracy: 0.9018\n","Epoch 3488/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3154 - accuracy: 0.9008\n","Epoch 3488: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3151 - accuracy: 0.9011\n","Epoch 3489/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3136 - accuracy: 0.9018\n","Epoch 3489: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3183 - accuracy: 0.9001\n","Epoch 3490/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3218 - accuracy: 0.8996\n","Epoch 3490: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3188 - accuracy: 0.9009\n","Epoch 3491/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3161 - accuracy: 0.8994\n","Epoch 3491: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3183 - accuracy: 0.8985\n","Epoch 3492/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3160 - accuracy: 0.9019\n","Epoch 3492: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3167 - accuracy: 0.9018\n","Epoch 3493/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3095 - accuracy: 0.9028\n","Epoch 3493: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3154 - accuracy: 0.9012\n","Epoch 3494/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3142 - accuracy: 0.9035\n","Epoch 3494: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3157 - accuracy: 0.9031\n","Epoch 3495/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3143 - accuracy: 0.8997\n","Epoch 3495: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3172 - accuracy: 0.8990\n","Epoch 3496/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3211 - accuracy: 0.9039\n","Epoch 3496: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3162 - accuracy: 0.9049\n","Epoch 3497/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3231 - accuracy: 0.8996\n","Epoch 3497: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3216 - accuracy: 0.9003\n","Epoch 3498/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3147 - accuracy: 0.9000\n","Epoch 3498: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3158 - accuracy: 0.8989\n","Epoch 3499/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3124 - accuracy: 0.9023\n","Epoch 3499: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 56ms/step - loss: 0.3181 - accuracy: 0.9002\n","Epoch 3500/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3163 - accuracy: 0.9015\n","Epoch 3500: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3177 - accuracy: 0.9011\n","Epoch 3501/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3156 - accuracy: 0.9005\n","Epoch 3501: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3186 - accuracy: 0.8994\n","Epoch 3502/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3118 - accuracy: 0.9033\n","Epoch 3502: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3177 - accuracy: 0.9012\n","Epoch 3503/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3140 - accuracy: 0.9025\n","Epoch 3503: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3171 - accuracy: 0.9016\n","Epoch 3504/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3111 - accuracy: 0.9039\n","Epoch 3504: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3167 - accuracy: 0.9012\n","Epoch 3505/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3201 - accuracy: 0.9016\n","Epoch 3505: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3140 - accuracy: 0.9028\n","Epoch 3506/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3111 - accuracy: 0.9014\n","Epoch 3506: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3153 - accuracy: 0.8996\n","Epoch 3507/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3097 - accuracy: 0.9022\n","Epoch 3507: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3158 - accuracy: 0.9003\n","Epoch 3508/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3200 - accuracy: 0.8993\n","Epoch 3508: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3181 - accuracy: 0.8996\n","Epoch 3509/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3131 - accuracy: 0.9023\n","Epoch 3509: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3176 - accuracy: 0.9006\n","Epoch 3510/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3152 - accuracy: 0.8980\n","Epoch 3510: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3178 - accuracy: 0.8975\n","Epoch 3511/4000\n","8/8 [==============================] - ETA: 0s - loss: 0.3173 - accuracy: 0.9003\n","Epoch 3511: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3173 - accuracy: 0.9003\n","Epoch 3512/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3102 - accuracy: 0.9018\n","Epoch 3512: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3166 - accuracy: 0.8990\n","Epoch 3513/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3153 - accuracy: 0.9008\n","Epoch 3513: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3190 - accuracy: 0.8994\n","Epoch 3514/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3122 - accuracy: 0.9023\n","Epoch 3514: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3196 - accuracy: 0.9012\n","Epoch 3515/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3156 - accuracy: 0.9009\n","Epoch 3515: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3172 - accuracy: 0.9005\n","Epoch 3516/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3178 - accuracy: 0.9008\n","Epoch 3516: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3194 - accuracy: 0.8998\n","Epoch 3517/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3105 - accuracy: 0.9026\n","Epoch 3517: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3171 - accuracy: 0.9005\n","Epoch 3518/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3148 - accuracy: 0.9001\n","Epoch 3518: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 48ms/step - loss: 0.3168 - accuracy: 0.8993\n","Epoch 3519/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3142 - accuracy: 0.9032\n","Epoch 3519: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3178 - accuracy: 0.9010\n","Epoch 3520/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3208 - accuracy: 0.8998\n","Epoch 3520: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3175 - accuracy: 0.9011\n","Epoch 3521/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3165 - accuracy: 0.9011\n","Epoch 3521: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3190 - accuracy: 0.8996\n","Epoch 3522/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3173 - accuracy: 0.9014\n","Epoch 3522: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3186 - accuracy: 0.8997\n","Epoch 3523/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3124 - accuracy: 0.9019\n","Epoch 3523: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3169 - accuracy: 0.9007\n","Epoch 3524/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3142 - accuracy: 0.9019\n","Epoch 3524: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3157 - accuracy: 0.9007\n","Epoch 3525/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3155 - accuracy: 0.9019\n","Epoch 3525: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3193 - accuracy: 0.9005\n","Epoch 3526/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3158 - accuracy: 0.8993\n","Epoch 3526: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3193 - accuracy: 0.8983\n","Epoch 3527/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3165 - accuracy: 0.9011\n","Epoch 3527: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3185 - accuracy: 0.9011\n","Epoch 3528/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3206 - accuracy: 0.9004\n","Epoch 3528: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3191 - accuracy: 0.9005\n","Epoch 3529/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3171 - accuracy: 0.9001\n","Epoch 3529: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3180 - accuracy: 0.9001\n","Epoch 3530/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3155 - accuracy: 0.9012\n","Epoch 3530: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3170 - accuracy: 0.9003\n","Epoch 3531/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3116 - accuracy: 0.9011\n","Epoch 3531: loss did not improve from 0.31266\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3146 - accuracy: 0.9006\n","Epoch 3532/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3080 - accuracy: 0.9028\n","Epoch 3532: loss improved from 0.31266 to 0.31201, saving model to best_model_3.hdf5\n","8/8 [==============================] - 1s 106ms/step - loss: 0.3120 - accuracy: 0.9014\n","Epoch 3533/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3156 - accuracy: 0.9019\n","Epoch 3533: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 49ms/step - loss: 0.3168 - accuracy: 0.9014\n","Epoch 3534/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3205 - accuracy: 0.8970\n","Epoch 3534: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3178 - accuracy: 0.8980\n","Epoch 3535/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3132 - accuracy: 0.9015\n","Epoch 3535: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3191 - accuracy: 0.8992\n","Epoch 3536/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3126 - accuracy: 0.9014\n","Epoch 3536: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3167 - accuracy: 0.9002\n","Epoch 3537/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3199 - accuracy: 0.9018\n","Epoch 3537: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3198 - accuracy: 0.9018\n","Epoch 3538/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3154 - accuracy: 0.9030\n","Epoch 3538: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3199 - accuracy: 0.9014\n","Epoch 3539/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3065 - accuracy: 0.9042\n","Epoch 3539: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3164 - accuracy: 0.9006\n","Epoch 3540/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3191 - accuracy: 0.8986\n","Epoch 3540: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3156 - accuracy: 0.9001\n","Epoch 3541/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3231 - accuracy: 0.8998\n","Epoch 3541: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3211 - accuracy: 0.8997\n","Epoch 3542/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3135 - accuracy: 0.9022\n","Epoch 3542: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3191 - accuracy: 0.9002\n","Epoch 3543/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3168 - accuracy: 0.9007\n","Epoch 3543: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3195 - accuracy: 0.8989\n","Epoch 3544/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3151 - accuracy: 0.9005\n","Epoch 3544: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3182 - accuracy: 0.8990\n","Epoch 3545/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3157 - accuracy: 0.9016\n","Epoch 3545: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3180 - accuracy: 0.9005\n","Epoch 3546/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3135 - accuracy: 0.9032\n","Epoch 3546: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3175 - accuracy: 0.9014\n","Epoch 3547/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3157 - accuracy: 0.9011\n","Epoch 3547: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3187 - accuracy: 0.9005\n","Epoch 3548/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3148 - accuracy: 0.9016\n","Epoch 3548: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3148 - accuracy: 0.9016\n","Epoch 3549/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3150 - accuracy: 0.9003\n","Epoch 3549: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3147 - accuracy: 0.8997\n","Epoch 3550/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3172 - accuracy: 0.9028\n","Epoch 3550: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3190 - accuracy: 0.9023\n","Epoch 3551/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3191 - accuracy: 0.8983\n","Epoch 3551: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3179 - accuracy: 0.8987\n","Epoch 3552/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3130 - accuracy: 0.9028\n","Epoch 3552: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3165 - accuracy: 0.9014\n","Epoch 3553/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3154 - accuracy: 0.9003\n","Epoch 3553: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3174 - accuracy: 0.8993\n","Epoch 3554/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3170 - accuracy: 0.8990\n","Epoch 3554: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3168 - accuracy: 0.8993\n","Epoch 3555/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3139 - accuracy: 0.8993\n","Epoch 3555: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3158 - accuracy: 0.8985\n","Epoch 3556/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3182 - accuracy: 0.8998\n","Epoch 3556: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3190 - accuracy: 0.8993\n","Epoch 3557/4000\n","8/8 [==============================] - ETA: 0s - loss: 0.3182 - accuracy: 0.9014\n","Epoch 3557: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 56ms/step - loss: 0.3182 - accuracy: 0.9014\n","Epoch 3558/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3162 - accuracy: 0.9028\n","Epoch 3558: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 49ms/step - loss: 0.3195 - accuracy: 0.9021\n","Epoch 3559/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3215 - accuracy: 0.8991\n","Epoch 3559: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3222 - accuracy: 0.8988\n","Epoch 3560/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3179 - accuracy: 0.9021\n","Epoch 3560: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3219 - accuracy: 0.9007\n","Epoch 3561/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3195 - accuracy: 0.9019\n","Epoch 3561: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3210 - accuracy: 0.9012\n","Epoch 3562/4000\n","8/8 [==============================] - ETA: 0s - loss: 0.3201 - accuracy: 0.9010\n","Epoch 3562: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3201 - accuracy: 0.9010\n","Epoch 3563/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3169 - accuracy: 0.9019\n","Epoch 3563: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3206 - accuracy: 0.9007\n","Epoch 3564/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3193 - accuracy: 0.9012\n","Epoch 3564: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3211 - accuracy: 0.8998\n","Epoch 3565/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3186 - accuracy: 0.9008\n","Epoch 3565: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3170 - accuracy: 0.9003\n","Epoch 3566/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3181 - accuracy: 0.8993\n","Epoch 3566: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3169 - accuracy: 0.9003\n","Epoch 3567/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3168 - accuracy: 0.9007\n","Epoch 3567: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3195 - accuracy: 0.9006\n","Epoch 3568/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3179 - accuracy: 0.9001\n","Epoch 3568: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3173 - accuracy: 0.8998\n","Epoch 3569/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3183 - accuracy: 0.9033\n","Epoch 3569: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3231 - accuracy: 0.9011\n","Epoch 3570/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3234 - accuracy: 0.9004\n","Epoch 3570: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3237 - accuracy: 0.9005\n","Epoch 3571/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3321 - accuracy: 0.8993\n","Epoch 3571: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3314 - accuracy: 0.8999\n","Epoch 3572/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3329 - accuracy: 0.8987\n","Epoch 3572: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3336 - accuracy: 0.8977\n","Epoch 3573/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3377 - accuracy: 0.8989\n","Epoch 3573: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3376 - accuracy: 0.8985\n","Epoch 3574/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3434 - accuracy: 0.8980\n","Epoch 3574: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3405 - accuracy: 0.8983\n","Epoch 3575/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3459 - accuracy: 0.8979\n","Epoch 3575: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3486 - accuracy: 0.8968\n","Epoch 3576/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3553 - accuracy: 0.8997\n","Epoch 3576: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3615 - accuracy: 0.8970\n","Epoch 3577/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3744 - accuracy: 0.8936\n","Epoch 3577: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3764 - accuracy: 0.8922\n","Epoch 3578/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3787 - accuracy: 0.8933\n","Epoch 3578: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3856 - accuracy: 0.8917\n","Epoch 3579/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.4429 - accuracy: 0.8747\n","Epoch 3579: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 51ms/step - loss: 0.4445 - accuracy: 0.8744\n","Epoch 3580/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.4960 - accuracy: 0.8664\n","Epoch 3580: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 51ms/step - loss: 0.4931 - accuracy: 0.8675\n","Epoch 3581/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.5359 - accuracy: 0.8595\n","Epoch 3581: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 52ms/step - loss: 0.5458 - accuracy: 0.8576\n","Epoch 3582/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.5578 - accuracy: 0.8562\n","Epoch 3582: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 52ms/step - loss: 0.5632 - accuracy: 0.8548\n","Epoch 3583/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.5860 - accuracy: 0.8599\n","Epoch 3583: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 53ms/step - loss: 0.5945 - accuracy: 0.8579\n","Epoch 3584/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.6629 - accuracy: 0.8422\n","Epoch 3584: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 54ms/step - loss: 0.6648 - accuracy: 0.8413\n","Epoch 3585/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.6771 - accuracy: 0.8384\n","Epoch 3585: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 53ms/step - loss: 0.6842 - accuracy: 0.8368\n","Epoch 3586/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.6678 - accuracy: 0.8415\n","Epoch 3586: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 50ms/step - loss: 0.6777 - accuracy: 0.8391\n","Epoch 3587/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.6799 - accuracy: 0.8422\n","Epoch 3587: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 52ms/step - loss: 0.6851 - accuracy: 0.8398\n","Epoch 3588/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.6364 - accuracy: 0.8524\n","Epoch 3588: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 51ms/step - loss: 0.6365 - accuracy: 0.8527\n","Epoch 3589/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.6173 - accuracy: 0.8629\n","Epoch 3589: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 51ms/step - loss: 0.6177 - accuracy: 0.8625\n","Epoch 3590/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.5733 - accuracy: 0.8726\n","Epoch 3590: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 49ms/step - loss: 0.5800 - accuracy: 0.8702\n","Epoch 3591/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.5346 - accuracy: 0.8768\n","Epoch 3591: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 53ms/step - loss: 0.5326 - accuracy: 0.8782\n","Epoch 3592/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.4984 - accuracy: 0.8830\n","Epoch 3592: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 51ms/step - loss: 0.5011 - accuracy: 0.8830\n","Epoch 3593/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.4843 - accuracy: 0.8873\n","Epoch 3593: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 55ms/step - loss: 0.4890 - accuracy: 0.8851\n","Epoch 3594/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.4426 - accuracy: 0.8944\n","Epoch 3594: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 53ms/step - loss: 0.4457 - accuracy: 0.8930\n","Epoch 3595/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.4260 - accuracy: 0.8944\n","Epoch 3595: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 53ms/step - loss: 0.4252 - accuracy: 0.8944\n","Epoch 3596/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.4108 - accuracy: 0.8949\n","Epoch 3596: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 53ms/step - loss: 0.4129 - accuracy: 0.8936\n","Epoch 3597/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3912 - accuracy: 0.8975\n","Epoch 3597: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3968 - accuracy: 0.8957\n","Epoch 3598/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3831 - accuracy: 0.8983\n","Epoch 3598: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3849 - accuracy: 0.8983\n","Epoch 3599/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3697 - accuracy: 0.9001\n","Epoch 3599: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3703 - accuracy: 0.8997\n","Epoch 3600/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3587 - accuracy: 0.9012\n","Epoch 3600: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3624 - accuracy: 0.8997\n","Epoch 3601/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3504 - accuracy: 0.9012\n","Epoch 3601: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3522 - accuracy: 0.9006\n","Epoch 3602/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3442 - accuracy: 0.9021\n","Epoch 3602: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3490 - accuracy: 0.8994\n","Epoch 3603/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3358 - accuracy: 0.9049\n","Epoch 3603: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3419 - accuracy: 0.9021\n","Epoch 3604/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3326 - accuracy: 0.9023\n","Epoch 3604: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3404 - accuracy: 0.8998\n","Epoch 3605/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3280 - accuracy: 0.9051\n","Epoch 3605: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3334 - accuracy: 0.9025\n","Epoch 3606/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3331 - accuracy: 0.8993\n","Epoch 3606: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3326 - accuracy: 0.8998\n","Epoch 3607/4000\n","8/8 [==============================] - ETA: 0s - loss: 0.3272 - accuracy: 0.9012\n","Epoch 3607: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 56ms/step - loss: 0.3272 - accuracy: 0.9012\n","Epoch 3608/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3253 - accuracy: 0.8998\n","Epoch 3608: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3251 - accuracy: 0.8994\n","Epoch 3609/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3216 - accuracy: 0.9044\n","Epoch 3609: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3227 - accuracy: 0.9027\n","Epoch 3610/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3156 - accuracy: 0.9039\n","Epoch 3610: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3221 - accuracy: 0.9015\n","Epoch 3611/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3174 - accuracy: 0.9040\n","Epoch 3611: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3199 - accuracy: 0.9023\n","Epoch 3612/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3172 - accuracy: 0.9023\n","Epoch 3612: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3183 - accuracy: 0.9020\n","Epoch 3613/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3125 - accuracy: 0.9040\n","Epoch 3613: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3168 - accuracy: 0.9023\n","Epoch 3614/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3203 - accuracy: 0.9000\n","Epoch 3614: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3167 - accuracy: 0.9007\n","Epoch 3615/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3164 - accuracy: 0.9008\n","Epoch 3615: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3168 - accuracy: 0.9010\n","Epoch 3616/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3124 - accuracy: 0.9022\n","Epoch 3616: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3136 - accuracy: 0.9019\n","Epoch 3617/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3103 - accuracy: 0.9023\n","Epoch 3617: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3151 - accuracy: 0.9010\n","Epoch 3618/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3101 - accuracy: 0.9028\n","Epoch 3618: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 48ms/step - loss: 0.3131 - accuracy: 0.9014\n","Epoch 3619/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3135 - accuracy: 0.9004\n","Epoch 3619: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3138 - accuracy: 0.9005\n","Epoch 3620/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3140 - accuracy: 0.8993\n","Epoch 3620: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3167 - accuracy: 0.8990\n","Epoch 3621/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3158 - accuracy: 0.9018\n","Epoch 3621: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3163 - accuracy: 0.9019\n","Epoch 3622/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3160 - accuracy: 0.9012\n","Epoch 3622: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 56ms/step - loss: 0.3141 - accuracy: 0.9019\n","Epoch 3623/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3192 - accuracy: 0.9015\n","Epoch 3623: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3168 - accuracy: 0.9023\n","Epoch 3624/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3126 - accuracy: 0.9026\n","Epoch 3624: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3175 - accuracy: 0.9011\n","Epoch 3625/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3140 - accuracy: 0.9033\n","Epoch 3625: loss did not improve from 0.31201\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3160 - accuracy: 0.9024\n","Epoch 3626/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3124 - accuracy: 0.9018\n","Epoch 3626: loss improved from 0.31201 to 0.31160, saving model to best_model_3.hdf5\n","8/8 [==============================] - 1s 106ms/step - loss: 0.3116 - accuracy: 0.9011\n","Epoch 3627/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3148 - accuracy: 0.9009\n","Epoch 3627: loss did not improve from 0.31160\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3164 - accuracy: 0.9003\n","Epoch 3628/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3112 - accuracy: 0.9029\n","Epoch 3628: loss did not improve from 0.31160\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3174 - accuracy: 0.9002\n","Epoch 3629/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3187 - accuracy: 0.9012\n","Epoch 3629: loss did not improve from 0.31160\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3179 - accuracy: 0.9014\n","Epoch 3630/4000\n","8/8 [==============================] - ETA: 0s - loss: 0.3161 - accuracy: 0.9024\n","Epoch 3630: loss did not improve from 0.31160\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3161 - accuracy: 0.9024\n","Epoch 3631/4000\n","8/8 [==============================] - ETA: 0s - loss: 0.3156 - accuracy: 0.9021\n","Epoch 3631: loss did not improve from 0.31160\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3156 - accuracy: 0.9021\n","Epoch 3632/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3152 - accuracy: 0.9014\n","Epoch 3632: loss did not improve from 0.31160\n","8/8 [==============================] - 0s 48ms/step - loss: 0.3172 - accuracy: 0.9006\n","Epoch 3633/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3097 - accuracy: 0.9050\n","Epoch 3633: loss did not improve from 0.31160\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3146 - accuracy: 0.9032\n","Epoch 3634/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3091 - accuracy: 0.9018\n","Epoch 3634: loss did not improve from 0.31160\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3151 - accuracy: 0.9002\n","Epoch 3635/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3175 - accuracy: 0.9025\n","Epoch 3635: loss did not improve from 0.31160\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3170 - accuracy: 0.9020\n","Epoch 3636/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3190 - accuracy: 0.8984\n","Epoch 3636: loss did not improve from 0.31160\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3176 - accuracy: 0.8984\n","Epoch 3637/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3090 - accuracy: 0.9025\n","Epoch 3637: loss did not improve from 0.31160\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3136 - accuracy: 0.9012\n","Epoch 3638/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3117 - accuracy: 0.9001\n","Epoch 3638: loss did not improve from 0.31160\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3123 - accuracy: 0.8993\n","Epoch 3639/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3135 - accuracy: 0.9011\n","Epoch 3639: loss did not improve from 0.31160\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3140 - accuracy: 0.9005\n","Epoch 3640/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3095 - accuracy: 0.9004\n","Epoch 3640: loss did not improve from 0.31160\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3119 - accuracy: 0.8997\n","Epoch 3641/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3086 - accuracy: 0.9009\n","Epoch 3641: loss did not improve from 0.31160\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3130 - accuracy: 0.9001\n","Epoch 3642/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3127 - accuracy: 0.9003\n","Epoch 3642: loss did not improve from 0.31160\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3161 - accuracy: 0.8987\n","Epoch 3643/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3141 - accuracy: 0.9004\n","Epoch 3643: loss did not improve from 0.31160\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3139 - accuracy: 0.9002\n","Epoch 3644/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3121 - accuracy: 0.9018\n","Epoch 3644: loss did not improve from 0.31160\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3119 - accuracy: 0.9018\n","Epoch 3645/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3080 - accuracy: 0.9032\n","Epoch 3645: loss did not improve from 0.31160\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3130 - accuracy: 0.9010\n","Epoch 3646/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3148 - accuracy: 0.9018\n","Epoch 3646: loss did not improve from 0.31160\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3121 - accuracy: 0.9032\n","Epoch 3647/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3095 - accuracy: 0.9036\n","Epoch 3647: loss improved from 0.31160 to 0.31074, saving model to best_model_3.hdf5\n","8/8 [==============================] - 1s 105ms/step - loss: 0.3107 - accuracy: 0.9028\n","Epoch 3648/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3114 - accuracy: 0.9030\n","Epoch 3648: loss did not improve from 0.31074\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3168 - accuracy: 0.9016\n","Epoch 3649/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3122 - accuracy: 0.9003\n","Epoch 3649: loss did not improve from 0.31074\n","8/8 [==============================] - 0s 49ms/step - loss: 0.3127 - accuracy: 0.8996\n","Epoch 3650/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3109 - accuracy: 0.9022\n","Epoch 3650: loss did not improve from 0.31074\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3108 - accuracy: 0.9024\n","Epoch 3651/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3122 - accuracy: 0.9012\n","Epoch 3651: loss improved from 0.31074 to 0.30983, saving model to best_model_3.hdf5\n","8/8 [==============================] - 1s 114ms/step - loss: 0.3098 - accuracy: 0.9020\n","Epoch 3652/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3066 - accuracy: 0.9026\n","Epoch 3652: loss did not improve from 0.30983\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3112 - accuracy: 0.9005\n","Epoch 3653/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3088 - accuracy: 0.9019\n","Epoch 3653: loss did not improve from 0.30983\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3128 - accuracy: 0.9009\n","Epoch 3654/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3109 - accuracy: 0.9026\n","Epoch 3654: loss did not improve from 0.30983\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3123 - accuracy: 0.9019\n","Epoch 3655/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3115 - accuracy: 0.9008\n","Epoch 3655: loss improved from 0.30983 to 0.30893, saving model to best_model_3.hdf5\n","8/8 [==============================] - 1s 106ms/step - loss: 0.3089 - accuracy: 0.9014\n","Epoch 3656/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.2979 - accuracy: 0.9056\n","Epoch 3656: loss did not improve from 0.30893\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3094 - accuracy: 0.9024\n","Epoch 3657/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3137 - accuracy: 0.9018\n","Epoch 3657: loss did not improve from 0.30893\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3118 - accuracy: 0.9025\n","Epoch 3658/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3071 - accuracy: 0.9026\n","Epoch 3658: loss did not improve from 0.30893\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3160 - accuracy: 0.8994\n","Epoch 3659/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3144 - accuracy: 0.9023\n","Epoch 3659: loss did not improve from 0.30893\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3174 - accuracy: 0.9010\n","Epoch 3660/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3095 - accuracy: 0.9015\n","Epoch 3660: loss did not improve from 0.30893\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3134 - accuracy: 0.9002\n","Epoch 3661/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3121 - accuracy: 0.9014\n","Epoch 3661: loss did not improve from 0.30893\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3132 - accuracy: 0.9009\n","Epoch 3662/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3098 - accuracy: 0.9025\n","Epoch 3662: loss did not improve from 0.30893\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3134 - accuracy: 0.9012\n","Epoch 3663/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3152 - accuracy: 0.9019\n","Epoch 3663: loss did not improve from 0.30893\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3121 - accuracy: 0.9027\n","Epoch 3664/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3101 - accuracy: 0.9023\n","Epoch 3664: loss did not improve from 0.30893\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3120 - accuracy: 0.9014\n","Epoch 3665/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3129 - accuracy: 0.8984\n","Epoch 3665: loss did not improve from 0.30893\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3132 - accuracy: 0.8981\n","Epoch 3666/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3110 - accuracy: 0.8994\n","Epoch 3666: loss did not improve from 0.30893\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3099 - accuracy: 0.8989\n","Epoch 3667/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3107 - accuracy: 0.8989\n","Epoch 3667: loss did not improve from 0.30893\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3117 - accuracy: 0.8992\n","Epoch 3668/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3035 - accuracy: 0.9036\n","Epoch 3668: loss improved from 0.30893 to 0.30800, saving model to best_model_3.hdf5\n","8/8 [==============================] - 1s 100ms/step - loss: 0.3080 - accuracy: 0.9021\n","Epoch 3669/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3104 - accuracy: 0.8973\n","Epoch 3669: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3119 - accuracy: 0.8967\n","Epoch 3670/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3092 - accuracy: 0.9011\n","Epoch 3670: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3106 - accuracy: 0.9009\n","Epoch 3671/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3089 - accuracy: 0.9028\n","Epoch 3671: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3087 - accuracy: 0.9024\n","Epoch 3672/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3151 - accuracy: 0.8996\n","Epoch 3672: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 56ms/step - loss: 0.3136 - accuracy: 0.8999\n","Epoch 3673/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3091 - accuracy: 0.9021\n","Epoch 3673: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 49ms/step - loss: 0.3120 - accuracy: 0.9014\n","Epoch 3674/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3105 - accuracy: 0.9001\n","Epoch 3674: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3131 - accuracy: 0.8993\n","Epoch 3675/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3098 - accuracy: 0.9032\n","Epoch 3675: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3111 - accuracy: 0.9023\n","Epoch 3676/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3106 - accuracy: 0.9012\n","Epoch 3676: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3129 - accuracy: 0.9005\n","Epoch 3677/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3104 - accuracy: 0.9016\n","Epoch 3677: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3113 - accuracy: 0.9011\n","Epoch 3678/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3044 - accuracy: 0.9026\n","Epoch 3678: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3125 - accuracy: 0.8998\n","Epoch 3679/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3105 - accuracy: 0.9015\n","Epoch 3679: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3134 - accuracy: 0.9005\n","Epoch 3680/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3137 - accuracy: 0.8983\n","Epoch 3680: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3120 - accuracy: 0.8987\n","Epoch 3681/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3121 - accuracy: 0.9016\n","Epoch 3681: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3141 - accuracy: 0.9012\n","Epoch 3682/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3050 - accuracy: 0.9028\n","Epoch 3682: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3084 - accuracy: 0.9020\n","Epoch 3683/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3110 - accuracy: 0.8997\n","Epoch 3683: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3107 - accuracy: 0.8998\n","Epoch 3684/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3131 - accuracy: 0.9009\n","Epoch 3684: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3136 - accuracy: 0.9007\n","Epoch 3685/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3043 - accuracy: 0.9025\n","Epoch 3685: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3112 - accuracy: 0.8996\n","Epoch 3686/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3133 - accuracy: 0.9016\n","Epoch 3686: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3145 - accuracy: 0.9012\n","Epoch 3687/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3150 - accuracy: 0.9016\n","Epoch 3687: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3154 - accuracy: 0.9011\n","Epoch 3688/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3073 - accuracy: 0.9053\n","Epoch 3688: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3113 - accuracy: 0.9034\n","Epoch 3689/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3088 - accuracy: 0.9021\n","Epoch 3689: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3142 - accuracy: 0.8996\n","Epoch 3690/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3133 - accuracy: 0.9007\n","Epoch 3690: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3146 - accuracy: 0.9003\n","Epoch 3691/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3053 - accuracy: 0.9035\n","Epoch 3691: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3131 - accuracy: 0.9015\n","Epoch 3692/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3067 - accuracy: 0.9018\n","Epoch 3692: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3120 - accuracy: 0.8998\n","Epoch 3693/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3093 - accuracy: 0.9036\n","Epoch 3693: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3125 - accuracy: 0.9016\n","Epoch 3694/4000\n","8/8 [==============================] - ETA: 0s - loss: 0.3130 - accuracy: 0.8979\n","Epoch 3694: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3130 - accuracy: 0.8979\n","Epoch 3695/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3113 - accuracy: 0.9015\n","Epoch 3695: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3156 - accuracy: 0.8998\n","Epoch 3696/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3162 - accuracy: 0.9008\n","Epoch 3696: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3147 - accuracy: 0.9007\n","Epoch 3697/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3066 - accuracy: 0.9009\n","Epoch 3697: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3098 - accuracy: 0.9001\n","Epoch 3698/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3063 - accuracy: 0.9030\n","Epoch 3698: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3118 - accuracy: 0.9009\n","Epoch 3699/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3064 - accuracy: 0.9039\n","Epoch 3699: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3100 - accuracy: 0.9023\n","Epoch 3700/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3071 - accuracy: 0.9016\n","Epoch 3700: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3087 - accuracy: 0.9015\n","Epoch 3701/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3133 - accuracy: 0.8982\n","Epoch 3701: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3107 - accuracy: 0.8994\n","Epoch 3702/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3094 - accuracy: 0.9009\n","Epoch 3702: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3108 - accuracy: 0.9001\n","Epoch 3703/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3080 - accuracy: 0.9012\n","Epoch 3703: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3084 - accuracy: 0.9006\n","Epoch 3704/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3093 - accuracy: 0.8997\n","Epoch 3704: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3106 - accuracy: 0.8996\n","Epoch 3705/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3101 - accuracy: 0.9011\n","Epoch 3705: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3127 - accuracy: 0.8998\n","Epoch 3706/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3042 - accuracy: 0.9036\n","Epoch 3706: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3092 - accuracy: 0.9016\n","Epoch 3707/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3098 - accuracy: 0.8996\n","Epoch 3707: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3106 - accuracy: 0.8990\n","Epoch 3708/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3111 - accuracy: 0.9028\n","Epoch 3708: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3116 - accuracy: 0.9023\n","Epoch 3709/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3049 - accuracy: 0.9026\n","Epoch 3709: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 56ms/step - loss: 0.3112 - accuracy: 0.9012\n","Epoch 3710/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3100 - accuracy: 0.8991\n","Epoch 3710: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3131 - accuracy: 0.8981\n","Epoch 3711/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3114 - accuracy: 0.9005\n","Epoch 3711: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 56ms/step - loss: 0.3131 - accuracy: 0.8993\n","Epoch 3712/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3087 - accuracy: 0.9021\n","Epoch 3712: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 49ms/step - loss: 0.3134 - accuracy: 0.8994\n","Epoch 3713/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3135 - accuracy: 0.9018\n","Epoch 3713: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3139 - accuracy: 0.9014\n","Epoch 3714/4000\n","8/8 [==============================] - ETA: 0s - loss: 0.3147 - accuracy: 0.8994\n","Epoch 3714: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3147 - accuracy: 0.8994\n","Epoch 3715/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3168 - accuracy: 0.8972\n","Epoch 3715: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3153 - accuracy: 0.8974\n","Epoch 3716/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3104 - accuracy: 0.9011\n","Epoch 3716: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3118 - accuracy: 0.8998\n","Epoch 3717/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3142 - accuracy: 0.8996\n","Epoch 3717: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3150 - accuracy: 0.8998\n","Epoch 3718/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3077 - accuracy: 0.9035\n","Epoch 3718: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3133 - accuracy: 0.9016\n","Epoch 3719/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3053 - accuracy: 0.9009\n","Epoch 3719: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3115 - accuracy: 0.8998\n","Epoch 3720/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3092 - accuracy: 0.9021\n","Epoch 3720: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3134 - accuracy: 0.8997\n","Epoch 3721/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3038 - accuracy: 0.9058\n","Epoch 3721: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3144 - accuracy: 0.9012\n","Epoch 3722/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3096 - accuracy: 0.9018\n","Epoch 3722: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 57ms/step - loss: 0.3131 - accuracy: 0.9007\n","Epoch 3723/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3138 - accuracy: 0.9026\n","Epoch 3723: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3137 - accuracy: 0.9021\n","Epoch 3724/4000\n","8/8 [==============================] - ETA: 0s - loss: 0.3152 - accuracy: 0.8997\n","Epoch 3724: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 57ms/step - loss: 0.3152 - accuracy: 0.8997\n","Epoch 3725/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3132 - accuracy: 0.9019\n","Epoch 3725: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 48ms/step - loss: 0.3124 - accuracy: 0.9021\n","Epoch 3726/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3142 - accuracy: 0.8991\n","Epoch 3726: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3149 - accuracy: 0.8992\n","Epoch 3727/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3150 - accuracy: 0.9003\n","Epoch 3727: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3139 - accuracy: 0.9010\n","Epoch 3728/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3080 - accuracy: 0.9011\n","Epoch 3728: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3118 - accuracy: 0.8996\n","Epoch 3729/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3097 - accuracy: 0.9001\n","Epoch 3729: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3092 - accuracy: 0.8999\n","Epoch 3730/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3123 - accuracy: 0.8998\n","Epoch 3730: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3107 - accuracy: 0.8996\n","Epoch 3731/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3056 - accuracy: 0.9018\n","Epoch 3731: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3085 - accuracy: 0.9007\n","Epoch 3732/4000\n","8/8 [==============================] - ETA: 0s - loss: 0.3116 - accuracy: 0.9002\n","Epoch 3732: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3116 - accuracy: 0.9002\n","Epoch 3733/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3123 - accuracy: 0.9035\n","Epoch 3733: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3134 - accuracy: 0.9024\n","Epoch 3734/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3091 - accuracy: 0.9037\n","Epoch 3734: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3098 - accuracy: 0.9034\n","Epoch 3735/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3064 - accuracy: 0.9026\n","Epoch 3735: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3107 - accuracy: 0.9012\n","Epoch 3736/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3089 - accuracy: 0.9005\n","Epoch 3736: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3116 - accuracy: 0.8999\n","Epoch 3737/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3079 - accuracy: 0.9032\n","Epoch 3737: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3125 - accuracy: 0.9019\n","Epoch 3738/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3174 - accuracy: 0.8996\n","Epoch 3738: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3125 - accuracy: 0.9011\n","Epoch 3739/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3118 - accuracy: 0.9015\n","Epoch 3739: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3139 - accuracy: 0.9011\n","Epoch 3740/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3047 - accuracy: 0.9009\n","Epoch 3740: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3137 - accuracy: 0.8987\n","Epoch 3741/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3122 - accuracy: 0.9011\n","Epoch 3741: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3119 - accuracy: 0.9006\n","Epoch 3742/4000\n","8/8 [==============================] - ETA: 0s - loss: 0.3117 - accuracy: 0.9023\n","Epoch 3742: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3117 - accuracy: 0.9023\n","Epoch 3743/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3115 - accuracy: 0.9003\n","Epoch 3743: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3119 - accuracy: 0.9002\n","Epoch 3744/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3158 - accuracy: 0.9014\n","Epoch 3744: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3169 - accuracy: 0.9010\n","Epoch 3745/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3141 - accuracy: 0.9001\n","Epoch 3745: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3142 - accuracy: 0.9001\n","Epoch 3746/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3150 - accuracy: 0.8997\n","Epoch 3746: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3169 - accuracy: 0.8985\n","Epoch 3747/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3107 - accuracy: 0.9012\n","Epoch 3747: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3116 - accuracy: 0.9009\n","Epoch 3748/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3134 - accuracy: 0.9009\n","Epoch 3748: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3116 - accuracy: 0.9016\n","Epoch 3749/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3131 - accuracy: 0.8989\n","Epoch 3749: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3132 - accuracy: 0.8984\n","Epoch 3750/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3075 - accuracy: 0.9008\n","Epoch 3750: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3119 - accuracy: 0.8990\n","Epoch 3751/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3097 - accuracy: 0.9018\n","Epoch 3751: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3147 - accuracy: 0.9005\n","Epoch 3752/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3099 - accuracy: 0.9016\n","Epoch 3752: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3148 - accuracy: 0.8994\n","Epoch 3753/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3089 - accuracy: 0.9007\n","Epoch 3753: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3100 - accuracy: 0.9015\n","Epoch 3754/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3161 - accuracy: 0.8989\n","Epoch 3754: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3165 - accuracy: 0.8979\n","Epoch 3755/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3110 - accuracy: 0.9012\n","Epoch 3755: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3129 - accuracy: 0.9002\n","Epoch 3756/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3091 - accuracy: 0.9022\n","Epoch 3756: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3125 - accuracy: 0.9009\n","Epoch 3757/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3170 - accuracy: 0.8990\n","Epoch 3757: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3124 - accuracy: 0.9002\n","Epoch 3758/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3141 - accuracy: 0.9023\n","Epoch 3758: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 48ms/step - loss: 0.3130 - accuracy: 0.9015\n","Epoch 3759/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3102 - accuracy: 0.9022\n","Epoch 3759: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3125 - accuracy: 0.9009\n","Epoch 3760/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3104 - accuracy: 0.9019\n","Epoch 3760: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3126 - accuracy: 0.9005\n","Epoch 3761/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3100 - accuracy: 0.9029\n","Epoch 3761: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3134 - accuracy: 0.9016\n","Epoch 3762/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3090 - accuracy: 0.9016\n","Epoch 3762: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3125 - accuracy: 0.8998\n","Epoch 3763/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3064 - accuracy: 0.9012\n","Epoch 3763: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3112 - accuracy: 0.8998\n","Epoch 3764/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3121 - accuracy: 0.9023\n","Epoch 3764: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3127 - accuracy: 0.9015\n","Epoch 3765/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3109 - accuracy: 0.9037\n","Epoch 3765: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 56ms/step - loss: 0.3135 - accuracy: 0.9024\n","Epoch 3766/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3064 - accuracy: 0.9029\n","Epoch 3766: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3169 - accuracy: 0.8983\n","Epoch 3767/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3136 - accuracy: 0.9018\n","Epoch 3767: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3199 - accuracy: 0.9003\n","Epoch 3768/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3180 - accuracy: 0.9001\n","Epoch 3768: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3179 - accuracy: 0.8999\n","Epoch 3769/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3139 - accuracy: 0.9008\n","Epoch 3769: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3180 - accuracy: 0.8988\n","Epoch 3770/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3202 - accuracy: 0.8987\n","Epoch 3770: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3182 - accuracy: 0.8996\n","Epoch 3771/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3125 - accuracy: 0.9018\n","Epoch 3771: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3140 - accuracy: 0.9001\n","Epoch 3772/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3061 - accuracy: 0.9049\n","Epoch 3772: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3120 - accuracy: 0.9025\n","Epoch 3773/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3103 - accuracy: 0.9032\n","Epoch 3773: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3122 - accuracy: 0.9014\n","Epoch 3774/4000\n","8/8 [==============================] - ETA: 0s - loss: 0.3126 - accuracy: 0.8989\n","Epoch 3774: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3126 - accuracy: 0.8989\n","Epoch 3775/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3134 - accuracy: 0.9001\n","Epoch 3775: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3168 - accuracy: 0.8985\n","Epoch 3776/4000\n","8/8 [==============================] - ETA: 0s - loss: 0.3158 - accuracy: 0.8996\n","Epoch 3776: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3158 - accuracy: 0.8996\n","Epoch 3777/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3154 - accuracy: 0.8977\n","Epoch 3777: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3133 - accuracy: 0.8988\n","Epoch 3778/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3122 - accuracy: 0.9007\n","Epoch 3778: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3135 - accuracy: 0.8996\n","Epoch 3779/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3100 - accuracy: 0.9037\n","Epoch 3779: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3129 - accuracy: 0.9021\n","Epoch 3780/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3103 - accuracy: 0.9015\n","Epoch 3780: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3121 - accuracy: 0.9005\n","Epoch 3781/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3132 - accuracy: 0.8986\n","Epoch 3781: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 57ms/step - loss: 0.3141 - accuracy: 0.8980\n","Epoch 3782/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3070 - accuracy: 0.9021\n","Epoch 3782: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3127 - accuracy: 0.9001\n","Epoch 3783/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3135 - accuracy: 0.9009\n","Epoch 3783: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3119 - accuracy: 0.9010\n","Epoch 3784/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3078 - accuracy: 0.9018\n","Epoch 3784: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3122 - accuracy: 0.8998\n","Epoch 3785/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3111 - accuracy: 0.9003\n","Epoch 3785: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3124 - accuracy: 0.9001\n","Epoch 3786/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3146 - accuracy: 0.9001\n","Epoch 3786: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3139 - accuracy: 0.9006\n","Epoch 3787/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3099 - accuracy: 0.9022\n","Epoch 3787: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3132 - accuracy: 0.9003\n","Epoch 3788/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3124 - accuracy: 0.9000\n","Epoch 3788: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3140 - accuracy: 0.8987\n","Epoch 3789/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3138 - accuracy: 0.8991\n","Epoch 3789: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3112 - accuracy: 0.8996\n","Epoch 3790/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3105 - accuracy: 0.8997\n","Epoch 3790: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3132 - accuracy: 0.8996\n","Epoch 3791/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3109 - accuracy: 0.9042\n","Epoch 3791: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3146 - accuracy: 0.9027\n","Epoch 3792/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3093 - accuracy: 0.8987\n","Epoch 3792: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3105 - accuracy: 0.8992\n","Epoch 3793/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3140 - accuracy: 0.8983\n","Epoch 3793: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3133 - accuracy: 0.8990\n","Epoch 3794/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3118 - accuracy: 0.8996\n","Epoch 3794: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3108 - accuracy: 0.8998\n","Epoch 3795/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3100 - accuracy: 0.9014\n","Epoch 3795: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3106 - accuracy: 0.9007\n","Epoch 3796/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3071 - accuracy: 0.9001\n","Epoch 3796: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3110 - accuracy: 0.8989\n","Epoch 3797/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3093 - accuracy: 0.8997\n","Epoch 3797: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3094 - accuracy: 0.8992\n","Epoch 3798/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3072 - accuracy: 0.9023\n","Epoch 3798: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 56ms/step - loss: 0.3114 - accuracy: 0.9010\n","Epoch 3799/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3090 - accuracy: 0.9035\n","Epoch 3799: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3102 - accuracy: 0.9029\n","Epoch 3800/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3115 - accuracy: 0.9022\n","Epoch 3800: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3120 - accuracy: 0.9014\n","Epoch 3801/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3062 - accuracy: 0.9015\n","Epoch 3801: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3111 - accuracy: 0.8996\n","Epoch 3802/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3090 - accuracy: 0.9007\n","Epoch 3802: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3138 - accuracy: 0.8996\n","Epoch 3803/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3089 - accuracy: 0.9030\n","Epoch 3803: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3145 - accuracy: 0.9003\n","Epoch 3804/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3122 - accuracy: 0.9042\n","Epoch 3804: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3135 - accuracy: 0.9034\n","Epoch 3805/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3135 - accuracy: 0.8972\n","Epoch 3805: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3201 - accuracy: 0.8954\n","Epoch 3806/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3135 - accuracy: 0.9023\n","Epoch 3806: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3192 - accuracy: 0.8999\n","Epoch 3807/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3164 - accuracy: 0.9008\n","Epoch 3807: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3191 - accuracy: 0.8996\n","Epoch 3808/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3086 - accuracy: 0.9026\n","Epoch 3808: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3142 - accuracy: 0.8996\n","Epoch 3809/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3125 - accuracy: 0.8980\n","Epoch 3809: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3134 - accuracy: 0.8976\n","Epoch 3810/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3111 - accuracy: 0.9040\n","Epoch 3810: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3148 - accuracy: 0.9020\n","Epoch 3811/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3152 - accuracy: 0.9015\n","Epoch 3811: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3150 - accuracy: 0.9009\n","Epoch 3812/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3072 - accuracy: 0.9035\n","Epoch 3812: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3146 - accuracy: 0.9011\n","Epoch 3813/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3073 - accuracy: 0.9008\n","Epoch 3813: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3145 - accuracy: 0.8992\n","Epoch 3814/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3136 - accuracy: 0.9011\n","Epoch 3814: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 49ms/step - loss: 0.3131 - accuracy: 0.9016\n","Epoch 3815/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3172 - accuracy: 0.8997\n","Epoch 3815: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3152 - accuracy: 0.9005\n","Epoch 3816/4000\n","8/8 [==============================] - ETA: 0s - loss: 0.3196 - accuracy: 0.8993\n","Epoch 3816: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3196 - accuracy: 0.8993\n","Epoch 3817/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3118 - accuracy: 0.9005\n","Epoch 3817: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3144 - accuracy: 0.8994\n","Epoch 3818/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3143 - accuracy: 0.8994\n","Epoch 3818: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3126 - accuracy: 0.9003\n","Epoch 3819/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3059 - accuracy: 0.9021\n","Epoch 3819: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3100 - accuracy: 0.9006\n","Epoch 3820/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3115 - accuracy: 0.8991\n","Epoch 3820: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 49ms/step - loss: 0.3134 - accuracy: 0.8977\n","Epoch 3821/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3074 - accuracy: 0.9016\n","Epoch 3821: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3107 - accuracy: 0.9001\n","Epoch 3822/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3110 - accuracy: 0.9011\n","Epoch 3822: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3120 - accuracy: 0.9010\n","Epoch 3823/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3173 - accuracy: 0.8965\n","Epoch 3823: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3155 - accuracy: 0.8971\n","Epoch 3824/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3092 - accuracy: 0.9023\n","Epoch 3824: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3159 - accuracy: 0.8994\n","Epoch 3825/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3160 - accuracy: 0.8997\n","Epoch 3825: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 56ms/step - loss: 0.3140 - accuracy: 0.9006\n","Epoch 3826/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3153 - accuracy: 0.9012\n","Epoch 3826: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3146 - accuracy: 0.9014\n","Epoch 3827/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3090 - accuracy: 0.9008\n","Epoch 3827: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3112 - accuracy: 0.8994\n","Epoch 3828/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3087 - accuracy: 0.9022\n","Epoch 3828: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3109 - accuracy: 0.9014\n","Epoch 3829/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3129 - accuracy: 0.8996\n","Epoch 3829: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3127 - accuracy: 0.8988\n","Epoch 3830/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3106 - accuracy: 0.9014\n","Epoch 3830: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3120 - accuracy: 0.9009\n","Epoch 3831/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3132 - accuracy: 0.8982\n","Epoch 3831: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3132 - accuracy: 0.8985\n","Epoch 3832/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3081 - accuracy: 0.9012\n","Epoch 3832: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3118 - accuracy: 0.8994\n","Epoch 3833/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3088 - accuracy: 0.9008\n","Epoch 3833: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3161 - accuracy: 0.8990\n","Epoch 3834/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3142 - accuracy: 0.9005\n","Epoch 3834: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3149 - accuracy: 0.8999\n","Epoch 3835/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3098 - accuracy: 0.8993\n","Epoch 3835: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 57ms/step - loss: 0.3127 - accuracy: 0.8981\n","Epoch 3836/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3045 - accuracy: 0.9022\n","Epoch 3836: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 49ms/step - loss: 0.3126 - accuracy: 0.9001\n","Epoch 3837/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3131 - accuracy: 0.9003\n","Epoch 3837: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 49ms/step - loss: 0.3176 - accuracy: 0.8983\n","Epoch 3838/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3122 - accuracy: 0.9011\n","Epoch 3838: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 56ms/step - loss: 0.3156 - accuracy: 0.9001\n","Epoch 3839/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3132 - accuracy: 0.9012\n","Epoch 3839: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3170 - accuracy: 0.9002\n","Epoch 3840/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3064 - accuracy: 0.9008\n","Epoch 3840: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3126 - accuracy: 0.8984\n","Epoch 3841/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3088 - accuracy: 0.9018\n","Epoch 3841: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3105 - accuracy: 0.9009\n","Epoch 3842/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3091 - accuracy: 0.9030\n","Epoch 3842: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 56ms/step - loss: 0.3127 - accuracy: 0.9010\n","Epoch 3843/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3121 - accuracy: 0.9000\n","Epoch 3843: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3141 - accuracy: 0.9002\n","Epoch 3844/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3057 - accuracy: 0.9033\n","Epoch 3844: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3113 - accuracy: 0.9006\n","Epoch 3845/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3069 - accuracy: 0.9018\n","Epoch 3845: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3107 - accuracy: 0.9002\n","Epoch 3846/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3077 - accuracy: 0.9008\n","Epoch 3846: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3139 - accuracy: 0.8990\n","Epoch 3847/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3069 - accuracy: 0.9033\n","Epoch 3847: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3128 - accuracy: 0.9015\n","Epoch 3848/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3118 - accuracy: 0.9004\n","Epoch 3848: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3104 - accuracy: 0.9002\n","Epoch 3849/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3131 - accuracy: 0.9007\n","Epoch 3849: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3126 - accuracy: 0.9014\n","Epoch 3850/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3101 - accuracy: 0.9009\n","Epoch 3850: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3110 - accuracy: 0.9006\n","Epoch 3851/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3147 - accuracy: 0.8986\n","Epoch 3851: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3141 - accuracy: 0.8992\n","Epoch 3852/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3089 - accuracy: 0.9009\n","Epoch 3852: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3112 - accuracy: 0.9003\n","Epoch 3853/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3086 - accuracy: 0.8998\n","Epoch 3853: loss did not improve from 0.30800\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3098 - accuracy: 0.8989\n","Epoch 3854/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3073 - accuracy: 0.9022\n","Epoch 3854: loss improved from 0.30800 to 0.30766, saving model to best_model_3.hdf5\n","8/8 [==============================] - 1s 103ms/step - loss: 0.3077 - accuracy: 0.9018\n","Epoch 3855/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3044 - accuracy: 0.9015\n","Epoch 3855: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3104 - accuracy: 0.8998\n","Epoch 3856/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3086 - accuracy: 0.9015\n","Epoch 3856: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3104 - accuracy: 0.9006\n","Epoch 3857/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3082 - accuracy: 0.9019\n","Epoch 3857: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3108 - accuracy: 0.9009\n","Epoch 3858/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3119 - accuracy: 0.9009\n","Epoch 3858: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3123 - accuracy: 0.9011\n","Epoch 3859/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3107 - accuracy: 0.9008\n","Epoch 3859: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 49ms/step - loss: 0.3119 - accuracy: 0.9006\n","Epoch 3860/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3088 - accuracy: 0.9007\n","Epoch 3860: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3112 - accuracy: 0.8997\n","Epoch 3861/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3100 - accuracy: 0.9015\n","Epoch 3861: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3083 - accuracy: 0.9025\n","Epoch 3862/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3079 - accuracy: 0.8996\n","Epoch 3862: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3102 - accuracy: 0.8994\n","Epoch 3863/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3157 - accuracy: 0.9003\n","Epoch 3863: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3153 - accuracy: 0.8999\n","Epoch 3864/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3090 - accuracy: 0.9008\n","Epoch 3864: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3139 - accuracy: 0.8993\n","Epoch 3865/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3079 - accuracy: 0.9021\n","Epoch 3865: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3118 - accuracy: 0.9014\n","Epoch 3866/4000\n","8/8 [==============================] - ETA: 0s - loss: 0.3142 - accuracy: 0.9010\n","Epoch 3866: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 57ms/step - loss: 0.3142 - accuracy: 0.9010\n","Epoch 3867/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3106 - accuracy: 0.8997\n","Epoch 3867: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3149 - accuracy: 0.8983\n","Epoch 3868/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3171 - accuracy: 0.9008\n","Epoch 3868: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3170 - accuracy: 0.9006\n","Epoch 3869/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3134 - accuracy: 0.9012\n","Epoch 3869: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3157 - accuracy: 0.9003\n","Epoch 3870/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3209 - accuracy: 0.9008\n","Epoch 3870: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3201 - accuracy: 0.9010\n","Epoch 3871/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3166 - accuracy: 0.9001\n","Epoch 3871: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3186 - accuracy: 0.8993\n","Epoch 3872/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3149 - accuracy: 0.8997\n","Epoch 3872: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3154 - accuracy: 0.8992\n","Epoch 3873/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3113 - accuracy: 0.9026\n","Epoch 3873: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3174 - accuracy: 0.9003\n","Epoch 3874/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3137 - accuracy: 0.8983\n","Epoch 3874: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3147 - accuracy: 0.8981\n","Epoch 3875/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3163 - accuracy: 0.9009\n","Epoch 3875: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3184 - accuracy: 0.8994\n","Epoch 3876/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3150 - accuracy: 0.9007\n","Epoch 3876: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3165 - accuracy: 0.9003\n","Epoch 3877/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3208 - accuracy: 0.9005\n","Epoch 3877: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3192 - accuracy: 0.9009\n","Epoch 3878/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3154 - accuracy: 0.9029\n","Epoch 3878: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3177 - accuracy: 0.9010\n","Epoch 3879/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3198 - accuracy: 0.8990\n","Epoch 3879: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3186 - accuracy: 0.8990\n","Epoch 3880/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3145 - accuracy: 0.9009\n","Epoch 3880: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3170 - accuracy: 0.9007\n","Epoch 3881/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3239 - accuracy: 0.8984\n","Epoch 3881: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3223 - accuracy: 0.8988\n","Epoch 3882/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3277 - accuracy: 0.8991\n","Epoch 3882: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3279 - accuracy: 0.8984\n","Epoch 3883/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3330 - accuracy: 0.8975\n","Epoch 3883: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3357 - accuracy: 0.8965\n","Epoch 3884/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3433 - accuracy: 0.8996\n","Epoch 3884: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3451 - accuracy: 0.8989\n","Epoch 3885/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3563 - accuracy: 0.8915\n","Epoch 3885: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3541 - accuracy: 0.8926\n","Epoch 3886/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3655 - accuracy: 0.8947\n","Epoch 3886: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3671 - accuracy: 0.8946\n","Epoch 3887/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3809 - accuracy: 0.8923\n","Epoch 3887: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3899 - accuracy: 0.8895\n","Epoch 3888/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.4068 - accuracy: 0.8841\n","Epoch 3888: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 54ms/step - loss: 0.4110 - accuracy: 0.8827\n","Epoch 3889/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.4631 - accuracy: 0.8736\n","Epoch 3889: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 54ms/step - loss: 0.4605 - accuracy: 0.8752\n","Epoch 3890/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.5645 - accuracy: 0.8510\n","Epoch 3890: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 55ms/step - loss: 0.5737 - accuracy: 0.8491\n","Epoch 3891/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.6499 - accuracy: 0.8354\n","Epoch 3891: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 55ms/step - loss: 0.6652 - accuracy: 0.8333\n","Epoch 3892/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.7582 - accuracy: 0.8100\n","Epoch 3892: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 52ms/step - loss: 0.7625 - accuracy: 0.8086\n","Epoch 3893/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.8074 - accuracy: 0.8076\n","Epoch 3893: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 51ms/step - loss: 0.8247 - accuracy: 0.8027\n","Epoch 3894/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.8081 - accuracy: 0.8188\n","Epoch 3894: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 55ms/step - loss: 0.8154 - accuracy: 0.8161\n","Epoch 3895/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.7536 - accuracy: 0.8357\n","Epoch 3895: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 52ms/step - loss: 0.7659 - accuracy: 0.8345\n","Epoch 3896/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.7178 - accuracy: 0.8450\n","Epoch 3896: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 51ms/step - loss: 0.7188 - accuracy: 0.8443\n","Epoch 3897/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.6784 - accuracy: 0.8560\n","Epoch 3897: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 54ms/step - loss: 0.6864 - accuracy: 0.8539\n","Epoch 3898/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.6296 - accuracy: 0.8623\n","Epoch 3898: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 53ms/step - loss: 0.6319 - accuracy: 0.8616\n","Epoch 3899/4000\n","8/8 [==============================] - ETA: 0s - loss: 0.5865 - accuracy: 0.8672\n","Epoch 3899: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 52ms/step - loss: 0.5865 - accuracy: 0.8672\n","Epoch 3900/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.5343 - accuracy: 0.8799\n","Epoch 3900: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 53ms/step - loss: 0.5370 - accuracy: 0.8790\n","Epoch 3901/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.5065 - accuracy: 0.8842\n","Epoch 3901: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 49ms/step - loss: 0.5072 - accuracy: 0.8844\n","Epoch 3902/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.4701 - accuracy: 0.8903\n","Epoch 3902: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 52ms/step - loss: 0.4717 - accuracy: 0.8893\n","Epoch 3903/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.4425 - accuracy: 0.8929\n","Epoch 3903: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 55ms/step - loss: 0.4471 - accuracy: 0.8908\n","Epoch 3904/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.4237 - accuracy: 0.8962\n","Epoch 3904: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 54ms/step - loss: 0.4234 - accuracy: 0.8958\n","Epoch 3905/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.4042 - accuracy: 0.8959\n","Epoch 3905: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 54ms/step - loss: 0.4006 - accuracy: 0.8965\n","Epoch 3906/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3824 - accuracy: 0.9003\n","Epoch 3906: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3858 - accuracy: 0.8993\n","Epoch 3907/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3745 - accuracy: 0.8984\n","Epoch 3907: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3728 - accuracy: 0.8985\n","Epoch 3908/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3551 - accuracy: 0.9007\n","Epoch 3908: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3569 - accuracy: 0.8990\n","Epoch 3909/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3470 - accuracy: 0.9035\n","Epoch 3909: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3482 - accuracy: 0.9021\n","Epoch 3910/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3356 - accuracy: 0.9030\n","Epoch 3910: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3382 - accuracy: 0.9012\n","Epoch 3911/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3297 - accuracy: 0.9021\n","Epoch 3911: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3333 - accuracy: 0.9009\n","Epoch 3912/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3269 - accuracy: 0.9011\n","Epoch 3912: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3275 - accuracy: 0.9011\n","Epoch 3913/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3247 - accuracy: 0.9015\n","Epoch 3913: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3254 - accuracy: 0.9007\n","Epoch 3914/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3175 - accuracy: 0.9008\n","Epoch 3914: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3205 - accuracy: 0.9006\n","Epoch 3915/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3196 - accuracy: 0.9019\n","Epoch 3915: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3180 - accuracy: 0.9023\n","Epoch 3916/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3172 - accuracy: 0.9008\n","Epoch 3916: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3151 - accuracy: 0.9016\n","Epoch 3917/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3151 - accuracy: 0.9028\n","Epoch 3917: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3156 - accuracy: 0.9018\n","Epoch 3918/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3100 - accuracy: 0.9025\n","Epoch 3918: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3144 - accuracy: 0.9010\n","Epoch 3919/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3089 - accuracy: 0.9022\n","Epoch 3919: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3133 - accuracy: 0.9012\n","Epoch 3920/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3114 - accuracy: 0.9011\n","Epoch 3920: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3144 - accuracy: 0.9007\n","Epoch 3921/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3085 - accuracy: 0.9025\n","Epoch 3921: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3108 - accuracy: 0.9010\n","Epoch 3922/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3088 - accuracy: 0.9025\n","Epoch 3922: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3118 - accuracy: 0.9015\n","Epoch 3923/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3088 - accuracy: 0.9040\n","Epoch 3923: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3111 - accuracy: 0.9023\n","Epoch 3924/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3107 - accuracy: 0.8975\n","Epoch 3924: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3117 - accuracy: 0.8970\n","Epoch 3925/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3098 - accuracy: 0.9011\n","Epoch 3925: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3115 - accuracy: 0.9005\n","Epoch 3926/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3103 - accuracy: 0.9008\n","Epoch 3926: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3084 - accuracy: 0.9015\n","Epoch 3927/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3115 - accuracy: 0.8997\n","Epoch 3927: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3108 - accuracy: 0.9010\n","Epoch 3928/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3077 - accuracy: 0.9014\n","Epoch 3928: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3090 - accuracy: 0.9003\n","Epoch 3929/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3099 - accuracy: 0.9016\n","Epoch 3929: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3091 - accuracy: 0.9021\n","Epoch 3930/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3001 - accuracy: 0.9033\n","Epoch 3930: loss improved from 0.30766 to 0.30766, saving model to best_model_3.hdf5\n","8/8 [==============================] - 1s 108ms/step - loss: 0.3077 - accuracy: 0.9005\n","Epoch 3931/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3108 - accuracy: 0.9019\n","Epoch 3931: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3093 - accuracy: 0.9016\n","Epoch 3932/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3108 - accuracy: 0.9001\n","Epoch 3932: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3130 - accuracy: 0.8994\n","Epoch 3933/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3107 - accuracy: 0.9005\n","Epoch 3933: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3115 - accuracy: 0.9007\n","Epoch 3934/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3118 - accuracy: 0.9026\n","Epoch 3934: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3144 - accuracy: 0.9012\n","Epoch 3935/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3081 - accuracy: 0.9003\n","Epoch 3935: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3091 - accuracy: 0.8996\n","Epoch 3936/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3060 - accuracy: 0.9026\n","Epoch 3936: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 56ms/step - loss: 0.3130 - accuracy: 0.8996\n","Epoch 3937/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3065 - accuracy: 0.9015\n","Epoch 3937: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3097 - accuracy: 0.8997\n","Epoch 3938/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3070 - accuracy: 0.8991\n","Epoch 3938: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3094 - accuracy: 0.8983\n","Epoch 3939/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3068 - accuracy: 0.9004\n","Epoch 3939: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3118 - accuracy: 0.8993\n","Epoch 3940/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3060 - accuracy: 0.9032\n","Epoch 3940: loss did not improve from 0.30766\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3094 - accuracy: 0.9021\n","Epoch 3941/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3058 - accuracy: 0.9001\n","Epoch 3941: loss improved from 0.30766 to 0.30741, saving model to best_model_3.hdf5\n","8/8 [==============================] - 1s 109ms/step - loss: 0.3074 - accuracy: 0.8999\n","Epoch 3942/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3080 - accuracy: 0.9012\n","Epoch 3942: loss did not improve from 0.30741\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3094 - accuracy: 0.9006\n","Epoch 3943/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3029 - accuracy: 0.9051\n","Epoch 3943: loss improved from 0.30741 to 0.30673, saving model to best_model_3.hdf5\n","8/8 [==============================] - 1s 108ms/step - loss: 0.3067 - accuracy: 0.9038\n","Epoch 3944/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3041 - accuracy: 0.9049\n","Epoch 3944: loss did not improve from 0.30673\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3081 - accuracy: 0.9021\n","Epoch 3945/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3065 - accuracy: 0.9004\n","Epoch 3945: loss did not improve from 0.30673\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3117 - accuracy: 0.8996\n","Epoch 3946/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3099 - accuracy: 0.9001\n","Epoch 3946: loss did not improve from 0.30673\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3083 - accuracy: 0.9009\n","Epoch 3947/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3064 - accuracy: 0.9026\n","Epoch 3947: loss did not improve from 0.30673\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3101 - accuracy: 0.9016\n","Epoch 3948/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3060 - accuracy: 0.9028\n","Epoch 3948: loss did not improve from 0.30673\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3104 - accuracy: 0.9009\n","Epoch 3949/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3079 - accuracy: 0.9009\n","Epoch 3949: loss did not improve from 0.30673\n","8/8 [==============================] - 0s 57ms/step - loss: 0.3072 - accuracy: 0.9010\n","Epoch 3950/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3033 - accuracy: 0.9040\n","Epoch 3950: loss did not improve from 0.30673\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3088 - accuracy: 0.9021\n","Epoch 3951/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3067 - accuracy: 0.9004\n","Epoch 3951: loss did not improve from 0.30673\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3076 - accuracy: 0.9002\n","Epoch 3952/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3095 - accuracy: 0.8987\n","Epoch 3952: loss did not improve from 0.30673\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3105 - accuracy: 0.8985\n","Epoch 3953/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3086 - accuracy: 0.9016\n","Epoch 3953: loss did not improve from 0.30673\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3081 - accuracy: 0.9011\n","Epoch 3954/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3020 - accuracy: 0.9029\n","Epoch 3954: loss did not improve from 0.30673\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3093 - accuracy: 0.8998\n","Epoch 3955/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3028 - accuracy: 0.9022\n","Epoch 3955: loss did not improve from 0.30673\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3068 - accuracy: 0.9010\n","Epoch 3956/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3058 - accuracy: 0.9032\n","Epoch 3956: loss did not improve from 0.30673\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3080 - accuracy: 0.9027\n","Epoch 3957/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3062 - accuracy: 0.9021\n","Epoch 3957: loss did not improve from 0.30673\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3092 - accuracy: 0.9006\n","Epoch 3958/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3019 - accuracy: 0.9028\n","Epoch 3958: loss improved from 0.30673 to 0.30523, saving model to best_model_3.hdf5\n","8/8 [==============================] - 1s 105ms/step - loss: 0.3052 - accuracy: 0.9016\n","Epoch 3959/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3020 - accuracy: 0.9003\n","Epoch 3959: loss did not improve from 0.30523\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3058 - accuracy: 0.8985\n","Epoch 3960/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3070 - accuracy: 0.9023\n","Epoch 3960: loss did not improve from 0.30523\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3067 - accuracy: 0.9020\n","Epoch 3961/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3108 - accuracy: 0.9011\n","Epoch 3961: loss did not improve from 0.30523\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3090 - accuracy: 0.9016\n","Epoch 3962/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3068 - accuracy: 0.9005\n","Epoch 3962: loss did not improve from 0.30523\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3077 - accuracy: 0.9001\n","Epoch 3963/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3038 - accuracy: 0.9018\n","Epoch 3963: loss improved from 0.30523 to 0.30493, saving model to best_model_3.hdf5\n","8/8 [==============================] - 1s 103ms/step - loss: 0.3049 - accuracy: 0.9015\n","Epoch 3964/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3017 - accuracy: 0.9001\n","Epoch 3964: loss did not improve from 0.30493\n","8/8 [==============================] - 0s 56ms/step - loss: 0.3065 - accuracy: 0.8980\n","Epoch 3965/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3111 - accuracy: 0.8982\n","Epoch 3965: loss did not improve from 0.30493\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3080 - accuracy: 0.8993\n","Epoch 3966/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3100 - accuracy: 0.9033\n","Epoch 3966: loss did not improve from 0.30493\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3100 - accuracy: 0.9029\n","Epoch 3967/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3105 - accuracy: 0.8990\n","Epoch 3967: loss did not improve from 0.30493\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3103 - accuracy: 0.8990\n","Epoch 3968/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3031 - accuracy: 0.9040\n","Epoch 3968: loss did not improve from 0.30493\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3058 - accuracy: 0.9027\n","Epoch 3969/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3042 - accuracy: 0.9019\n","Epoch 3969: loss did not improve from 0.30493\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3079 - accuracy: 0.9007\n","Epoch 3970/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3059 - accuracy: 0.8996\n","Epoch 3970: loss did not improve from 0.30493\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3086 - accuracy: 0.8985\n","Epoch 3971/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3105 - accuracy: 0.9023\n","Epoch 3971: loss did not improve from 0.30493\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3094 - accuracy: 0.9019\n","Epoch 3972/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3018 - accuracy: 0.9057\n","Epoch 3972: loss did not improve from 0.30493\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3057 - accuracy: 0.9041\n","Epoch 3973/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3079 - accuracy: 0.9019\n","Epoch 3973: loss did not improve from 0.30493\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3097 - accuracy: 0.9002\n","Epoch 3974/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3060 - accuracy: 0.9021\n","Epoch 3974: loss did not improve from 0.30493\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3073 - accuracy: 0.9019\n","Epoch 3975/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3077 - accuracy: 0.8998\n","Epoch 3975: loss did not improve from 0.30493\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3073 - accuracy: 0.8993\n","Epoch 3976/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3065 - accuracy: 0.8986\n","Epoch 3976: loss did not improve from 0.30493\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3080 - accuracy: 0.8976\n","Epoch 3977/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3027 - accuracy: 0.9018\n","Epoch 3977: loss did not improve from 0.30493\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3049 - accuracy: 0.9007\n","Epoch 3978/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3036 - accuracy: 0.9015\n","Epoch 3978: loss did not improve from 0.30493\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3063 - accuracy: 0.9011\n","Epoch 3979/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3031 - accuracy: 0.9018\n","Epoch 3979: loss did not improve from 0.30493\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3067 - accuracy: 0.9001\n","Epoch 3980/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3026 - accuracy: 0.9014\n","Epoch 3980: loss did not improve from 0.30493\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3054 - accuracy: 0.9009\n","Epoch 3981/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3088 - accuracy: 0.8997\n","Epoch 3981: loss did not improve from 0.30493\n","8/8 [==============================] - 0s 56ms/step - loss: 0.3054 - accuracy: 0.8999\n","Epoch 3982/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3063 - accuracy: 0.8996\n","Epoch 3982: loss did not improve from 0.30493\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3070 - accuracy: 0.8988\n","Epoch 3983/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3055 - accuracy: 0.9012\n","Epoch 3983: loss did not improve from 0.30493\n","8/8 [==============================] - 0s 58ms/step - loss: 0.3059 - accuracy: 0.9009\n","Epoch 3984/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3016 - accuracy: 0.9021\n","Epoch 3984: loss did not improve from 0.30493\n","8/8 [==============================] - 0s 51ms/step - loss: 0.3056 - accuracy: 0.9002\n","Epoch 3985/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.2990 - accuracy: 0.9043\n","Epoch 3985: loss did not improve from 0.30493\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3052 - accuracy: 0.9019\n","Epoch 3986/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.2998 - accuracy: 0.9046\n","Epoch 3986: loss improved from 0.30493 to 0.30386, saving model to best_model_3.hdf5\n","8/8 [==============================] - 1s 103ms/step - loss: 0.3039 - accuracy: 0.9021\n","Epoch 3987/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.2983 - accuracy: 0.9019\n","Epoch 3987: loss did not improve from 0.30386\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3046 - accuracy: 0.8998\n","Epoch 3988/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3006 - accuracy: 0.9030\n","Epoch 3988: loss did not improve from 0.30386\n","8/8 [==============================] - 0s 56ms/step - loss: 0.3068 - accuracy: 0.9011\n","Epoch 3989/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3026 - accuracy: 0.9030\n","Epoch 3989: loss did not improve from 0.30386\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3085 - accuracy: 0.9005\n","Epoch 3990/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3074 - accuracy: 0.9026\n","Epoch 3990: loss did not improve from 0.30386\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3097 - accuracy: 0.9011\n","Epoch 3991/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3040 - accuracy: 0.9028\n","Epoch 3991: loss did not improve from 0.30386\n","8/8 [==============================] - 0s 52ms/step - loss: 0.3065 - accuracy: 0.9011\n","Epoch 3992/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3082 - accuracy: 0.8996\n","Epoch 3992: loss did not improve from 0.30386\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3069 - accuracy: 0.9005\n","Epoch 3993/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3005 - accuracy: 0.9008\n","Epoch 3993: loss did not improve from 0.30386\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3055 - accuracy: 0.8994\n","Epoch 3994/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3067 - accuracy: 0.8994\n","Epoch 3994: loss did not improve from 0.30386\n","8/8 [==============================] - 0s 54ms/step - loss: 0.3065 - accuracy: 0.8998\n","Epoch 3995/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3014 - accuracy: 0.9025\n","Epoch 3995: loss did not improve from 0.30386\n","8/8 [==============================] - 0s 56ms/step - loss: 0.3049 - accuracy: 0.9006\n","Epoch 3996/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3083 - accuracy: 0.9005\n","Epoch 3996: loss did not improve from 0.30386\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3074 - accuracy: 0.9003\n","Epoch 3997/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.2973 - accuracy: 0.9044\n","Epoch 3997: loss did not improve from 0.30386\n","8/8 [==============================] - 0s 53ms/step - loss: 0.3056 - accuracy: 0.9021\n","Epoch 3998/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3060 - accuracy: 0.9025\n","Epoch 3998: loss did not improve from 0.30386\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3065 - accuracy: 0.9027\n","Epoch 3999/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3059 - accuracy: 0.9026\n","Epoch 3999: loss did not improve from 0.30386\n","8/8 [==============================] - 0s 55ms/step - loss: 0.3072 - accuracy: 0.9027\n","Epoch 4000/4000\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3040 - accuracy: 0.9014\n","Epoch 4000: loss did not improve from 0.30386\n","8/8 [==============================] - 0s 50ms/step - loss: 0.3074 - accuracy: 0.8996\n"]}]},{"cell_type":"markdown","metadata":{"id":"FWJR7YxwYNs8"},"source":["# Plotting the training graphs "]},{"cell_type":"code","metadata":{"id":"rcXreH5urHwX","colab":{"base_uri":"https://localhost:8080/","height":545},"executionInfo":{"status":"ok","timestamp":1645399101977,"user_tz":-360,"elapsed":1284,"user":{"displayName":"Mimsadi Islam","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07228862094531790502"}},"outputId":"fcf538ce-26c9-44b7-b92e-2117582828c4"},"source":["import matplotlib.pyplot as plt\n","accuracy = history.history['accuracy']\n","loss = history.history['loss']\n","\n","epochs = range(len(accuracy))\n","\n","plt.plot(epochs, accuracy, 'b', label='Training accuracy')\n","plt.title('Training accuracy')\n","\n","plt.figure()\n","\n","plt.plot(epochs, loss, 'b', label='Training Loss')\n","plt.title('Training loss')\n","plt.legend()\n","\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3debgcZZn38e+dPTFhyQaBBBMFgcALGI4s4kgwLAnMEF4NmhgQBY0sEVR2GRAY9QKUAcTMCLwQESGsyuSSKAqCihLIiUSWIBgTmBACCSGELZDtfv94qu3qPt3ndPep7url97muvrqqurrq7jp9fv30U9VV5u6IiEjj65F2ASIikgwFuohIk1Cgi4g0CQW6iEiTUKCLiDQJBbqISJNQoEtdMbNfmdkJSc8r0gpMx6FLd5nZ27HRAcD7wOZo/KvufmvtqxJpPQp0SZSZvQB82d0fKPBYL3ffVPuqGou2k1RKXS5SNWY23sxeMrNzzewVYLaZbWtmvzSz1Wa2NhoeGXvOw2b25Wj4i2b2iJn9IJp3mZlNqnDeMWb2BzN7y8weMLNZZvazInV3VeNgM5ttZi9Hj98be2yymS0yszfN7B9mNjGa/oKZHRqb7+LM+s1stJm5mZ1kZv8L/C6afpeZvWJm66La94g9v7+ZXWlmL0aPPxJNu8/Mvpb3ep40s/9b7t9PGo8CXapte2Aw8EFgBuE9Nzsa3wlYD/yok+fvDzwHDAWuAG40M6tg3tuAx4EhwMXA8Z2ss6sabyF0Le0BDAeuAjCz/YCfAmcD2wCfBF7oZD35DgZ2B46Ixn8F7BKt4y9AvOvqB8C+wMcJ2/ccYAtwM3BcZiYz2xvYEbivjDqkUbm7broldiME2KHR8HhgA9Cvk/n3AdbGxh8mdNkAfBFYEntsAODA9uXMSwjlTcCA2OM/A35W4mv6Z43ACEJwbltgvuuAq7raLtH4xZn1A6OjWj/USQ3bRPNsTfjAWQ/sXWC+fsBaYJdo/AfAf6X9vtCtNje10KXaVrv7e5kRMxtgZtdFXQVvAn8AtjGznkWe/0pmwN3fjQYHljnvDsDrsWkAy4sV3EWNo6JlrS3w1FHAP4ottwT/rMnMeprZZVG3zZtkW/pDo1u/QuuKtvUdwHFm1gOYRvhGIS1AgS7Vlr/X/UxgV2B/d9+K0C0BUKwbJQkrgcFmNiA2bVQn83dW4/JoWdsUeN5y4MNFlvkO4VtDxvYF5olvq88Dk4FDCa3y0bEaXgPe62RdNwPTgQnAu+7+aJH5pMko0KXWBhG6C94ws8HAt6u9Qnd/EWgHLjazPmZ2IPBvldTo7isJfdv/Fe087W1mmcC/EfiSmU0wsx5mtqOZ7RY9tgiYGs3fBkzpouxBhMM/1xA+CL4Xq2ELcBPwn2a2Q9SaP9DM+kaPP0roFroStc5bigJdau1qoD+hlTkf+HWN1jsdOJAQkN8hdEu8X2Termo8HtgI/A1YBXwdwN0fB75E2Em6Dvg9YccqwIWEFvVa4BLCTtrO/BR4EVgBLI7qiDsLeApYALwOXE7u//NPgf9D2FcgLULHoUtLMrM7gL+5e9W/IaTBzL4AzHD3T6Rdi9SOWujSEszsY2b24agrZCKhf/rerp7XiKJ9BacC16ddi9SWAl1axfaEwxzfBn4InOLuT6RaURWY2RHAauBVuu7WkSajLhcRkSahFrqISJPoldaKhw4d6qNHj05r9SIiDWnhwoWvufuwQo+lFuijR4+mvb09rdWLiDQkM3ux2GPqchERaRIKdBGRJqFAFxFpEgp0EZEmoUAXEWkSCnQRkSahQBcRaRIKdKkLm0q4xv369dWvo5q2bIE1a7qeb926rud580146aXS1715c+Hpb78Nb71V+LHHHoNly0pfxzvvhGXln03EPfuaVq/OrWnLFtiwIfdvu3lzeM6WLeF1ZqxbF94n8WUUej0bNsCrr8Idd5RW9/r1YT2Zut98E957L/v4K690fM6aNaW9ZzdsgL//PQzPnx/WUdWzraR17bt9993XpfbeeMP9tdc6Tt+0yX39+sLPWbo08zZ0/+pX3WfMCMPf+lZ4fPNm909/OjtP/q293X3Nmuzy9t+/+LyZ2377hVrdu54X3K+/3v3883OnXXhheP4tt5S2jPzbhg3u771X2XMzt8WL3U84ofLnb7dd2L4//nH36ojfli93v+KK5Jb36KPuZ52V3PIK3ebMSW5ZP/qR+003Va/WV1/tep758yv/Hwba3QvnasGJtbgp0Gtr4sTcN9QBB7hv2RIee+ih4m+8NWs6f2MuWlT6G/3BB8M6y/nn+NOfuvfP9eabIRQrff6JJybzT96d2xlnpF+DbsneLrus8v/lzgJdXS5NZu5cMAu3L30pO/3XedfcmT8f7rwTJkyAQw4pvrypUztf33e/W3ptEybAE3knrLUuriT6swqutxNf5qhRMHhwGD766HA/YgRsU+iKoAXEv24fcEB2mSeeGIbHjw/3/fp1vpxddgn3Z50FRxwBe+4JY8fC974HF14In/kMtLXBVluF+eJ/u2uuyQ6fcUaY/9vfhjFjwrSvfjXUs+eexV/XwQfDbrtlxzPzXXJJuN9/f7j7bjj7bDj/fDj5ZPjhD2HpUvjJT0KtcZMmwTe/mR3/+Mdh6FB4/HFYuRIuvzxMP+KI8PyHH4YVK+ArXwnTp0wJf49jjw3j06fDUUeFOg4/HI4/Hvbeu+PrOOccOPNMOPfc7LR774WHHoLhw+HAA8PwxRfDtGlhm5xyShg/5hjYb7/c5T39NPzmN2GbzpkTpn3rW+G1DR4cnnvPPeE9ddJJ0LMn/FuBixdecgmMG5c77ZRT4HOfg+uug4MOgoED4eqr4Y9/hFNP7biMRBRL+mrf1EJPRqbFO2SI+4oVHVsCa9a4//a3lbckhg4N96ee6r7nnmH4ttvc3347d76vfS102WzenFvfO++4/8//dFzuL3/Z+es68kj3HXd0P/dc9969s98mClm2LLvczHyrVmWnDRoUWrnluOaa8NxRo9wnTCjvue6hjmOOydZwzz3lL8M9u80hdJN012mnuffv796jR7ZLqjtuvDHUNmxY+BaYtJdfzr7+mTO7v7zHHssub8qU7i8vX2bZZqEbsxpQC715Pf98uF+zJrTy8g0ZAocdlh1fuRLeeKPjfLvvnt1B9fLLkDlv2muvwQ47wKxZ8Pvfww03hFb7gAG5z7/mmtBK7ZH3jhowILTE7rord/q++3b+usaODeu+8krYuLHzlvzo0bBkSdiZlplv2LCwjn32CTvqhg7tfH35Mq3D5cvhAx8o77kQ6hg5Mju+9dblLwPg9NOzw8OHV7aMuKFDw07ALVvCduuubbcN96tXd/wWmIT+/bPDlW7DYsvLfLtK0pTo0t9DhoTWfK0p0BvQkiWwaFHYix//Gj0/uozwF76Q7R6ImzMHtt8++7U+41OfgsWLQwj17h26JOLzZIJp8GD48pezXTq9e4fpQ4Z03XUyJe8a910F7K67wvvvl3YkAcCHP9zxw2TnncO2KmV9+eLzDxxY3nMzBg3KDlcaRvEPk1K7iToTD7Qdd+z+8jKBXi19+mSHkwj0eNdYEh+Q+TL/N8MKnty2+lI7fa5UZu3abH9sMeeeG1raH/1o7vRMyJuFAJ80CU44Ab7xjY7LyPTPQu4hXHEbN4b7/H7JYq67LvT3AvTq4p2XRFAMGxYOY4PyA33IkOxwJS10yP0WU2kYxwPogx+sbBlx8ZriHziViv+dLrqo+8vLV81AT+IDMl8m0PMbTbWiFnoDWb06u4Mv7tprc8eHDg1dDZ//fO70+Jt5993hhRfCzpxCb+xevbJB/eSTnddVajCU8w+0YEF2+JxzSn9eXLwFVm6LKb6dKw30+PauNIyq2eWQ321WiXhNSdSXL95tkcTy+/bNDifx+ostP76da0mB3iDefbf4V8SZM3MDKDN8xhm5822/fXnrzPzg5IQTOp+v1EAvp09x2rTscKUt0/j2KreF3qdP9h++0i6XpAM9HkaViodYEoEWry/emk5KvCsv6RZ6NUI30w2ZVqCry6WOvf126CtfsCD3ELG4TN/0mjXwt7/BI49kuzNK7Qop5tlnw/2ECZ3PV2owlBPou++eHa60ayD+ARbvQilVpt5KW+hJhF18GV0dGlmKpAM9XlMSHzidSbrearTQM4FejQ+3UqiFXsdOPRX+5V+KhzmE43czdtst7LQsZOHCyusoFmiZfvbbbittOZmdlqUEe/wfotIW8ogR2eFK+kszP5dPosulUkm30JPucokvr9pXlEwiJDOBC9VtoadxhAuohV7Xbrml63kmT+788XXrwpur0lCC4m/OTECX+o+WWU78n6oUlf7jxQOrknDdsCHcV/qBkkRg1HuXS/xvmTmiqFqSeP3xLpxmDHS10OuQe+FjZPv0gUcfzf66Dro+XHCrrboX5lD8zXnffSHsFi0qbTnlfgBkWtVJBHolModMptlCjy+jqyODSpH0B0T8/Xfhhd1fXmeS7tKpRqBn/kZqocs/3Xpr+BFPvgULYK+9wk/2+/ULx2nXQrEfYOy6a/Ez9RWSeZOXGuiZMKv0H6/QEUGVSKIPvVJJh078Q66rxkC5Cv1UP0mNEOhpt9AV6HXo+OMLT49/9V+2rLRTsXbHjTeGX6JW2uWQr9xAf/fdcF9pSzupw+iSOMqlUkmHTjWPvkjiuPbOJB3oSXzjyadAlxzXXVf8sXiwjBiRu9OvGjInoEpKuV0umXNhFzuXd1eSaoHWy07RJFTjyI6MagRkXFKBPn16OFlYNWSCvNrbohgFep05+eTijyXVUk5LpTtFd945+VrKkWaXS/7pDLorreOjk5DUoYCVnMGzVJnGh1rowlNP5Y4PGQJ/+Uv2hzWN/M8I5Xe5vPhi2Cbd2ak7Zkz2lK2VqvSDtNrHZVeikd9D9bg982V2pCvQhb32yg5PmgTz5uU+nvROrFrLtDZLbaHvtFO4dcfSpZU/99JLw/lJKvlREqT3tbsz5X47qidp/VinHAp0wb3jdQvvuy+dWqop84FUj0FXyL//ezhxWaX9zvX6OqdOhe22S25599wT3sPVlnT3UzWk3eVS0iYys4lm9pyZLTGz8wo8vpOZPWRmT5jZk2Z2ZPKlNqctW8LJtXbYITstc4WUjP33r31d1ZBpvTRCSwvC36A7+y0ygV5vXQVz5oQr5yTl058ufC7+VpQJ9LrdKWpmPYFZwGHAS8ACM5vr7otjs/07cKe7/7eZjQXmAaOrUG/TOfFEuPnm3Gn5Fx545JHKj/SoJ5nT7Tby1/5KVOM0rVKf0m6hl/I5sh+wxN2XApjZ7cBkIB7oDmTOALw18HKSRTaz/DCHjp/uvXrV79f3cmTe5M3w4VSKoUPDNUS7e/jnnDmNvTOzu04+OXtlrnqX2YFf7Qt/FGPeReeXmU0BJrr7l6Px44H93X1mbJ4RwG+AbYEPAIe6e4fTQZnZDGAGwE477bTviy++mNTraFiFdnS+/np6b4hqev/9cAzwpZd2vOiwSDPYuDFcjvH006vXtWhmC929rdBjSe1mmAb8xN1HAkcCt5hZh2W7+/Xu3ububcPSukZTHdmypeO0MWOaM8wh9CXffbfCXJpX797hW1k9nz53BTAqNj4ymhZ3EnAngLs/CvQDyrykQOvJ73qYPbt7h9mJSGsrJdAXALuY2Rgz6wNMBebmzfO/wAQAM9udEOirkyy02WzYEA6LizvuuHRqEZHm0GWgu/smYCZwP/As4WiWZ8zsUjM7OprtTOArZvZXYA7wRe+qc77FzZ4NV1yRO60ZdnyKSHpKihB3n0c4FDE+7aLY8GLgoGRLa2733pt2BSLSbBrgt1fNp70dfv3rtKsQkWajQE/Bxz7WcdrPf177OkSkuSjQa6zYnoWJE2tbh4g0HwV6jb36asdpn/1sa/8SUESSoUCvsUI/e6/09KwiInEK9BordGX0JC5VJiKiQK+hV18Nx5/n+8Qnal+LiDQfBXqN3HcfbL997rThw2H58nA+aRGR7lKg18isWR2nTZ8OI0fWvhYRaU4K9BopdGZFnRxBRJKkQK+RQlfpUaCLSJIU6DVy8MEdpynQRSRJCvQauOceOPvs3GlTpsAFF6RTj4g0J52wtQamTMkdnzQJ7rornVpEpHmphZ6CefO6nkdEpFwKdBGRJqEulypatQrWrEm7ChFpFQr0Kho9GtavT7sKEWkV6nKpIoW5iNSSAl1EpEko0EVEmoQCXUSkSSjQRUSahAJdRKRJ6LDFGrrkEth667SrEJFmpUCvoWOOgb32SrsKEWlWCvQqOOggeP/9jtN7aWuLSBUpYqrgz38uPF2BLiLVpJ2iNaRAF5FqUqBX2a67wsCBYbhnz3RrEZHmpkBP2Ftv5Y5vu212WC10EakmBXrC8k/IdeWV2WuHKtBFpJoU6Al7773c8Y98JDusQBeRalKgJ+xrX8sd790720JXH7qIVJMCPWFz5+aOx1vlCnQRqSYFeoJef73jtHigm9WuFhFpPSUFuplNNLPnzGyJmZ1XZJ7PmtliM3vGzG5LtszGMGRIx2m9e8Ott8K4cTBgQO1rEpHW0eVuOjPrCcwCDgNeAhaY2Vx3XxybZxfgfOAgd19rZsOrVXCj6dEjnMPlmGPSrkREml0pLfT9gCXuvtTdNwC3A5Pz5vkKMMvd1wK4+6pkyxQRka6UEug7Astj4y9F0+I+AnzEzP5kZvPNbGKhBZnZDDNrN7P21atXV1ZxA9hzz7QrEJFWlNRO0V7ALsB4YBpwg5ltkz+Tu1/v7m3u3jZs2LCEVl0fHnkkO3zAAenVISKtq5RAXwGMio2PjKbFvQTMdfeN7r4MeJ4Q8C1j5szssI5mEZE0lBLoC4BdzGyMmfUBpgJ5R1tzL6F1jpkNJXTBLE2wzrq3aVN2+IEH0qtDRFpXl4Hu7puAmcD9wLPAne7+jJldamZHR7PdD6wxs8XAQ8DZ7r6mWkXXo/g5XPLP5yIiUgslnV3E3ecB8/KmXRQbduCb0a0lrYl9fO22G7zySnq1iEhr0i9FE3D33bBuXXZ8y5Zw379/OvWISGvS+f8ScOyxueNbtsDChbD99unUIyKtSYFeBZs3h5/6i4jUkrpcEjZ4MFx7bdpViEgrUgs9YWta6tgeEaknaqGLiDQJBXo3bdiQdgUiIoECvZuWLUu7AhGRQIHeTT20BUWkTiiOuunFF9OuQEQkUKB3w49+BIcdlh2/6KLi84qIVJuF07DUXltbm7e3t6ey7qTknyY3pU0pIi3EzBa6e1uhx9RCFxFpEgr0hMyenXYFItLqFOgJOfzwtCsQkVanQE9Inz5pVyAirU6BnpDevdOuQERanQI9IWqhi0jaFOgJUQtdRNKmQK/Qxo254z17plOHiEiGAr1Cn/tc7nj+j4xERGpNgV6hX/wi7QpERHIp0BNw6KFpVyAiokBPxAUXpF2BiIgCvSLLl2eHhw6F8eNTK0VE5J8U6BW4997CwyIiaVKgV+D008P99Olw0EHp1iIikqFAL9Ptt2eHp09Prw4RkXwK9DK89RZMm5Yd79cvvVpERPIp0MuwYkXuuM7fIiL1RIFehr59c8f1c38RqScK9DJs2pQ73kNbT0TqiCKpDBs25I7vvHM6dYiIFKJAL0N+H/rgwenUISJSiAK9DOpiEZF6VlJEmdlEM3vOzJaY2XmdzPcZM3Mza0uuxPqR34cuIlJPugx0M+sJzAImAWOBaWY2tsB8g4AzgMeSLrJe3Hln2hWIiBRXSgt9P2CJuy919w3A7cDkAvP9B3A58F6C9dWV2bOzw+7p1SEiUkgpgb4jEDu/IC9F0/7JzMYBo9z9vs4WZGYzzKzdzNpXr15ddrH1Yp990q5ARKSjbu/mM7MewH8CZ3Y1r7tf7+5t7t42bNiw7q66ptavzw7femt6dYiIFFNKoK8ARsXGR0bTMgYBewIPm9kLwAHA3GbbMbr//tnhXr3Sq0NEpJhSAn0BsIuZjTGzPsBUYG7mQXdf5+5D3X20u48G5gNHu3t7VSpOyVNPZYd1QWgRqUddBrq7bwJmAvcDzwJ3uvszZnapmR1d7QLrkQ5fFJF6VFLngbvPA+blTbuoyLzju19WfVOgi0g90m8fS5B/iOLo0amUISLSKe3eK8F7sSPr330X+vdPrxYRkWLUQi/B669nhxXmIlKvFOgleOONtCsQEemaAr0E+edBFxGpRwr0Ljz7LFx7bRjO3IuI1CPtFO3CXntlD1Mc2+EckyIi9UMt9C7Ejznv0ye9OkREuqJAL0PfvmlXICJSnAK9DL17p12BiEhxCvQybNmSdgUiIsUp0MugwxdFpJ4p0Muwxx5pVyAiUpwCvRMbN+aODxqUTh0iIqVQoHfitNPSrkBEpHQK9E7ce2/aFYiIlE6B3ol33027AhGR0inQO/HOO2lXICJSOgW6iEiTUKCLiDQJBXoRmzenXYGISHkU6EWsXJl2BSIi5VGgF7FiRdoViIiUR4FexNFHp12BiEh5FOhFrFqVdgUiIuVRoHfh6qvTrkBEpDQK9C700lVXRaRBKNALePnl7HAPbSERaRBqfxawdGl2uEcP+NOfYPDg9OoRESmFAr2AhQuzwz16wMc/nl4tIiKlUodCAV//enZYXS4i0igUV13o2TPtCkRESqNAz/P227njaqGLSKNQXOXJv0qRAl1EGoXiKs9ll+WO9+mTTh0iIuUqKdDNbKKZPWdmS8zsvAKPf9PMFpvZk2b2oJl9MPlSa+OZZ3LHFegi0ii6DHQz6wnMAiYBY4FpZjY2b7YngDZ33wu4G7gi6UJrwT13fPfd4ZBD0qlFRKRcpbTQ9wOWuPtSd98A3A5Mjs/g7g+5e+aSyvOBkcmWWRtXXZU7vngxbL11OrWIiJSrlEDfEVgeG38pmlbMScCvCj1gZjPMrN3M2levXl16lTVy5pnZ4QcfTK8OEZFKJLpT1MyOA9qA7xd63N2vd/c2d28bNmxYkqtO3LhxaVcgIlKeUn76vwIYFRsfGU3LYWaHAhcAB7v7+8mUl57+/dOuQESkPKW00BcAu5jZGDPrA0wF5sZnMLOPAtcBR7t7Q14aYuPG3PG+fdOpQ0SkUl0GurtvAmYC9wPPAne6+zNmdqmZZS7U9n1gIHCXmS0ys7lFFle3hg/PDt99d3p1iIhUyjz/WL0aaWtr8/b29lTWXYhZdnjzZv1CVETqk5ktdPe2Qo8ptsg9/nzGDIW5iDQmRRfwxhvZ4X790qtDRKQ7FOjAggXZYf3UX0QalQKd3J2gxx2XXh0iIt2hQAduuCE7vPfe6dUhItIdLR/oc+akXYGISDJaOtDfeQc+//ns+BNPpFeLiEh3tXSgDxyYO67uFhFpZC0b6KsKnKAg/uMiEZFG07KBvnZt2hWIiCSrZQN9t93SrkBEJFktG+hx99+f+2tREZFGVMr50JuKe+65Wn7wAzj88PTqERFJSsu10K+8Mnf82GPTqUNEJGktFeirVsHZZ2fHzz0XdtopvXpERJLUUoG+3Xa54+edl04dIiLV0DKBvnlzx2nbbFP7OkREqqVlAn3ChNzxPfZIpw4RkWppmUD//e/D/Sc/Ce++C08/nW49IiJJa4lAv/DC7PDcudC/f3q1iIhUS9MH+vPPw3e+kx3feuv0ahERqaamD/Rdd80OZ7pdRESaUVMH+rp1ueOjR6dShohITTRtoG/c2PGwxB12SKcWEZFaaNpAHz++47ReLXfmGhFpJU0Xce5w6KHw5z9np61YARs2pFeTiEgtNF2g33MP/O532fEjj1RXi4i0hqbqctm0Kffsid//Pvz85+nVIyJSS03TQn/hBRgzJju+aJEu+iwiraUpWujf/W5umIPCXERaT8O30I86CubNy502blw6tYiIpKmhA/3hh3PDfO1aWL9eP+8XkdbUsF0uJ58MhxySHX/yyfBDohEjYMCA9OoSEUlLw7XQ33oLttoqd5p7OrWIiNSThmuhP/BA7rh+MCQiEpQU6GY20cyeM7MlZtbhSpxm1tfM7ogef8zMRiddaMaKFeF+5crQMu/du1prEhFpLF0Gupn1BGYBk4CxwDQzG5s320nAWnffGbgKuDzpQjNGjYJjjoHhw6u1BhGRxlRKC30/YIm7L3X3DcDtwOS8eSYDN0fDdwMTzMySKzO2osnwi19Aj4brLBIRqa5SYnFHYHls/KVoWsF53H0TsA4Ykr8gM5thZu1m1r569erKKhYRkYJq2s519+vdvc3d24YNG1bLVYuINL1SAn0FMCo2PjKaVnAeM+sFbA2sSaJAEREpTSmBvgDYxczGmFkfYCowN2+eucAJ0fAU4HfuOjpcRKSWuvxhkbtvMrOZwP1AT+Amd3/GzC4F2t19LnAjcIuZLQFeJ4S+iIjUUEm/FHX3ecC8vGkXxYbfA47Nf56IiNSODv4TEWkSCnQRkSZhae27NLPVwIsVPn0o8FqC5SRFdZWnXuuC+q1NdZWnGev6oLsXPO47tUDvDjNrd/e2tOvIp7rKU691Qf3WprrK02p1qctFRKRJKNBFRJpEowb69WkXUITqKk+91gX1W5vqKk9L1dWQfegiItJRo7bQRUQkjwJdRKRJNFygd3U5vBqs/wUze8rMFplZezRtsJn91sz+Ht1vG003M/thVOuTZjYuwTpuMrNVZvZ0bFrZdZjZCdH8fzezEwqtK4G6LjazFdE2W2RmR8YeOz+q6zkzOyI2PdG/s5mNMrOHzGyxmT1jZmdE01PdZp3Uleo2M7N+Zva4mf01quuSaPoYC5eZXGLhspN9oulFL0NZrN6E6/qJmS2Lba99ouk1e+9Hy+xpZk+Y2S+j8dpuL3dvmBvh5GD/AD4E9AH+CoytcQ0vAEPzpl0BnBcNnwdcHg0fCfwKMOAA4LEE6/gkMA54utI6gMHA0uh+22h42yrUdTFwVoF5x0Z/w77AmOhv27Maf2dgBDAuGh4EPB+tP9Vt1kldqW6z6HUPjIZ7A49F2+FOYGo0/cfAKdHwqcCPo+GpwB2d1VuFun4CTCkwf83e+9FyvwncBvwyGq/p9mq0Fnopl8NLQ/wSfDcDx8Sm/9SD+cA2ZjYiiRW6+x8IZ7bsTh1HAEHaZ/YAAAMnSURBVL9199fdfS3wW2BiFeoqZjJwu7u/7+7LgCWEv3Hif2d3X+nuf4mG3wKeJVxpK9Vt1kldxdRkm0Wv++1otHd0c+BThMtMQsftVegylMXqTbquYmr23jezkcBRwP+Lxo0ab69GC/RSLodXbQ78xswWmtmMaNp27r4yGn4F2C4arnW95dZRy/pmRl95b8p0a6RVV/T19qOE1l3dbLO8uiDlbRZ1HywCVhEC7x/AGx4uM5m/jmKXoax6Xe6e2V7fjbbXVWbWN7+uvPVX4+94NXAOsCUaH0KNt1ejBXo9+IS7jwMmAaeZ2SfjD3r43pT6saD1Ukfkv4EPA/sAK4Er0yrEzAYC9wBfd/c344+luc0K1JX6NnP3ze6+D+EqZfsBu9W6hkLy6zKzPYHzCfV9jNCNcm4tazKzfwVWufvCWq43X6MFeimXw6sqd18R3a8CfkF4o7+a6UqJ7ldFs9e63nLrqEl97v5q9E+4BbiB7FfImtZlZr0JoXmru/88mpz6NitUV71ss6iWN4CHgAMJXRaZ6yjE11HsMpS1qGti1HXl7v4+MJvab6+DgKPN7AVCd9engGuo9fbqzg6AWt8IF+RYSthZkNnxs0cN1/8BYFBs+M+Efrfvk7tj7Ypo+Chyd8g8nnA9o8nd+VhWHYSWzDLCTqFto+HBVahrRGz4G4Q+QoA9yN0BtJSwcy/xv3P02n8KXJ03PdVt1kldqW4zYBiwTTTcH/gj8K/AXeTu5Ds1Gj6N3J18d3ZWbxXqGhHbnlcDl6Xx3o+WPZ7sTtGabq/EwqVWN8Je6+cJ/XkX1HjdH4o29l+BZzLrJ/R9PQj8HXgg88aI3kSzolqfAtoSrGUO4av4RkI/20mV1AGcSNjxsgT4UpXquiVa75OE68/Gw+qCqK7ngEnV+jsDnyB0pzwJLIpuR6a9zTqpK9VtBuwFPBGt/2ngotj/wOPRa78L6BtN7xeNL4ke/1BX9SZc1++i7fU08DOyR8LU7L0fW+54soFe0+2ln/6LiDSJRutDFxGRIhToIiJNQoEuItIkFOgiIk1CgS4i0iQU6CIiTUKBLiLSJP4/2Dk46EKcbGIAAAAASUVORK5CYII=\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"U_vp2gIKBPll"},"source":["# Output the Lyrics "]},{"cell_type":"code","metadata":{"id":"FJk29hBMsIiw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1645399138813,"user_tz":-360,"elapsed":11910,"user":{"displayName":"Mimsadi Islam","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07228862094531790502"}},"outputId":"1f24abcb-cfd2-41a4-d2d3-434f23655b4f"},"source":["#model_3.load_weights('/content/drive/My Drive/Colab Notebooks/R_T/best_model_3.hdf5')\n","model_3.load_weights('/content/best_model_3.hdf5')\n","model2.load_weights('/content/best_next_line_model.hdf5')\n","#model2.load_weights('/content/drive/My Drive/Colab Notebooks/R_T/best_next_line_model.hdf5')\n","seed_text = \"চোখের আলো  \"\n","#count=0\n","\n","#prv_last=\"\"\n","first_word_seed_text=\"\"\n","lines = 10\n","i=0\n","prediction_probabilities = []\n","while i < lines :\n","    if first_word_seed_text == \"\":\n","\n","        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n","        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n","        predicted = model_3.predict(token_list, verbose=0)\n","    else:\n","        token_list = tokenizer.texts_to_sequences([first_word_seed_text])[0]\n","        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n","        predicted = model_3.predict(token_list, verbose=0)\n","        first_word_seed_text = \"\"\n","    predicted_class = np.argmax(predicted)\n","    prediction_probabilities.append(predicted[0][predicted_class])\n","    output_word = \"\"\n","    for word, index in tokenizer.word_index.items():\n","        if index == predicted_class:\n","            output_word = word\n","            break\n","\n","    if seed_text.find(output_word) == -1:\n","        seed_text += output_word + \" \"\n","    else:\n","        predicted_class = np.argsort(predicted)[0][-2]\n","    \n","        for word, index in tokenizer.word_index.items():\n","            if index == predicted_class:         \n","                output_word = word\n","                break\n","        \n","\n","        seed_text +=  output_word + \" \"\n","\n","    next_line_seed_text = seed_text.split('\\n')[-1]\n","    if next_line_seed_text == \"\":\n","        next_line_seed_text = seed_text\n","    char_token_list = char_tokenizer.texts_to_sequences([next_line_seed_text])\n","    char_token_list = np.array(pad_sequences(char_token_list, maxlen=max_seq_length, padding='post'))\n","    predicted_next_line = model2.predict(char_token_list, verbose=0)[0][0]\n","    if predicted_next_line >= 0.5:\n","        seed_text += \"\\n\"\n","        i += 1\n","        first_word_seed_text = next_line_seed_text\n","    \n","\n","    \n","\n","\t\t\n","print(seed_text)\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["চোখের আলো  পথের তলে দুরে \n","তোমার ছল কতই সে যেই দান আর না কভু অণু ঠেকাবে \n","তোমাকে গো’ ব’লে কানে কখন যা \n","মেঘের কথা রে দিল আমায় আর আর আমায় দিকে তাহা হৃদয় হারাইয়া \n","বাঁধন যত আনন্দে ঘিরি বন্দে উড়ে আসবে চায় \n","তখন নিদয়া কোলে দ্বার তোমারে হয় হে নামে \n","মেঘের আসে গো বাসা পাওয়া ভালোবেসে না পারে \n","দোলে বাণে না গান কে খানে নয় \n","ঘর দেখালে পানে লাগে হে কোলে সমীরণে \n","কোথা সমীরণে ভবের আকাশ ধরার খোলা রাখিতে আমার– কোলে ঝর্ঝর সেই জানে আর ভাই বাঁধন সকল নামে \n","\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","col_list = [\"Starting\", \"Self -BLEU(GPT-2)\",\"SELF_BLEU(LSTM)\"]\n","df = pd.read_csv(\"/content/drive/MyDrive/ML Project/result - Sheet1.csv\", usecols=col_list)\n","\n","print(df[\"Starting\"][1])\n","print(len(df[\"Starting\"]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cXSum7AJdGsu","executionInfo":{"status":"ok","timestamp":1645399609092,"user_tz":-360,"elapsed":401,"user":{"displayName":"Mimsadi Islam","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07228862094531790502"}},"outputId":"9939c912-be7a-44e3-daec-a2f9d507e9bd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["আজি বর্ষায়\n","50\n"]}]},{"cell_type":"code","metadata":{"id":"-fkzEN-KydlM"},"source":["#####all songs together#####\n","#model_3.load_weights('/content/drive/My Drive/Colab Notebooks/R_T/best_model_3.hdf5')\n","model_3.load_weights('/content/best_model_3.hdf5')\n","model2.load_weights('/content/best_next_line_model.hdf5')\n","#model2.load_weights('/content/drive/My Drive/Colab Notebooks/R_T/best_next_line_model.hdf5')\n","col_list = [\"Starting\", \"Self -BLEU(GPT-2)\",\"SELF_BLEU(LSTM)\"]\n","df = pd.read_csv(\"/content/drive/MyDrive/ML Project/result - Sheet1.csv\", usecols=col_list)\n","\n","#print(df[\"Starting\"])\n","for j in range(len(df[\"Starting\"])):\n","    seed_text = df[\"Starting\"][j]\n","#count=0\n","\n","#prv_last=\"\"\n","    first_word_seed_text=\"\"\n","    lines = 10\n","    i=0\n","    prediction_probabilities = []\n","    while i < lines :\n","        if first_word_seed_text == \"\":\n","\n","            token_list = tokenizer.texts_to_sequences([seed_text])[0]\n","            token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n","            predicted = model_3.predict(token_list, verbose=0)\n","        else:\n","            token_list = tokenizer.texts_to_sequences([first_word_seed_text])[0]\n","            token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n","            predicted = model_3.predict(token_list, verbose=0)\n","            first_word_seed_text = \"\"\n","        predicted_class = np.argmax(predicted)\n","        prediction_probabilities.append(predicted[0][predicted_class])\n","        output_word = \"\"\n","        for word, index in tokenizer.word_index.items():\n","            if index == predicted_class:\n","                output_word = word\n","                break\n","\n","        if seed_text.find(output_word) == -1:\n","            seed_text += output_word + \" \"\n","        else:\n","            predicted_class = np.argsort(predicted)[0][-2]\n","           \n","            for word, index in tokenizer.word_index.items():\n","                if index == predicted_class:         \n","                    output_word = word\n","                    break\n","        \n","\n","            seed_text +=  output_word + \" \"\n","\n","        next_line_seed_text = seed_text.split('\\n')[-1]\n","        if next_line_seed_text == \"\":\n","            next_line_seed_text = seed_text\n","        char_token_list = char_tokenizer.texts_to_sequences([next_line_seed_text])\n","        char_token_list = np.array(pad_sequences(char_token_list, maxlen=max_seq_length, padding='post'))\n","        predicted_next_line = model2.predict(char_token_list, verbose=0)[0][0]\n","        if predicted_next_line >= 0.5:\n","            seed_text += \"\\n\"\n","            i += 1\n","            first_word_seed_text = next_line_seed_text\n","    \n","\n","    \n","\n","    path = \"/content/drive/MyDrive/ML Project/LSTM_outputs/song\" + str(j) + \".txt\"\n","    f = open(path, \"w\")\n","    f.writelines(seed_text)\n","    f.close()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"CtX1aYcBfRGQ"},"execution_count":null,"outputs":[]}]}